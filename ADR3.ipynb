{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADR3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqaElBXhFzJn"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/iADR')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "y = pd.read_csv('./data/labels(2248).csv')\n",
        "data6 = np.load('./data/gin_supervised_masking.npy')\n",
        "c_X_train,k_x_test,c_Y_train,k_y_test= train_test_split(data6,y,test_size=0.1,random_state=2021)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PI9ZtUoGAaH"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbeH70K-Kz5E"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS0ahTDtJ29c"
      },
      "source": [
        "# data5 = pd.read_csv('./data/fp(256).txt')\n",
        "y = pd.read_csv('./data/labels(2248).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGC9GJF_RvGp"
      },
      "source": [
        "data6 = np.load('./data/gin_supervised_masking.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKjeeLTUNc6j"
      },
      "source": [
        "data5= np.array(data5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nkmft_Y9E9t"
      },
      "source": [
        "data7 = np.hstack((data5,data6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOeaRT3wLGJR"
      },
      "source": [
        "c_X_train,k_x_test,c_Y_train,k_y_test= train_test_split(data6,y,test_size=0.1,random_state=2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOriFdkgLJ1p"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau#回调函数\n",
        "# # 定义回调函数：保存最优模型                     \n",
        "checkpoint = ModelCheckpoint(\"./model/model_context2.hdf5\",\n",
        "                             monitor=\"val_accuracy\",\n",
        "                             mode=\"max\",\n",
        "                             save_best_only = True,\n",
        "                             save_weights_only=False,\n",
        "                             verbose=1)\n",
        "# 定义回调函数：提前终止训练\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0.0001, \n",
        "                          patience = 40,\n",
        "                          verbose = 3,\n",
        "                          mode = 'min',\n",
        "                          restore_best_weights = True)\n",
        "# 定义回调函数：学习率衰减\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 10,\n",
        "                              verbose = 3,\n",
        "                              min_delta = 0.0001)\n",
        "\n",
        "# 将回调函数组织为回调列表\n",
        "callbacks = [earlystop,reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpu4g3RMvvfB",
        "outputId": "2a6334e7-565d-401f-f2fe-803479d01fa8"
      },
      "source": [
        "results=[]\n",
        "# 运行计时部分\n",
        "time_start = time.time()\n",
        "\n",
        "kfolder = KFold(n_splits=5,shuffle=True,random_state=2021)\n",
        "for i, (tra_id,val_id) in enumerate(kfolder.split(c_X_train,c_Y_train)):\n",
        "  print(f\"***********fold-{i+1}***********\")\n",
        "\n",
        "  c_x_train = c_X_train[tra_id]\n",
        "  c_y_train = c_Y_train.iloc[tra_id]\n",
        "\n",
        "  c_x_valid = c_X_train[val_id]\n",
        "  c_y_valid = c_Y_train.iloc[val_id]\n",
        "\n",
        "\n",
        "\n",
        "  scaler = preprocessing.StandardScaler().fit(c_x_train)\n",
        "  c_x_train = scaler.transform(c_x_train)\n",
        "\n",
        "  \n",
        "  scaler = preprocessing.StandardScaler().fit(c_x_valid)\n",
        "  c_x_valid = scaler.transform(c_x_valid)\n",
        "\n",
        "  \n",
        "\n",
        "  # reshape for cnn training\n",
        "  # c_x_test = np.array(c_x_test).reshape(c_x_test.shape[0], c_x_test.shape[1],1)\n",
        "  c_x_valid = np.array(c_x_valid).reshape(c_x_valid.shape[0], c_x_valid.shape[1],1)\n",
        "  c_x_train = np.array(c_x_train).reshape(c_x_train.shape[0], c_x_train.shape[1],1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  masking_input = keras.Input(\n",
        "      shape=(300,1), name=\"masking\"\n",
        "  )  # Variable-length sequence of ints\n",
        "  FP_input = keras.Input(\n",
        "      shape=(256,1), name=\"FP\"\n",
        "  ) \n",
        "\n",
        "\n",
        "  # Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
        "  # FP_masking_features = layers.Conv1D(16, 2, activation=\"relu\")(FP_masking_input)\n",
        "  # FP_masking_features2 = layers.Conv2D(32, 3, activation=\"relu\")(FP_masking_features1)\n",
        "  # FP_masking_features = layers.MaxPooling1D(3)(FP_masking_features)\n",
        "\n",
        "  # FP_masking_features = layers.LSTM(300)(FP_masking_features)\n",
        "  masking_features = layers.Flatten()(masking_input)\n",
        "\n",
        "  FP_flat = layers.Flatten()(FP_nput)\n",
        "  # FP_masking_flat = layers.LSTM(300)(FP_masking_flat)\n",
        "\n",
        "  # Merge all available features into a single large vector via concatenation\n",
        "  x = layers.concatenate([masking_flat,FP_flat])\n",
        "\n",
        "  # Stick a logistic regression for priority prediction on top of the features\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(1024,activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  # x = layers.Dense(512,activation=\"relu\")(x)\n",
        "  # x = layers.Dropout(0.4)(x)\n",
        "  priority_pred = layers.Dense(27, activation=\"sigmoid\",name=\"priority\")(x)\n",
        "\n",
        "  model = keras.Model(inputs=[masking_input,FP_input],outputs=[priority_pred])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  opt = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "    \n",
        "  # training\n",
        "  history = model.fit({\"masking\": c_x_train,\"FP\":},{\"priority\": c_y_train.values},epochs=100,batch_size=128,\n",
        "                      validation_data=(c_x_valid, c_y_valid.values),callbacks=callbacks,)\n",
        "\n",
        "\n",
        "  baseline_results = model.evaluate(c_x_valid, c_y_valid.values, verbose=0)\n",
        "  for name, value in zip(model.metrics_names, baseline_results):\n",
        "    print(name, ': ', value)\n",
        "  print()\n",
        "\n",
        "\n",
        "  # model.save('./model/model_masking_5fold'+str(i+1)+'.h5')\n",
        "\n",
        "  result = np.array(baseline_results)\n",
        "  results.append(result)\n",
        "\n",
        "\n",
        "\n",
        "print(\"******************************************************************\")\n",
        "print(np.array(results))\n",
        "\n",
        "print(f\"-Accuracy score_mean:{np.mean(np.array(results)[:,[1]])}\")\n",
        "print(f\"-Accuracy score_mean:{np.array(results)[:,[1]]}\")\n",
        "print(f\"-Accuracy score_mean:{np.std(np.array(results)[:,[1]])}\")\n",
        "\n",
        "print(f\"-Precision score_mean:{np.mean(np.array(results)[:,[2]])}\")\n",
        "print(f\"-Precision score_mean:{np.std(np.array(results)[:,[2]])}\")\n",
        "\n",
        "print(f\"-Recall score_mean:{np.mean(np.array(results)[:,[3]])}\")\n",
        "print(f\"-Recall score_mean:{np.std(np.array(results)[:,[3]])}\")\n",
        "\n",
        "print(f\"-AUC score_mean:{np.mean(np.array(results)[:,[4]])}\")\n",
        "print(f\"-AUC score_mean:{np.std(np.array(results)[:,[4]])}\")\n",
        "\n",
        "print(f\"-AUPR score_mean:{np.mean(np.array(results)[:,[5]])}\")\n",
        "print(f\"-AUPR score_mean:{np.std(np.array(results)[:,[5]])}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# 运行计时部分\n",
        "time_end = time.time()\n",
        "print(f\"total running time: {(time_end - time_start)/60} minites\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********fold-1***********\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 123ms/step - loss: 0.5750 - accuracy: 0.7298 - precision: 0.7652 - recall: 0.8081 - AUC: 0.5645 - AUPR: 0.6523 - val_loss: 0.4992 - val_accuracy: 0.7629 - val_precision: 0.7604 - val_recall: 0.8730 - val_AUC: 0.6249 - val_AUPR: 0.6593\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.5194 - accuracy: 0.7517 - precision: 0.7733 - recall: 0.8414 - AUC: 0.5865 - AUPR: 0.6626 - val_loss: 0.4900 - val_accuracy: 0.7658 - val_precision: 0.7545 - val_recall: 0.8938 - val_AUC: 0.6342 - val_AUPR: 0.6706\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4994 - accuracy: 0.7628 - precision: 0.7865 - recall: 0.8410 - AUC: 0.6139 - AUPR: 0.6807 - val_loss: 0.4829 - val_accuracy: 0.7682 - val_precision: 0.7575 - val_recall: 0.8927 - val_AUC: 0.6556 - val_AUPR: 0.6782\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4851 - accuracy: 0.7722 - precision: 0.7840 - recall: 0.8670 - AUC: 0.6425 - AUPR: 0.6945 - val_loss: 0.4795 - val_accuracy: 0.7682 - val_precision: 0.7576 - val_recall: 0.8924 - val_AUC: 0.6657 - val_AUPR: 0.6813\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.4770 - accuracy: 0.7748 - precision: 0.7910 - recall: 0.8595 - AUC: 0.6558 - AUPR: 0.7079 - val_loss: 0.4748 - val_accuracy: 0.7721 - val_precision: 0.7639 - val_recall: 0.8880 - val_AUC: 0.6747 - val_AUPR: 0.6854\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4673 - accuracy: 0.7789 - precision: 0.7905 - recall: 0.8695 - AUC: 0.6775 - AUPR: 0.7186 - val_loss: 0.4742 - val_accuracy: 0.7715 - val_precision: 0.7623 - val_recall: 0.8901 - val_AUC: 0.6801 - val_AUPR: 0.6860\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4603 - accuracy: 0.7833 - precision: 0.7955 - recall: 0.8700 - AUC: 0.6945 - AUPR: 0.7270 - val_loss: 0.4729 - val_accuracy: 0.7740 - val_precision: 0.7689 - val_recall: 0.8818 - val_AUC: 0.6832 - val_AUPR: 0.6879\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4521 - accuracy: 0.7881 - precision: 0.7995 - recall: 0.8731 - AUC: 0.7130 - AUPR: 0.7398 - val_loss: 0.4700 - val_accuracy: 0.7744 - val_precision: 0.7724 - val_recall: 0.8753 - val_AUC: 0.6828 - val_AUPR: 0.6876\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.4504 - accuracy: 0.7900 - precision: 0.8068 - recall: 0.8641 - AUC: 0.7150 - AUPR: 0.7395 - val_loss: 0.4749 - val_accuracy: 0.7741 - val_precision: 0.7598 - val_recall: 0.9022 - val_AUC: 0.6852 - val_AUPR: 0.6873\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.4429 - accuracy: 0.7916 - precision: 0.8048 - recall: 0.8711 - AUC: 0.7290 - AUPR: 0.7534 - val_loss: 0.4696 - val_accuracy: 0.7771 - val_precision: 0.7767 - val_recall: 0.8732 - val_AUC: 0.6908 - val_AUPR: 0.6899\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4360 - accuracy: 0.7947 - precision: 0.8057 - recall: 0.8762 - AUC: 0.7422 - AUPR: 0.7597 - val_loss: 0.4697 - val_accuracy: 0.7765 - val_precision: 0.7708 - val_recall: 0.8839 - val_AUC: 0.6959 - val_AUPR: 0.6924\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.4337 - accuracy: 0.7967 - precision: 0.8102 - recall: 0.8725 - AUC: 0.7451 - AUPR: 0.7627 - val_loss: 0.4687 - val_accuracy: 0.7786 - val_precision: 0.7802 - val_recall: 0.8696 - val_AUC: 0.6965 - val_AUPR: 0.6931\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4252 - accuracy: 0.7987 - precision: 0.8102 - recall: 0.8769 - AUC: 0.7596 - AUPR: 0.7723 - val_loss: 0.4701 - val_accuracy: 0.7786 - val_precision: 0.7767 - val_recall: 0.8766 - val_AUC: 0.6938 - val_AUPR: 0.6905\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4223 - accuracy: 0.8017 - precision: 0.8221 - recall: 0.8631 - AUC: 0.7667 - AUPR: 0.7774 - val_loss: 0.4721 - val_accuracy: 0.7753 - val_precision: 0.7643 - val_recall: 0.8950 - val_AUC: 0.6981 - val_AUPR: 0.6920\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4206 - accuracy: 0.8037 - precision: 0.8080 - recall: 0.8913 - AUC: 0.7686 - AUPR: 0.7762 - val_loss: 0.4689 - val_accuracy: 0.7811 - val_precision: 0.7943 - val_recall: 0.8485 - val_AUC: 0.6959 - val_AUPR: 0.6932\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4142 - accuracy: 0.8071 - precision: 0.8235 - recall: 0.8722 - AUC: 0.7807 - AUPR: 0.7864 - val_loss: 0.4714 - val_accuracy: 0.7802 - val_precision: 0.7723 - val_recall: 0.8894 - val_AUC: 0.7011 - val_AUPR: 0.6945\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4109 - accuracy: 0.8068 - precision: 0.8216 - recall: 0.8744 - AUC: 0.7864 - AUPR: 0.7912 - val_loss: 0.4682 - val_accuracy: 0.7815 - val_precision: 0.7798 - val_recall: 0.8772 - val_AUC: 0.7022 - val_AUPR: 0.6954\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4061 - accuracy: 0.8120 - precision: 0.8273 - recall: 0.8759 - AUC: 0.7932 - AUPR: 0.7945 - val_loss: 0.4673 - val_accuracy: 0.7809 - val_precision: 0.7766 - val_recall: 0.8823 - val_AUC: 0.7033 - val_AUPR: 0.6994\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.4041 - accuracy: 0.8090 - precision: 0.8202 - recall: 0.8814 - AUC: 0.7930 - AUPR: 0.7937 - val_loss: 0.4677 - val_accuracy: 0.7804 - val_precision: 0.7789 - val_recall: 0.8766 - val_AUC: 0.7002 - val_AUPR: 0.6973\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4027 - accuracy: 0.8119 - precision: 0.8258 - recall: 0.8782 - AUC: 0.7975 - AUPR: 0.7984 - val_loss: 0.4679 - val_accuracy: 0.7825 - val_precision: 0.7802 - val_recall: 0.8789 - val_AUC: 0.7020 - val_AUPR: 0.6993\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3969 - accuracy: 0.8158 - precision: 0.8276 - recall: 0.8833 - AUC: 0.8044 - AUPR: 0.8020 - val_loss: 0.4664 - val_accuracy: 0.7802 - val_precision: 0.7800 - val_recall: 0.8736 - val_AUC: 0.7059 - val_AUPR: 0.7015\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3975 - accuracy: 0.8111 - precision: 0.8296 - recall: 0.8704 - AUC: 0.8048 - AUPR: 0.8010 - val_loss: 0.4682 - val_accuracy: 0.7811 - val_precision: 0.7784 - val_recall: 0.8791 - val_AUC: 0.7103 - val_AUPR: 0.7033\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3894 - accuracy: 0.8198 - precision: 0.8345 - recall: 0.8805 - AUC: 0.8120 - AUPR: 0.8058 - val_loss: 0.4667 - val_accuracy: 0.7849 - val_precision: 0.7974 - val_recall: 0.8518 - val_AUC: 0.7093 - val_AUPR: 0.7030\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3837 - accuracy: 0.8234 - precision: 0.8350 - recall: 0.8871 - AUC: 0.8195 - AUPR: 0.8186 - val_loss: 0.4666 - val_accuracy: 0.7830 - val_precision: 0.7862 - val_recall: 0.8682 - val_AUC: 0.7091 - val_AUPR: 0.7046\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3809 - accuracy: 0.8228 - precision: 0.8382 - recall: 0.8806 - AUC: 0.8245 - AUPR: 0.8157 - val_loss: 0.4682 - val_accuracy: 0.7845 - val_precision: 0.7870 - val_recall: 0.8699 - val_AUC: 0.7102 - val_AUPR: 0.7060\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3820 - accuracy: 0.8209 - precision: 0.8369 - recall: 0.8788 - AUC: 0.8223 - AUPR: 0.8170 - val_loss: 0.4687 - val_accuracy: 0.7845 - val_precision: 0.7848 - val_recall: 0.8744 - val_AUC: 0.7083 - val_AUPR: 0.7053\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3747 - accuracy: 0.8269 - precision: 0.8412 - recall: 0.8843 - AUC: 0.8309 - AUPR: 0.8205 - val_loss: 0.4670 - val_accuracy: 0.7849 - val_precision: 0.7827 - val_recall: 0.8795 - val_AUC: 0.7125 - val_AUPR: 0.7066\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3717 - accuracy: 0.8276 - precision: 0.8395 - recall: 0.8885 - AUC: 0.8353 - AUPR: 0.8292 - val_loss: 0.4678 - val_accuracy: 0.7882 - val_precision: 0.8001 - val_recall: 0.8542 - val_AUC: 0.7094 - val_AUPR: 0.7039\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3695 - accuracy: 0.8302 - precision: 0.8450 - recall: 0.8851 - AUC: 0.8363 - AUPR: 0.8278 - val_loss: 0.4728 - val_accuracy: 0.7847 - val_precision: 0.7900 - val_recall: 0.8649 - val_AUC: 0.7116 - val_AUPR: 0.7043\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3682 - accuracy: 0.8291 - precision: 0.8485 - recall: 0.8778 - AUC: 0.8390 - AUPR: 0.8298 - val_loss: 0.4724 - val_accuracy: 0.7848 - val_precision: 0.7850 - val_recall: 0.8747 - val_AUC: 0.7128 - val_AUPR: 0.7065\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3650 - accuracy: 0.8307 - precision: 0.8467 - recall: 0.8836 - AUC: 0.8412 - AUPR: 0.8323 - val_loss: 0.4695 - val_accuracy: 0.7845 - val_precision: 0.7780 - val_recall: 0.8879 - val_AUC: 0.7157 - val_AUPR: 0.7121\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3609 - accuracy: 0.8336 - precision: 0.8410 - recall: 0.8981 - AUC: 0.8474 - AUPR: 0.8391 - val_loss: 0.4656 - val_accuracy: 0.7858 - val_precision: 0.7889 - val_recall: 0.8694 - val_AUC: 0.7156 - val_AUPR: 0.7119\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3603 - accuracy: 0.8336 - precision: 0.8501 - recall: 0.8843 - AUC: 0.8492 - AUPR: 0.8343 - val_loss: 0.4662 - val_accuracy: 0.7873 - val_precision: 0.7922 - val_recall: 0.8666 - val_AUC: 0.7163 - val_AUPR: 0.7110\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3554 - accuracy: 0.8348 - precision: 0.8503 - recall: 0.8865 - AUC: 0.8531 - AUPR: 0.8397 - val_loss: 0.4687 - val_accuracy: 0.7856 - val_precision: 0.7883 - val_recall: 0.8702 - val_AUC: 0.7161 - val_AUPR: 0.7096\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3542 - accuracy: 0.8371 - precision: 0.8494 - recall: 0.8922 - AUC: 0.8546 - AUPR: 0.8411 - val_loss: 0.4697 - val_accuracy: 0.7859 - val_precision: 0.7882 - val_recall: 0.8710 - val_AUC: 0.7168 - val_AUPR: 0.7103\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3528 - accuracy: 0.8368 - precision: 0.8516 - recall: 0.8884 - AUC: 0.8567 - AUPR: 0.8452 - val_loss: 0.4680 - val_accuracy: 0.7892 - val_precision: 0.7966 - val_recall: 0.8629 - val_AUC: 0.7182 - val_AUPR: 0.7106\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3507 - accuracy: 0.8381 - precision: 0.8539 - recall: 0.8876 - AUC: 0.8590 - AUPR: 0.8417 - val_loss: 0.4693 - val_accuracy: 0.7866 - val_precision: 0.7896 - val_recall: 0.8701 - val_AUC: 0.7177 - val_AUPR: 0.7100\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3450 - accuracy: 0.8422 - precision: 0.8537 - recall: 0.8959 - AUC: 0.8645 - AUPR: 0.8501 - val_loss: 0.4706 - val_accuracy: 0.7866 - val_precision: 0.7878 - val_recall: 0.8735 - val_AUC: 0.7165 - val_AUPR: 0.7097\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3505 - accuracy: 0.8372 - precision: 0.8513 - recall: 0.8896 - AUC: 0.8577 - AUPR: 0.8443 - val_loss: 0.4706 - val_accuracy: 0.7879 - val_precision: 0.7922 - val_recall: 0.8682 - val_AUC: 0.7174 - val_AUPR: 0.7099\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3470 - accuracy: 0.8427 - precision: 0.8579 - recall: 0.8907 - AUC: 0.8610 - AUPR: 0.8462 - val_loss: 0.4715 - val_accuracy: 0.7882 - val_precision: 0.7935 - val_recall: 0.8663 - val_AUC: 0.7173 - val_AUPR: 0.7098\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3468 - accuracy: 0.8389 - precision: 0.8506 - recall: 0.8941 - AUC: 0.8622 - AUPR: 0.8486 - val_loss: 0.4733 - val_accuracy: 0.7876 - val_precision: 0.7876 - val_recall: 0.8759 - val_AUC: 0.7177 - val_AUPR: 0.7092\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3501 - accuracy: 0.8390 - precision: 0.8547 - recall: 0.8881 - AUC: 0.8591 - AUPR: 0.8435 - val_loss: 0.4706 - val_accuracy: 0.7890 - val_precision: 0.7933 - val_recall: 0.8685 - val_AUC: 0.7176 - val_AUPR: 0.7095\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3443 - accuracy: 0.8435 - precision: 0.8595 - recall: 0.8900 - AUC: 0.8653 - AUPR: 0.8492 - val_loss: 0.4709 - val_accuracy: 0.7888 - val_precision: 0.7921 - val_recall: 0.8704 - val_AUC: 0.7176 - val_AUPR: 0.7096\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3450 - accuracy: 0.8409 - precision: 0.8553 - recall: 0.8909 - AUC: 0.8648 - AUPR: 0.8460 - val_loss: 0.4713 - val_accuracy: 0.7889 - val_precision: 0.7918 - val_recall: 0.8711 - val_AUC: 0.7179 - val_AUPR: 0.7098\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3438 - accuracy: 0.8433 - precision: 0.8605 - recall: 0.8882 - AUC: 0.8644 - AUPR: 0.8531 - val_loss: 0.4715 - val_accuracy: 0.7897 - val_precision: 0.7927 - val_recall: 0.8711 - val_AUC: 0.7177 - val_AUPR: 0.7097\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3451 - accuracy: 0.8401 - precision: 0.8544 - recall: 0.8908 - AUC: 0.8633 - AUPR: 0.8493 - val_loss: 0.4717 - val_accuracy: 0.7883 - val_precision: 0.7915 - val_recall: 0.8704 - val_AUC: 0.7182 - val_AUPR: 0.7097\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3457 - accuracy: 0.8407 - precision: 0.8559 - recall: 0.8898 - AUC: 0.8619 - AUPR: 0.8483 - val_loss: 0.4720 - val_accuracy: 0.7877 - val_precision: 0.7907 - val_recall: 0.8705 - val_AUC: 0.7182 - val_AUPR: 0.7098\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3462 - accuracy: 0.8390 - precision: 0.8528 - recall: 0.8910 - AUC: 0.8614 - AUPR: 0.8455 - val_loss: 0.4720 - val_accuracy: 0.7878 - val_precision: 0.7910 - val_recall: 0.8702 - val_AUC: 0.7183 - val_AUPR: 0.7097\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3416 - accuracy: 0.8423 - precision: 0.8576 - recall: 0.8904 - AUC: 0.8669 - AUPR: 0.8514 - val_loss: 0.4721 - val_accuracy: 0.7875 - val_precision: 0.7910 - val_recall: 0.8693 - val_AUC: 0.7182 - val_AUPR: 0.7097\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3473 - accuracy: 0.8408 - precision: 0.8532 - recall: 0.8939 - AUC: 0.8620 - AUPR: 0.8500 - val_loss: 0.4720 - val_accuracy: 0.7874 - val_precision: 0.7917 - val_recall: 0.8677 - val_AUC: 0.7181 - val_AUPR: 0.7098\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3441 - accuracy: 0.8412 - precision: 0.8554 - recall: 0.8914 - AUC: 0.8640 - AUPR: 0.8550 - val_loss: 0.4721 - val_accuracy: 0.7870 - val_precision: 0.7908 - val_recall: 0.8687 - val_AUC: 0.7181 - val_AUPR: 0.7098\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.3442 - accuracy: 0.8414 - precision: 0.8542 - recall: 0.8938 - AUC: 0.8633 - AUPR: 0.8521 - val_loss: 0.4721 - val_accuracy: 0.7876 - val_precision: 0.7914 - val_recall: 0.8688 - val_AUC: 0.7181 - val_AUPR: 0.7099\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3452 - accuracy: 0.8412 - precision: 0.8547 - recall: 0.8925 - AUC: 0.8639 - AUPR: 0.8504 - val_loss: 0.4721 - val_accuracy: 0.7873 - val_precision: 0.7913 - val_recall: 0.8684 - val_AUC: 0.7181 - val_AUPR: 0.7099\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3446 - accuracy: 0.8407 - precision: 0.8550 - recall: 0.8912 - AUC: 0.8639 - AUPR: 0.8496 - val_loss: 0.4721 - val_accuracy: 0.7874 - val_precision: 0.7914 - val_recall: 0.8684 - val_AUC: 0.7181 - val_AUPR: 0.7098\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3458 - accuracy: 0.8389 - precision: 0.8532 - recall: 0.8902 - AUC: 0.8619 - AUPR: 0.8463 - val_loss: 0.4721 - val_accuracy: 0.7877 - val_precision: 0.7916 - val_recall: 0.8687 - val_AUC: 0.7180 - val_AUPR: 0.7099\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3432 - accuracy: 0.8416 - precision: 0.8571 - recall: 0.8897 - AUC: 0.8662 - AUPR: 0.8501 - val_loss: 0.4722 - val_accuracy: 0.7875 - val_precision: 0.7914 - val_recall: 0.8685 - val_AUC: 0.7180 - val_AUPR: 0.7098\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.3443 - accuracy: 0.8416 - precision: 0.8565 - recall: 0.8906 - AUC: 0.8648 - AUPR: 0.8542 - val_loss: 0.4722 - val_accuracy: 0.7875 - val_precision: 0.7910 - val_recall: 0.8693 - val_AUC: 0.7180 - val_AUPR: 0.7099\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3458 - accuracy: 0.8386 - precision: 0.8523 - recall: 0.8909 - AUC: 0.8631 - AUPR: 0.8504 - val_loss: 0.4722 - val_accuracy: 0.7876 - val_precision: 0.7911 - val_recall: 0.8693 - val_AUC: 0.7181 - val_AUPR: 0.7099\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3399 - accuracy: 0.8429 - precision: 0.8598 - recall: 0.8885 - AUC: 0.8697 - AUPR: 0.8533 - val_loss: 0.4723 - val_accuracy: 0.7876 - val_precision: 0.7912 - val_recall: 0.8691 - val_AUC: 0.7181 - val_AUPR: 0.7098\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3456 - accuracy: 0.8399 - precision: 0.8547 - recall: 0.8899 - AUC: 0.8629 - AUPR: 0.8450 - val_loss: 0.4723 - val_accuracy: 0.7877 - val_precision: 0.7913 - val_recall: 0.8694 - val_AUC: 0.7181 - val_AUPR: 0.7098\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3442 - accuracy: 0.8424 - precision: 0.8601 - recall: 0.8869 - AUC: 0.8641 - AUPR: 0.8509 - val_loss: 0.4723 - val_accuracy: 0.7875 - val_precision: 0.7909 - val_recall: 0.8694 - val_AUC: 0.7181 - val_AUPR: 0.7099\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3423 - accuracy: 0.8403 - precision: 0.8529 - recall: 0.8935 - AUC: 0.8652 - AUPR: 0.8526 - val_loss: 0.4723 - val_accuracy: 0.7875 - val_precision: 0.7908 - val_recall: 0.8697 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3422 - accuracy: 0.8438 - precision: 0.8545 - recall: 0.8980 - AUC: 0.8667 - AUPR: 0.8524 - val_loss: 0.4723 - val_accuracy: 0.7876 - val_precision: 0.7910 - val_recall: 0.8696 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3426 - accuracy: 0.8422 - precision: 0.8556 - recall: 0.8930 - AUC: 0.8649 - AUPR: 0.8496 - val_loss: 0.4723 - val_accuracy: 0.7877 - val_precision: 0.7911 - val_recall: 0.8696 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3446 - accuracy: 0.8412 - precision: 0.8568 - recall: 0.8894 - AUC: 0.8653 - AUPR: 0.8508 - val_loss: 0.4723 - val_accuracy: 0.7876 - val_precision: 0.7911 - val_recall: 0.8694 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3421 - accuracy: 0.8448 - precision: 0.8569 - recall: 0.8963 - AUC: 0.8672 - AUPR: 0.8537 - val_loss: 0.4723 - val_accuracy: 0.7875 - val_precision: 0.7910 - val_recall: 0.8693 - val_AUC: 0.7182 - val_AUPR: 0.7100\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3413 - accuracy: 0.8426 - precision: 0.8567 - recall: 0.8924 - AUC: 0.8681 - AUPR: 0.8560 - val_loss: 0.4723 - val_accuracy: 0.7874 - val_precision: 0.7911 - val_recall: 0.8690 - val_AUC: 0.7182 - val_AUPR: 0.7100\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3403 - accuracy: 0.8448 - precision: 0.8590 - recall: 0.8933 - AUC: 0.8685 - AUPR: 0.8512 - val_loss: 0.4723 - val_accuracy: 0.7873 - val_precision: 0.7910 - val_recall: 0.8690 - val_AUC: 0.7182 - val_AUPR: 0.7100\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3455 - accuracy: 0.8421 - precision: 0.8563 - recall: 0.8919 - AUC: 0.8627 - AUPR: 0.8462 - val_loss: 0.4723 - val_accuracy: 0.7875 - val_precision: 0.7912 - val_recall: 0.8690 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3440 - accuracy: 0.8410 - precision: 0.8548 - recall: 0.8920 - AUC: 0.8648 - AUPR: 0.8498 - val_loss: 0.4723 - val_accuracy: 0.7874 - val_precision: 0.7911 - val_recall: 0.8690 - val_AUC: 0.7181 - val_AUPR: 0.7100\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3483 - accuracy: 0.8390 - precision: 0.8543 - recall: 0.8888 - AUC: 0.8597 - AUPR: 0.8460 - val_loss: 0.4723 - val_accuracy: 0.7877 - val_precision: 0.7913 - val_recall: 0.8691 - val_AUC: 0.7182 - val_AUPR: 0.7100\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3403 - accuracy: 0.8444 - precision: 0.8568 - recall: 0.8957 - AUC: 0.8683 - AUPR: 0.8541 - val_loss: 0.4723 - val_accuracy: 0.7878 - val_precision: 0.7915 - val_recall: 0.8693 - val_AUC: 0.7182 - val_AUPR: 0.7100\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 00072: early stopping\n",
            "loss :  0.46563878655433655\n",
            "accuracy :  0.7858253121376038\n",
            "precision :  0.7889404892921448\n",
            "recall :  0.8694370985031128\n",
            "AUC :  0.7155795693397522\n",
            "AUPR :  0.7118765711784363\n",
            "\n",
            "***********fold-2***********\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 120ms/step - loss: 0.5870 - accuracy: 0.7239 - precision: 0.7565 - recall: 0.7981 - AUC: 0.5838 - AUPR: 0.6491 - val_loss: 0.4830 - val_accuracy: 0.7805 - val_precision: 0.7927 - val_recall: 0.8753 - val_AUC: 0.5993 - val_AUPR: 0.6766\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.5226 - accuracy: 0.7462 - precision: 0.7721 - recall: 0.8234 - AUC: 0.5833 - AUPR: 0.6562 - val_loss: 0.4764 - val_accuracy: 0.7812 - val_precision: 0.7969 - val_recall: 0.8689 - val_AUC: 0.6338 - val_AUPR: 0.6914\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.4976 - accuracy: 0.7627 - precision: 0.7796 - recall: 0.8471 - AUC: 0.6303 - AUPR: 0.6816 - val_loss: 0.4722 - val_accuracy: 0.7867 - val_precision: 0.8014 - val_recall: 0.8727 - val_AUC: 0.6438 - val_AUPR: 0.6954\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.4831 - accuracy: 0.7699 - precision: 0.7845 - recall: 0.8542 - AUC: 0.6603 - AUPR: 0.6952 - val_loss: 0.4663 - val_accuracy: 0.7874 - val_precision: 0.7991 - val_recall: 0.8783 - val_AUC: 0.6525 - val_AUPR: 0.7020\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4713 - accuracy: 0.7758 - precision: 0.7885 - recall: 0.8601 - AUC: 0.6812 - AUPR: 0.7113 - val_loss: 0.4655 - val_accuracy: 0.7888 - val_precision: 0.8106 - val_recall: 0.8608 - val_AUC: 0.6557 - val_AUPR: 0.7081\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4649 - accuracy: 0.7807 - precision: 0.8022 - recall: 0.8461 - AUC: 0.6985 - AUPR: 0.7200 - val_loss: 0.4620 - val_accuracy: 0.7909 - val_precision: 0.8017 - val_recall: 0.8809 - val_AUC: 0.6605 - val_AUPR: 0.7089\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.4588 - accuracy: 0.7811 - precision: 0.7936 - recall: 0.8625 - AUC: 0.7139 - AUPR: 0.7277 - val_loss: 0.4595 - val_accuracy: 0.7897 - val_precision: 0.8109 - val_recall: 0.8621 - val_AUC: 0.6687 - val_AUPR: 0.7129\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4469 - accuracy: 0.7892 - precision: 0.7967 - recall: 0.8748 - AUC: 0.7315 - AUPR: 0.7395 - val_loss: 0.4606 - val_accuracy: 0.7897 - val_precision: 0.8109 - val_recall: 0.8622 - val_AUC: 0.6723 - val_AUPR: 0.7155\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4423 - accuracy: 0.7933 - precision: 0.8164 - recall: 0.8493 - AUC: 0.7433 - AUPR: 0.7472 - val_loss: 0.4581 - val_accuracy: 0.7899 - val_precision: 0.8116 - val_recall: 0.8615 - val_AUC: 0.6762 - val_AUPR: 0.7160\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.4356 - accuracy: 0.7966 - precision: 0.8050 - recall: 0.8760 - AUC: 0.7494 - AUPR: 0.7533 - val_loss: 0.4582 - val_accuracy: 0.7903 - val_precision: 0.8153 - val_recall: 0.8560 - val_AUC: 0.6771 - val_AUPR: 0.7170\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4274 - accuracy: 0.7979 - precision: 0.8157 - recall: 0.8602 - AUC: 0.7634 - AUPR: 0.7633 - val_loss: 0.4602 - val_accuracy: 0.7888 - val_precision: 0.8097 - val_recall: 0.8622 - val_AUC: 0.6765 - val_AUPR: 0.7164\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.4226 - accuracy: 0.8016 - precision: 0.8183 - recall: 0.8638 - AUC: 0.7696 - AUPR: 0.7707 - val_loss: 0.4596 - val_accuracy: 0.7905 - val_precision: 0.8162 - val_recall: 0.8550 - val_AUC: 0.6775 - val_AUPR: 0.7182\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.4194 - accuracy: 0.8034 - precision: 0.8215 - recall: 0.8624 - AUC: 0.7773 - AUPR: 0.7747 - val_loss: 0.4600 - val_accuracy: 0.7891 - val_precision: 0.8138 - val_recall: 0.8560 - val_AUC: 0.6803 - val_AUPR: 0.7203\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4123 - accuracy: 0.8082 - precision: 0.8206 - recall: 0.8740 - AUC: 0.7839 - AUPR: 0.7780 - val_loss: 0.4597 - val_accuracy: 0.7891 - val_precision: 0.8235 - val_recall: 0.8403 - val_AUC: 0.6821 - val_AUPR: 0.7217\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.4053 - accuracy: 0.8113 - precision: 0.8248 - recall: 0.8735 - AUC: 0.7950 - AUPR: 0.7895 - val_loss: 0.4589 - val_accuracy: 0.7895 - val_precision: 0.8170 - val_recall: 0.8516 - val_AUC: 0.6816 - val_AUPR: 0.7221\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.4067 - accuracy: 0.8095 - precision: 0.8293 - recall: 0.8625 - AUC: 0.7946 - AUPR: 0.7867 - val_loss: 0.4612 - val_accuracy: 0.7878 - val_precision: 0.8140 - val_recall: 0.8531 - val_AUC: 0.6802 - val_AUPR: 0.7228\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3948 - accuracy: 0.8163 - precision: 0.8287 - recall: 0.8777 - AUC: 0.8090 - AUPR: 0.8005 - val_loss: 0.4588 - val_accuracy: 0.7888 - val_precision: 0.8202 - val_recall: 0.8449 - val_AUC: 0.6862 - val_AUPR: 0.7262\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3910 - accuracy: 0.8182 - precision: 0.8342 - recall: 0.8731 - AUC: 0.8138 - AUPR: 0.8022 - val_loss: 0.4586 - val_accuracy: 0.7897 - val_precision: 0.8181 - val_recall: 0.8502 - val_AUC: 0.6898 - val_AUPR: 0.7276\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3874 - accuracy: 0.8219 - precision: 0.8371 - recall: 0.8759 - AUC: 0.8166 - AUPR: 0.8026 - val_loss: 0.4599 - val_accuracy: 0.7886 - val_precision: 0.8255 - val_recall: 0.8360 - val_AUC: 0.6903 - val_AUPR: 0.7285\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3791 - accuracy: 0.8260 - precision: 0.8453 - recall: 0.8718 - AUC: 0.8288 - AUPR: 0.8172 - val_loss: 0.4589 - val_accuracy: 0.7883 - val_precision: 0.8189 - val_recall: 0.8460 - val_AUC: 0.6905 - val_AUPR: 0.7287\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3767 - accuracy: 0.8253 - precision: 0.8402 - recall: 0.8783 - AUC: 0.8300 - AUPR: 0.8145 - val_loss: 0.4592 - val_accuracy: 0.7899 - val_precision: 0.8172 - val_recall: 0.8522 - val_AUC: 0.6898 - val_AUPR: 0.7282\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3758 - accuracy: 0.8279 - precision: 0.8437 - recall: 0.8781 - AUC: 0.8320 - AUPR: 0.8150 - val_loss: 0.4600 - val_accuracy: 0.7895 - val_precision: 0.8189 - val_recall: 0.8485 - val_AUC: 0.6899 - val_AUPR: 0.7281\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3703 - accuracy: 0.8304 - precision: 0.8449 - recall: 0.8813 - AUC: 0.8350 - AUPR: 0.8171 - val_loss: 0.4614 - val_accuracy: 0.7878 - val_precision: 0.8196 - val_recall: 0.8440 - val_AUC: 0.6900 - val_AUPR: 0.7277\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3698 - accuracy: 0.8296 - precision: 0.8458 - recall: 0.8783 - AUC: 0.8392 - AUPR: 0.8186 - val_loss: 0.4620 - val_accuracy: 0.7877 - val_precision: 0.8191 - val_recall: 0.8446 - val_AUC: 0.6903 - val_AUPR: 0.7276\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3677 - accuracy: 0.8307 - precision: 0.8461 - recall: 0.8803 - AUC: 0.8397 - AUPR: 0.8223 - val_loss: 0.4625 - val_accuracy: 0.7877 - val_precision: 0.8209 - val_recall: 0.8416 - val_AUC: 0.6903 - val_AUPR: 0.7277\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.3650 - accuracy: 0.8335 - precision: 0.8482 - recall: 0.8827 - AUC: 0.8439 - AUPR: 0.8240 - val_loss: 0.4629 - val_accuracy: 0.7891 - val_precision: 0.8202 - val_recall: 0.8456 - val_AUC: 0.6902 - val_AUPR: 0.7276\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3651 - accuracy: 0.8318 - precision: 0.8455 - recall: 0.8832 - AUC: 0.8451 - AUPR: 0.8286 - val_loss: 0.4629 - val_accuracy: 0.7881 - val_precision: 0.8192 - val_recall: 0.8451 - val_AUC: 0.6897 - val_AUPR: 0.7277\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3669 - accuracy: 0.8317 - precision: 0.8473 - recall: 0.8804 - AUC: 0.8423 - AUPR: 0.8235 - val_loss: 0.4629 - val_accuracy: 0.7884 - val_precision: 0.8194 - val_recall: 0.8454 - val_AUC: 0.6901 - val_AUPR: 0.7274\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3614 - accuracy: 0.8338 - precision: 0.8467 - recall: 0.8854 - AUC: 0.8465 - AUPR: 0.8313 - val_loss: 0.4625 - val_accuracy: 0.7885 - val_precision: 0.8193 - val_recall: 0.8457 - val_AUC: 0.6914 - val_AUPR: 0.7276\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3671 - accuracy: 0.8311 - precision: 0.8443 - recall: 0.8837 - AUC: 0.8415 - AUPR: 0.8265 - val_loss: 0.4624 - val_accuracy: 0.7878 - val_precision: 0.8198 - val_recall: 0.8435 - val_AUC: 0.6916 - val_AUPR: 0.7277\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3652 - accuracy: 0.8324 - precision: 0.8483 - recall: 0.8805 - AUC: 0.8434 - AUPR: 0.8299 - val_loss: 0.4624 - val_accuracy: 0.7881 - val_precision: 0.8205 - val_recall: 0.8431 - val_AUC: 0.6916 - val_AUPR: 0.7277\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3627 - accuracy: 0.8336 - precision: 0.8497 - recall: 0.8807 - AUC: 0.8469 - AUPR: 0.8288 - val_loss: 0.4624 - val_accuracy: 0.7886 - val_precision: 0.8202 - val_recall: 0.8444 - val_AUC: 0.6916 - val_AUPR: 0.7278\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3613 - accuracy: 0.8341 - precision: 0.8489 - recall: 0.8829 - AUC: 0.8492 - AUPR: 0.8294 - val_loss: 0.4624 - val_accuracy: 0.7889 - val_precision: 0.8203 - val_recall: 0.8450 - val_AUC: 0.6918 - val_AUPR: 0.7278\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3633 - accuracy: 0.8357 - precision: 0.8500 - recall: 0.8845 - AUC: 0.8436 - AUPR: 0.8272 - val_loss: 0.4625 - val_accuracy: 0.7888 - val_precision: 0.8199 - val_recall: 0.8453 - val_AUC: 0.6917 - val_AUPR: 0.7280\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3626 - accuracy: 0.8342 - precision: 0.8494 - recall: 0.8823 - AUC: 0.8474 - AUPR: 0.8291 - val_loss: 0.4627 - val_accuracy: 0.7885 - val_precision: 0.8205 - val_recall: 0.8438 - val_AUC: 0.6916 - val_AUPR: 0.7278\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3580 - accuracy: 0.8350 - precision: 0.8504 - recall: 0.8825 - AUC: 0.8526 - AUPR: 0.8329 - val_loss: 0.4628 - val_accuracy: 0.7883 - val_precision: 0.8202 - val_recall: 0.8440 - val_AUC: 0.6917 - val_AUPR: 0.7281\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3584 - accuracy: 0.8347 - precision: 0.8492 - recall: 0.8837 - AUC: 0.8522 - AUPR: 0.8315 - val_loss: 0.4629 - val_accuracy: 0.7882 - val_precision: 0.8198 - val_recall: 0.8444 - val_AUC: 0.6919 - val_AUPR: 0.7282\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3578 - accuracy: 0.8362 - precision: 0.8517 - recall: 0.8829 - AUC: 0.8502 - AUPR: 0.8344 - val_loss: 0.4631 - val_accuracy: 0.7888 - val_precision: 0.8201 - val_recall: 0.8450 - val_AUC: 0.6920 - val_AUPR: 0.7281\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3595 - accuracy: 0.8352 - precision: 0.8504 - recall: 0.8829 - AUC: 0.8514 - AUPR: 0.8308 - val_loss: 0.4632 - val_accuracy: 0.7886 - val_precision: 0.8191 - val_recall: 0.8462 - val_AUC: 0.6920 - val_AUPR: 0.7282\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3564 - accuracy: 0.8371 - precision: 0.8503 - recall: 0.8868 - AUC: 0.8526 - AUPR: 0.8327 - val_loss: 0.4632 - val_accuracy: 0.7889 - val_precision: 0.8198 - val_recall: 0.8459 - val_AUC: 0.6920 - val_AUPR: 0.7281\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3596 - accuracy: 0.8344 - precision: 0.8496 - recall: 0.8824 - AUC: 0.8500 - AUPR: 0.8311 - val_loss: 0.4632 - val_accuracy: 0.7887 - val_precision: 0.8195 - val_recall: 0.8457 - val_AUC: 0.6920 - val_AUPR: 0.7280\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3593 - accuracy: 0.8354 - precision: 0.8471 - recall: 0.8881 - AUC: 0.8492 - AUPR: 0.8317 - val_loss: 0.4632 - val_accuracy: 0.7887 - val_precision: 0.8195 - val_recall: 0.8457 - val_AUC: 0.6920 - val_AUPR: 0.7280\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3593 - accuracy: 0.8359 - precision: 0.8508 - recall: 0.8836 - AUC: 0.8504 - AUPR: 0.8306 - val_loss: 0.4632 - val_accuracy: 0.7885 - val_precision: 0.8197 - val_recall: 0.8451 - val_AUC: 0.6920 - val_AUPR: 0.7280\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3598 - accuracy: 0.8347 - precision: 0.8487 - recall: 0.8845 - AUC: 0.8492 - AUPR: 0.8304 - val_loss: 0.4632 - val_accuracy: 0.7886 - val_precision: 0.8199 - val_recall: 0.8450 - val_AUC: 0.6919 - val_AUPR: 0.7281\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3610 - accuracy: 0.8332 - precision: 0.8465 - recall: 0.8845 - AUC: 0.8493 - AUPR: 0.8294 - val_loss: 0.4632 - val_accuracy: 0.7891 - val_precision: 0.8206 - val_recall: 0.8450 - val_AUC: 0.6919 - val_AUPR: 0.7281\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3603 - accuracy: 0.8350 - precision: 0.8479 - recall: 0.8863 - AUC: 0.8484 - AUPR: 0.8294 - val_loss: 0.4633 - val_accuracy: 0.7889 - val_precision: 0.8206 - val_recall: 0.8446 - val_AUC: 0.6918 - val_AUPR: 0.7281\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.3591 - accuracy: 0.8343 - precision: 0.8504 - recall: 0.8810 - AUC: 0.8512 - AUPR: 0.8306 - val_loss: 0.4633 - val_accuracy: 0.7890 - val_precision: 0.8207 - val_recall: 0.8446 - val_AUC: 0.6918 - val_AUPR: 0.7282\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3605 - accuracy: 0.8326 - precision: 0.8476 - recall: 0.8818 - AUC: 0.8487 - AUPR: 0.8324 - val_loss: 0.4633 - val_accuracy: 0.7890 - val_precision: 0.8207 - val_recall: 0.8446 - val_AUC: 0.6918 - val_AUPR: 0.7282\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3603 - accuracy: 0.8337 - precision: 0.8475 - recall: 0.8841 - AUC: 0.8506 - AUPR: 0.8293 - val_loss: 0.4634 - val_accuracy: 0.7890 - val_precision: 0.8207 - val_recall: 0.8446 - val_AUC: 0.6918 - val_AUPR: 0.7282\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00049: early stopping\n",
            "loss :  0.4581312835216522\n",
            "accuracy :  0.7899404764175415\n",
            "precision :  0.8116324543952942\n",
            "recall :  0.8614999055862427\n",
            "AUC :  0.6762320399284363\n",
            "AUPR :  0.7159745693206787\n",
            "\n",
            "***********fold-3***********\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 4s 125ms/step - loss: 0.5878 - accuracy: 0.7255 - precision: 0.7622 - recall: 0.7994 - AUC: 0.5569 - AUPR: 0.6459 - val_loss: 0.4961 - val_accuracy: 0.7698 - val_precision: 0.7960 - val_recall: 0.8376 - val_AUC: 0.6340 - val_AUPR: 0.6804\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.5211 - accuracy: 0.7494 - precision: 0.7777 - recall: 0.8224 - AUC: 0.5897 - AUPR: 0.6626 - val_loss: 0.4782 - val_accuracy: 0.7781 - val_precision: 0.7785 - val_recall: 0.8894 - val_AUC: 0.6526 - val_AUPR: 0.6898\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.4976 - accuracy: 0.7645 - precision: 0.7773 - recall: 0.8582 - AUC: 0.6221 - AUPR: 0.6803 - val_loss: 0.4758 - val_accuracy: 0.7806 - val_precision: 0.7875 - val_recall: 0.8773 - val_AUC: 0.6692 - val_AUPR: 0.7029\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4841 - accuracy: 0.7714 - precision: 0.7844 - recall: 0.8601 - AUC: 0.6528 - AUPR: 0.6965 - val_loss: 0.4682 - val_accuracy: 0.7831 - val_precision: 0.7858 - val_recall: 0.8861 - val_AUC: 0.6756 - val_AUPR: 0.7076\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4733 - accuracy: 0.7781 - precision: 0.7905 - recall: 0.8637 - AUC: 0.6753 - AUPR: 0.7089 - val_loss: 0.4685 - val_accuracy: 0.7836 - val_precision: 0.7925 - val_recall: 0.8745 - val_AUC: 0.6738 - val_AUPR: 0.7085\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.4631 - accuracy: 0.7813 - precision: 0.7926 - recall: 0.8666 - AUC: 0.6946 - AUPR: 0.7230 - val_loss: 0.4667 - val_accuracy: 0.7831 - val_precision: 0.7880 - val_recall: 0.8819 - val_AUC: 0.6744 - val_AUPR: 0.7075\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4554 - accuracy: 0.7839 - precision: 0.7967 - recall: 0.8650 - AUC: 0.7114 - AUPR: 0.7330 - val_loss: 0.4709 - val_accuracy: 0.7831 - val_precision: 0.8002 - val_recall: 0.8592 - val_AUC: 0.6772 - val_AUPR: 0.7110\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4513 - accuracy: 0.7881 - precision: 0.8011 - recall: 0.8661 - AUC: 0.7190 - AUPR: 0.7375 - val_loss: 0.4656 - val_accuracy: 0.7830 - val_precision: 0.7913 - val_recall: 0.8754 - val_AUC: 0.6769 - val_AUPR: 0.7118\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4446 - accuracy: 0.7912 - precision: 0.8028 - recall: 0.8700 - AUC: 0.7308 - AUPR: 0.7461 - val_loss: 0.4654 - val_accuracy: 0.7833 - val_precision: 0.7960 - val_recall: 0.8673 - val_AUC: 0.6773 - val_AUPR: 0.7131\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4390 - accuracy: 0.7930 - precision: 0.8107 - recall: 0.8600 - AUC: 0.7418 - AUPR: 0.7514 - val_loss: 0.4662 - val_accuracy: 0.7841 - val_precision: 0.7850 - val_recall: 0.8900 - val_AUC: 0.6811 - val_AUPR: 0.7144\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.4364 - accuracy: 0.7940 - precision: 0.8088 - recall: 0.8655 - AUC: 0.7453 - AUPR: 0.7569 - val_loss: 0.4635 - val_accuracy: 0.7846 - val_precision: 0.8009 - val_recall: 0.8613 - val_AUC: 0.6836 - val_AUPR: 0.7177\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4310 - accuracy: 0.7987 - precision: 0.8075 - recall: 0.8779 - AUC: 0.7571 - AUPR: 0.7583 - val_loss: 0.4630 - val_accuracy: 0.7865 - val_precision: 0.8024 - val_recall: 0.8626 - val_AUC: 0.6870 - val_AUPR: 0.7223\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4234 - accuracy: 0.8017 - precision: 0.8177 - recall: 0.8668 - AUC: 0.7649 - AUPR: 0.7690 - val_loss: 0.4632 - val_accuracy: 0.7854 - val_precision: 0.7936 - val_recall: 0.8763 - val_AUC: 0.6865 - val_AUPR: 0.7204\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4175 - accuracy: 0.8049 - precision: 0.8169 - recall: 0.8748 - AUC: 0.7721 - AUPR: 0.7754 - val_loss: 0.4623 - val_accuracy: 0.7859 - val_precision: 0.8105 - val_recall: 0.8473 - val_AUC: 0.6919 - val_AUPR: 0.7219\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4161 - accuracy: 0.8053 - precision: 0.8209 - recall: 0.8692 - AUC: 0.7770 - AUPR: 0.7789 - val_loss: 0.4616 - val_accuracy: 0.7841 - val_precision: 0.7955 - val_recall: 0.8700 - val_AUC: 0.6885 - val_AUPR: 0.7211\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4113 - accuracy: 0.8090 - precision: 0.8269 - recall: 0.8671 - AUC: 0.7831 - AUPR: 0.7813 - val_loss: 0.4629 - val_accuracy: 0.7847 - val_precision: 0.8015 - val_recall: 0.8604 - val_AUC: 0.6910 - val_AUPR: 0.7233\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4053 - accuracy: 0.8101 - precision: 0.8219 - recall: 0.8776 - AUC: 0.7925 - AUPR: 0.7857 - val_loss: 0.4621 - val_accuracy: 0.7838 - val_precision: 0.8062 - val_recall: 0.8502 - val_AUC: 0.6922 - val_AUPR: 0.7235\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4062 - accuracy: 0.8112 - precision: 0.8212 - recall: 0.8809 - AUC: 0.7894 - AUPR: 0.7878 - val_loss: 0.4624 - val_accuracy: 0.7809 - val_precision: 0.8053 - val_recall: 0.8454 - val_AUC: 0.6920 - val_AUPR: 0.7242\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.4015 - accuracy: 0.8136 - precision: 0.8270 - recall: 0.8764 - AUC: 0.7955 - AUPR: 0.7902 - val_loss: 0.4645 - val_accuracy: 0.7824 - val_precision: 0.8059 - val_recall: 0.8476 - val_AUC: 0.6890 - val_AUPR: 0.7230\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3941 - accuracy: 0.8169 - precision: 0.8328 - recall: 0.8741 - AUC: 0.8063 - AUPR: 0.7967 - val_loss: 0.4653 - val_accuracy: 0.7867 - val_precision: 0.7993 - val_recall: 0.8688 - val_AUC: 0.6912 - val_AUPR: 0.7235\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3870 - accuracy: 0.8220 - precision: 0.8374 - recall: 0.8773 - AUC: 0.8186 - AUPR: 0.8105 - val_loss: 0.4639 - val_accuracy: 0.7859 - val_precision: 0.8071 - val_recall: 0.8532 - val_AUC: 0.6949 - val_AUPR: 0.7258\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3868 - accuracy: 0.8214 - precision: 0.8345 - recall: 0.8805 - AUC: 0.8177 - AUPR: 0.8045 - val_loss: 0.4622 - val_accuracy: 0.7876 - val_precision: 0.8067 - val_recall: 0.8575 - val_AUC: 0.6968 - val_AUPR: 0.7279\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3819 - accuracy: 0.8222 - precision: 0.8318 - recall: 0.8865 - AUC: 0.8243 - AUPR: 0.8094 - val_loss: 0.4653 - val_accuracy: 0.7812 - val_precision: 0.8120 - val_recall: 0.8348 - val_AUC: 0.6962 - val_AUPR: 0.7283\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3806 - accuracy: 0.8232 - precision: 0.8451 - recall: 0.8682 - AUC: 0.8261 - AUPR: 0.8121 - val_loss: 0.4657 - val_accuracy: 0.7873 - val_precision: 0.7944 - val_recall: 0.8790 - val_AUC: 0.6985 - val_AUPR: 0.7299\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3743 - accuracy: 0.8262 - precision: 0.8362 - recall: 0.8878 - AUC: 0.8320 - AUPR: 0.8160 - val_loss: 0.4654 - val_accuracy: 0.7852 - val_precision: 0.8077 - val_recall: 0.8506 - val_AUC: 0.6953 - val_AUPR: 0.7278\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3723 - accuracy: 0.8261 - precision: 0.8414 - recall: 0.8795 - AUC: 0.8362 - AUPR: 0.8171 - val_loss: 0.4659 - val_accuracy: 0.7862 - val_precision: 0.8039 - val_recall: 0.8593 - val_AUC: 0.6944 - val_AUPR: 0.7275\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3664 - accuracy: 0.8316 - precision: 0.8470 - recall: 0.8821 - AUC: 0.8411 - AUPR: 0.8249 - val_loss: 0.4664 - val_accuracy: 0.7852 - val_precision: 0.8047 - val_recall: 0.8557 - val_AUC: 0.6946 - val_AUPR: 0.7273\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3669 - accuracy: 0.8299 - precision: 0.8428 - recall: 0.8851 - AUC: 0.8397 - AUPR: 0.8187 - val_loss: 0.4667 - val_accuracy: 0.7845 - val_precision: 0.8046 - val_recall: 0.8545 - val_AUC: 0.6956 - val_AUPR: 0.7280\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3673 - accuracy: 0.8306 - precision: 0.8428 - recall: 0.8864 - AUC: 0.8395 - AUPR: 0.8215 - val_loss: 0.4670 - val_accuracy: 0.7858 - val_precision: 0.8067 - val_recall: 0.8536 - val_AUC: 0.6957 - val_AUPR: 0.7274\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3639 - accuracy: 0.8329 - precision: 0.8493 - recall: 0.8812 - AUC: 0.8419 - AUPR: 0.8250 - val_loss: 0.4670 - val_accuracy: 0.7866 - val_precision: 0.8077 - val_recall: 0.8535 - val_AUC: 0.6965 - val_AUPR: 0.7275\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.3607 - accuracy: 0.8340 - precision: 0.8463 - recall: 0.8880 - AUC: 0.8467 - AUPR: 0.8266 - val_loss: 0.4677 - val_accuracy: 0.7865 - val_precision: 0.8075 - val_recall: 0.8536 - val_AUC: 0.6970 - val_AUPR: 0.7283\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3611 - accuracy: 0.8336 - precision: 0.8483 - recall: 0.8840 - AUC: 0.8469 - AUPR: 0.8368 - val_loss: 0.4676 - val_accuracy: 0.7853 - val_precision: 0.8069 - val_recall: 0.8521 - val_AUC: 0.6972 - val_AUPR: 0.7283\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3605 - accuracy: 0.8334 - precision: 0.8490 - recall: 0.8827 - AUC: 0.8491 - AUPR: 0.8305 - val_loss: 0.4680 - val_accuracy: 0.7856 - val_precision: 0.8080 - val_recall: 0.8511 - val_AUC: 0.6970 - val_AUPR: 0.7282\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3591 - accuracy: 0.8334 - precision: 0.8486 - recall: 0.8833 - AUC: 0.8490 - AUPR: 0.8283 - val_loss: 0.4692 - val_accuracy: 0.7855 - val_precision: 0.8065 - val_recall: 0.8533 - val_AUC: 0.6968 - val_AUPR: 0.7281\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3593 - accuracy: 0.8332 - precision: 0.8480 - recall: 0.8837 - AUC: 0.8488 - AUPR: 0.8286 - val_loss: 0.4698 - val_accuracy: 0.7848 - val_precision: 0.8063 - val_recall: 0.8523 - val_AUC: 0.6948 - val_AUPR: 0.7275\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3581 - accuracy: 0.8353 - precision: 0.8506 - recall: 0.8842 - AUC: 0.8489 - AUPR: 0.8294 - val_loss: 0.4699 - val_accuracy: 0.7845 - val_precision: 0.8060 - val_recall: 0.8520 - val_AUC: 0.6948 - val_AUPR: 0.7275\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3595 - accuracy: 0.8348 - precision: 0.8505 - recall: 0.8834 - AUC: 0.8484 - AUPR: 0.8296 - val_loss: 0.4700 - val_accuracy: 0.7849 - val_precision: 0.8060 - val_recall: 0.8529 - val_AUC: 0.6952 - val_AUPR: 0.7276\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3587 - accuracy: 0.8353 - precision: 0.8497 - recall: 0.8854 - AUC: 0.8505 - AUPR: 0.8313 - val_loss: 0.4697 - val_accuracy: 0.7849 - val_precision: 0.8066 - val_recall: 0.8518 - val_AUC: 0.6954 - val_AUPR: 0.7276\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3567 - accuracy: 0.8358 - precision: 0.8492 - recall: 0.8871 - AUC: 0.8514 - AUPR: 0.8369 - val_loss: 0.4696 - val_accuracy: 0.7849 - val_precision: 0.8063 - val_recall: 0.8524 - val_AUC: 0.6959 - val_AUPR: 0.7280\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3574 - accuracy: 0.8373 - precision: 0.8520 - recall: 0.8861 - AUC: 0.8496 - AUPR: 0.8286 - val_loss: 0.4696 - val_accuracy: 0.7850 - val_precision: 0.8064 - val_recall: 0.8524 - val_AUC: 0.6964 - val_AUPR: 0.7285\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3577 - accuracy: 0.8357 - precision: 0.8509 - recall: 0.8845 - AUC: 0.8504 - AUPR: 0.8321 - val_loss: 0.4695 - val_accuracy: 0.7853 - val_precision: 0.8072 - val_recall: 0.8517 - val_AUC: 0.6968 - val_AUPR: 0.7287\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3590 - accuracy: 0.8331 - precision: 0.8465 - recall: 0.8859 - AUC: 0.8489 - AUPR: 0.8276 - val_loss: 0.4693 - val_accuracy: 0.7856 - val_precision: 0.8075 - val_recall: 0.8520 - val_AUC: 0.6971 - val_AUPR: 0.7288\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3556 - accuracy: 0.8363 - precision: 0.8520 - recall: 0.8839 - AUC: 0.8536 - AUPR: 0.8345 - val_loss: 0.4694 - val_accuracy: 0.7856 - val_precision: 0.8077 - val_recall: 0.8514 - val_AUC: 0.6970 - val_AUPR: 0.7289\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3574 - accuracy: 0.8360 - precision: 0.8525 - recall: 0.8828 - AUC: 0.8504 - AUPR: 0.8332 - val_loss: 0.4696 - val_accuracy: 0.7857 - val_precision: 0.8077 - val_recall: 0.8518 - val_AUC: 0.6970 - val_AUPR: 0.7289\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.3511 - accuracy: 0.8382 - precision: 0.8527 - recall: 0.8869 - AUC: 0.8589 - AUPR: 0.8368 - val_loss: 0.4697 - val_accuracy: 0.7851 - val_precision: 0.8071 - val_recall: 0.8514 - val_AUC: 0.6971 - val_AUPR: 0.7291\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3547 - accuracy: 0.8361 - precision: 0.8505 - recall: 0.8860 - AUC: 0.8535 - AUPR: 0.8325 - val_loss: 0.4697 - val_accuracy: 0.7852 - val_precision: 0.8072 - val_recall: 0.8514 - val_AUC: 0.6972 - val_AUPR: 0.7291\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3575 - accuracy: 0.8361 - precision: 0.8516 - recall: 0.8842 - AUC: 0.8512 - AUPR: 0.8352 - val_loss: 0.4698 - val_accuracy: 0.7854 - val_precision: 0.8073 - val_recall: 0.8517 - val_AUC: 0.6972 - val_AUPR: 0.7291\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3552 - accuracy: 0.8363 - precision: 0.8493 - recall: 0.8881 - AUC: 0.8540 - AUPR: 0.8318 - val_loss: 0.4698 - val_accuracy: 0.7851 - val_precision: 0.8071 - val_recall: 0.8514 - val_AUC: 0.6971 - val_AUPR: 0.7291\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3522 - accuracy: 0.8379 - precision: 0.8532 - recall: 0.8855 - AUC: 0.8581 - AUPR: 0.8340 - val_loss: 0.4698 - val_accuracy: 0.7853 - val_precision: 0.8073 - val_recall: 0.8515 - val_AUC: 0.6971 - val_AUPR: 0.7291\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.3536 - accuracy: 0.8381 - precision: 0.8524 - recall: 0.8871 - AUC: 0.8532 - AUPR: 0.8316 - val_loss: 0.4697 - val_accuracy: 0.7854 - val_precision: 0.8073 - val_recall: 0.8517 - val_AUC: 0.6971 - val_AUPR: 0.7290\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3507 - accuracy: 0.8388 - precision: 0.8527 - recall: 0.8879 - AUC: 0.8581 - AUPR: 0.8395 - val_loss: 0.4697 - val_accuracy: 0.7851 - val_precision: 0.8072 - val_recall: 0.8512 - val_AUC: 0.6970 - val_AUPR: 0.7290\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3552 - accuracy: 0.8367 - precision: 0.8518 - recall: 0.8850 - AUC: 0.8516 - AUPR: 0.8325 - val_loss: 0.4697 - val_accuracy: 0.7852 - val_precision: 0.8072 - val_recall: 0.8514 - val_AUC: 0.6971 - val_AUPR: 0.7290\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3564 - accuracy: 0.8357 - precision: 0.8499 - recall: 0.8860 - AUC: 0.8512 - AUPR: 0.8319 - val_loss: 0.4697 - val_accuracy: 0.7849 - val_precision: 0.8072 - val_recall: 0.8509 - val_AUC: 0.6972 - val_AUPR: 0.7291\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3513 - accuracy: 0.8386 - precision: 0.8530 - recall: 0.8871 - AUC: 0.8569 - AUPR: 0.8355 - val_loss: 0.4696 - val_accuracy: 0.7853 - val_precision: 0.8073 - val_recall: 0.8515 - val_AUC: 0.6972 - val_AUPR: 0.7291\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3571 - accuracy: 0.8349 - precision: 0.8495 - recall: 0.8849 - AUC: 0.8523 - AUPR: 0.8328 - val_loss: 0.4696 - val_accuracy: 0.7852 - val_precision: 0.8072 - val_recall: 0.8514 - val_AUC: 0.6973 - val_AUPR: 0.7292\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00055: early stopping\n",
            "loss :  0.46161407232284546\n",
            "accuracy :  0.7840877771377563\n",
            "precision :  0.7954794764518738\n",
            "recall :  0.8699625730514526\n",
            "AUC :  0.688534140586853\n",
            "AUPR :  0.7210699915885925\n",
            "\n",
            "***********fold-4***********\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 128ms/step - loss: 0.5844 - accuracy: 0.7252 - precision: 0.7622 - recall: 0.7974 - AUC: 0.5612 - AUPR: 0.6482 - val_loss: 0.5090 - val_accuracy: 0.7586 - val_precision: 0.7690 - val_recall: 0.8605 - val_AUC: 0.5986 - val_AUPR: 0.6594\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.5172 - accuracy: 0.7556 - precision: 0.7726 - recall: 0.8477 - AUC: 0.5930 - AUPR: 0.6624 - val_loss: 0.4983 - val_accuracy: 0.7601 - val_precision: 0.7733 - val_recall: 0.8552 - val_AUC: 0.6219 - val_AUPR: 0.6753\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4951 - accuracy: 0.7635 - precision: 0.7794 - recall: 0.8525 - AUC: 0.6226 - AUPR: 0.6813 - val_loss: 0.4943 - val_accuracy: 0.7647 - val_precision: 0.7707 - val_recall: 0.8712 - val_AUC: 0.6306 - val_AUPR: 0.6811\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4785 - accuracy: 0.7728 - precision: 0.7883 - recall: 0.8565 - AUC: 0.6554 - AUPR: 0.6996 - val_loss: 0.4921 - val_accuracy: 0.7671 - val_precision: 0.7773 - val_recall: 0.8635 - val_AUC: 0.6352 - val_AUPR: 0.6850\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4659 - accuracy: 0.7791 - precision: 0.7962 - recall: 0.8561 - AUC: 0.6818 - AUPR: 0.7157 - val_loss: 0.4916 - val_accuracy: 0.7701 - val_precision: 0.7747 - val_recall: 0.8756 - val_AUC: 0.6369 - val_AUPR: 0.6882\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4600 - accuracy: 0.7853 - precision: 0.7972 - recall: 0.8677 - AUC: 0.6921 - AUPR: 0.7231 - val_loss: 0.4914 - val_accuracy: 0.7685 - val_precision: 0.7815 - val_recall: 0.8584 - val_AUC: 0.6418 - val_AUPR: 0.6909\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4508 - accuracy: 0.7868 - precision: 0.7985 - recall: 0.8690 - AUC: 0.7130 - AUPR: 0.7337 - val_loss: 0.4903 - val_accuracy: 0.7693 - val_precision: 0.7794 - val_recall: 0.8641 - val_AUC: 0.6463 - val_AUPR: 0.6913\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4459 - accuracy: 0.7897 - precision: 0.8076 - recall: 0.8590 - AUC: 0.7237 - AUPR: 0.7360 - val_loss: 0.4903 - val_accuracy: 0.7702 - val_precision: 0.7790 - val_recall: 0.8670 - val_AUC: 0.6495 - val_AUPR: 0.6932\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4372 - accuracy: 0.7957 - precision: 0.8096 - recall: 0.8685 - AUC: 0.7356 - AUPR: 0.7514 - val_loss: 0.4888 - val_accuracy: 0.7698 - val_precision: 0.7821 - val_recall: 0.8602 - val_AUC: 0.6548 - val_AUPR: 0.6956\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4333 - accuracy: 0.7952 - precision: 0.8060 - recall: 0.8737 - AUC: 0.7447 - AUPR: 0.7536 - val_loss: 0.4908 - val_accuracy: 0.7706 - val_precision: 0.7863 - val_recall: 0.8540 - val_AUC: 0.6565 - val_AUPR: 0.6951\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4278 - accuracy: 0.7991 - precision: 0.8220 - recall: 0.8549 - AUC: 0.7554 - AUPR: 0.7631 - val_loss: 0.4947 - val_accuracy: 0.7682 - val_precision: 0.7721 - val_recall: 0.8767 - val_AUC: 0.6546 - val_AUPR: 0.6955\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4203 - accuracy: 0.8018 - precision: 0.8136 - recall: 0.8746 - AUC: 0.7662 - AUPR: 0.7678 - val_loss: 0.4914 - val_accuracy: 0.7693 - val_precision: 0.7913 - val_recall: 0.8414 - val_AUC: 0.6560 - val_AUPR: 0.6971\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4173 - accuracy: 0.8035 - precision: 0.8161 - recall: 0.8740 - AUC: 0.7713 - AUPR: 0.7732 - val_loss: 0.4938 - val_accuracy: 0.7720 - val_precision: 0.7839 - val_recall: 0.8615 - val_AUC: 0.6589 - val_AUPR: 0.6964\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.4140 - accuracy: 0.8060 - precision: 0.8282 - recall: 0.8594 - AUC: 0.7785 - AUPR: 0.7756 - val_loss: 0.4940 - val_accuracy: 0.7718 - val_precision: 0.7742 - val_recall: 0.8806 - val_AUC: 0.6608 - val_AUPR: 0.6994\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4117 - accuracy: 0.8079 - precision: 0.8166 - recall: 0.8826 - AUC: 0.7800 - AUPR: 0.7810 - val_loss: 0.4929 - val_accuracy: 0.7682 - val_precision: 0.7971 - val_recall: 0.8289 - val_AUC: 0.6640 - val_AUPR: 0.7001\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4066 - accuracy: 0.8107 - precision: 0.8289 - recall: 0.8681 - AUC: 0.7876 - AUPR: 0.7860 - val_loss: 0.4958 - val_accuracy: 0.7701 - val_precision: 0.7815 - val_recall: 0.8619 - val_AUC: 0.6630 - val_AUPR: 0.6988\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3999 - accuracy: 0.8136 - precision: 0.8291 - recall: 0.8737 - AUC: 0.8015 - AUPR: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7693 - val_precision: 0.7833 - val_recall: 0.8567 - val_AUC: 0.6637 - val_AUPR: 0.7007\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3963 - accuracy: 0.8164 - precision: 0.8239 - recall: 0.8880 - AUC: 0.8031 - AUPR: 0.7946 - val_loss: 0.4952 - val_accuracy: 0.7645 - val_precision: 0.7933 - val_recall: 0.8272 - val_AUC: 0.6638 - val_AUPR: 0.7011\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3879 - accuracy: 0.8209 - precision: 0.8393 - recall: 0.8726 - AUC: 0.8121 - AUPR: 0.8005 - val_loss: 0.5003 - val_accuracy: 0.7692 - val_precision: 0.7818 - val_recall: 0.8591 - val_AUC: 0.6644 - val_AUPR: 0.6998\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3862 - accuracy: 0.8199 - precision: 0.8296 - recall: 0.8860 - AUC: 0.8151 - AUPR: 0.8041 - val_loss: 0.4983 - val_accuracy: 0.7662 - val_precision: 0.7866 - val_recall: 0.8434 - val_AUC: 0.6655 - val_AUPR: 0.7006\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3842 - accuracy: 0.8228 - precision: 0.8384 - recall: 0.8779 - AUC: 0.8161 - AUPR: 0.8055 - val_loss: 0.4975 - val_accuracy: 0.7668 - val_precision: 0.7868 - val_recall: 0.8443 - val_AUC: 0.6658 - val_AUPR: 0.7012\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3789 - accuracy: 0.8235 - precision: 0.8380 - recall: 0.8800 - AUC: 0.8230 - AUPR: 0.8106 - val_loss: 0.4988 - val_accuracy: 0.7671 - val_precision: 0.7850 - val_recall: 0.8485 - val_AUC: 0.6645 - val_AUPR: 0.7014\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3789 - accuracy: 0.8235 - precision: 0.8370 - recall: 0.8816 - AUC: 0.8240 - AUPR: 0.8104 - val_loss: 0.5000 - val_accuracy: 0.7682 - val_precision: 0.7860 - val_recall: 0.8489 - val_AUC: 0.6640 - val_AUPR: 0.7015\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3760 - accuracy: 0.8258 - precision: 0.8410 - recall: 0.8800 - AUC: 0.8295 - AUPR: 0.8153 - val_loss: 0.4997 - val_accuracy: 0.7671 - val_precision: 0.7855 - val_recall: 0.8475 - val_AUC: 0.6649 - val_AUPR: 0.7017\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3791 - accuracy: 0.8248 - precision: 0.8411 - recall: 0.8779 - AUC: 0.8255 - AUPR: 0.8091 - val_loss: 0.4995 - val_accuracy: 0.7682 - val_precision: 0.7862 - val_recall: 0.8485 - val_AUC: 0.6655 - val_AUPR: 0.7022\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3729 - accuracy: 0.8277 - precision: 0.8421 - recall: 0.8823 - AUC: 0.8322 - AUPR: 0.8168 - val_loss: 0.4988 - val_accuracy: 0.7669 - val_precision: 0.7867 - val_recall: 0.8446 - val_AUC: 0.6657 - val_AUPR: 0.7030\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3729 - accuracy: 0.8282 - precision: 0.8446 - recall: 0.8795 - AUC: 0.8297 - AUPR: 0.8150 - val_loss: 0.5000 - val_accuracy: 0.7671 - val_precision: 0.7855 - val_recall: 0.8475 - val_AUC: 0.6657 - val_AUPR: 0.7033\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3725 - accuracy: 0.8283 - precision: 0.8398 - recall: 0.8869 - AUC: 0.8303 - AUPR: 0.8173 - val_loss: 0.5011 - val_accuracy: 0.7667 - val_precision: 0.7838 - val_recall: 0.8498 - val_AUC: 0.6649 - val_AUPR: 0.7031\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3721 - accuracy: 0.8291 - precision: 0.8413 - recall: 0.8863 - AUC: 0.8313 - AUPR: 0.8180 - val_loss: 0.5010 - val_accuracy: 0.7668 - val_precision: 0.7878 - val_recall: 0.8424 - val_AUC: 0.6656 - val_AUPR: 0.7030\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3752 - accuracy: 0.8266 - precision: 0.8418 - recall: 0.8805 - AUC: 0.8258 - AUPR: 0.8145 - val_loss: 0.5009 - val_accuracy: 0.7668 - val_precision: 0.7884 - val_recall: 0.8413 - val_AUC: 0.6655 - val_AUPR: 0.7032\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3733 - accuracy: 0.8280 - precision: 0.8463 - recall: 0.8765 - AUC: 0.8312 - AUPR: 0.8133 - val_loss: 0.5010 - val_accuracy: 0.7669 - val_precision: 0.7879 - val_recall: 0.8424 - val_AUC: 0.6654 - val_AUPR: 0.7034\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3724 - accuracy: 0.8278 - precision: 0.8419 - recall: 0.8826 - AUC: 0.8327 - AUPR: 0.8169 - val_loss: 0.5011 - val_accuracy: 0.7669 - val_precision: 0.7878 - val_recall: 0.8425 - val_AUC: 0.6658 - val_AUPR: 0.7037\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3692 - accuracy: 0.8297 - precision: 0.8444 - recall: 0.8826 - AUC: 0.8355 - AUPR: 0.8203 - val_loss: 0.5011 - val_accuracy: 0.7674 - val_precision: 0.7884 - val_recall: 0.8428 - val_AUC: 0.6655 - val_AUPR: 0.7036\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3740 - accuracy: 0.8257 - precision: 0.8406 - recall: 0.8805 - AUC: 0.8305 - AUPR: 0.8170 - val_loss: 0.5012 - val_accuracy: 0.7676 - val_precision: 0.7884 - val_recall: 0.8431 - val_AUC: 0.6656 - val_AUPR: 0.7036\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3699 - accuracy: 0.8305 - precision: 0.8462 - recall: 0.8817 - AUC: 0.8355 - AUPR: 0.8195 - val_loss: 0.5013 - val_accuracy: 0.7675 - val_precision: 0.7881 - val_recall: 0.8436 - val_AUC: 0.6658 - val_AUPR: 0.7033\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.3695 - accuracy: 0.8299 - precision: 0.8428 - recall: 0.8857 - AUC: 0.8351 - AUPR: 0.8177 - val_loss: 0.5012 - val_accuracy: 0.7682 - val_precision: 0.7885 - val_recall: 0.8442 - val_AUC: 0.6657 - val_AUPR: 0.7032\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3672 - accuracy: 0.8318 - precision: 0.8477 - recall: 0.8820 - AUC: 0.8385 - AUPR: 0.8245 - val_loss: 0.5015 - val_accuracy: 0.7672 - val_precision: 0.7867 - val_recall: 0.8455 - val_AUC: 0.6658 - val_AUPR: 0.7031\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3740 - accuracy: 0.8262 - precision: 0.8426 - recall: 0.8785 - AUC: 0.8315 - AUPR: 0.8161 - val_loss: 0.5016 - val_accuracy: 0.7678 - val_precision: 0.7875 - val_recall: 0.8452 - val_AUC: 0.6659 - val_AUPR: 0.7033\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3683 - accuracy: 0.8292 - precision: 0.8445 - recall: 0.8815 - AUC: 0.8385 - AUPR: 0.8189 - val_loss: 0.5019 - val_accuracy: 0.7680 - val_precision: 0.7867 - val_recall: 0.8472 - val_AUC: 0.6659 - val_AUPR: 0.7033\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.3697 - accuracy: 0.8283 - precision: 0.8428 - recall: 0.8823 - AUC: 0.8348 - AUPR: 0.8211 - val_loss: 0.5020 - val_accuracy: 0.7681 - val_precision: 0.7866 - val_recall: 0.8475 - val_AUC: 0.6659 - val_AUPR: 0.7033\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3680 - accuracy: 0.8280 - precision: 0.8441 - recall: 0.8799 - AUC: 0.8353 - AUPR: 0.8193 - val_loss: 0.5020 - val_accuracy: 0.7682 - val_precision: 0.7868 - val_recall: 0.8476 - val_AUC: 0.6659 - val_AUPR: 0.7032\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3697 - accuracy: 0.8267 - precision: 0.8405 - recall: 0.8827 - AUC: 0.8346 - AUPR: 0.8236 - val_loss: 0.5020 - val_accuracy: 0.7680 - val_precision: 0.7867 - val_recall: 0.8472 - val_AUC: 0.6660 - val_AUPR: 0.7033\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.3719 - accuracy: 0.8260 - precision: 0.8409 - recall: 0.8806 - AUC: 0.8332 - AUPR: 0.8225 - val_loss: 0.5019 - val_accuracy: 0.7676 - val_precision: 0.7864 - val_recall: 0.8469 - val_AUC: 0.6658 - val_AUPR: 0.7032\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3700 - accuracy: 0.8276 - precision: 0.8401 - recall: 0.8850 - AUC: 0.8343 - AUPR: 0.8197 - val_loss: 0.5020 - val_accuracy: 0.7679 - val_precision: 0.7867 - val_recall: 0.8469 - val_AUC: 0.6659 - val_AUPR: 0.7032\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3687 - accuracy: 0.8275 - precision: 0.8422 - recall: 0.8818 - AUC: 0.8382 - AUPR: 0.8176 - val_loss: 0.5020 - val_accuracy: 0.7675 - val_precision: 0.7867 - val_recall: 0.8461 - val_AUC: 0.6660 - val_AUPR: 0.7033\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3679 - accuracy: 0.8310 - precision: 0.8437 - recall: 0.8864 - AUC: 0.8353 - AUPR: 0.8220 - val_loss: 0.5019 - val_accuracy: 0.7677 - val_precision: 0.7872 - val_recall: 0.8455 - val_AUC: 0.6661 - val_AUPR: 0.7034\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3682 - accuracy: 0.8297 - precision: 0.8431 - recall: 0.8847 - AUC: 0.8356 - AUPR: 0.8190 - val_loss: 0.5018 - val_accuracy: 0.7678 - val_precision: 0.7879 - val_recall: 0.8445 - val_AUC: 0.6662 - val_AUPR: 0.7034\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3674 - accuracy: 0.8297 - precision: 0.8447 - recall: 0.8824 - AUC: 0.8365 - AUPR: 0.8235 - val_loss: 0.5018 - val_accuracy: 0.7676 - val_precision: 0.7878 - val_recall: 0.8442 - val_AUC: 0.6662 - val_AUPR: 0.7033\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.3686 - accuracy: 0.8288 - precision: 0.8443 - recall: 0.8811 - AUC: 0.8370 - AUPR: 0.8188 - val_loss: 0.5018 - val_accuracy: 0.7677 - val_precision: 0.7879 - val_recall: 0.8443 - val_AUC: 0.6663 - val_AUPR: 0.7034\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00049: early stopping\n",
            "loss :  0.4887693524360657\n",
            "accuracy :  0.7698019742965698\n",
            "precision :  0.7820530533790588\n",
            "recall :  0.8601874113082886\n",
            "AUC :  0.6548100709915161\n",
            "AUPR :  0.6955689191818237\n",
            "\n",
            "***********fold-5***********\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 4s 130ms/step - loss: 0.5961 - accuracy: 0.7139 - precision: 0.7508 - recall: 0.7910 - AUC: 0.5501 - AUPR: 0.6372 - val_loss: 0.4852 - val_accuracy: 0.7714 - val_precision: 0.7874 - val_recall: 0.8588 - val_AUC: 0.6229 - val_AUPR: 0.6835\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.5244 - accuracy: 0.7468 - precision: 0.7698 - recall: 0.8314 - AUC: 0.5821 - AUPR: 0.6550 - val_loss: 0.4828 - val_accuracy: 0.7726 - val_precision: 0.7854 - val_recall: 0.8654 - val_AUC: 0.6389 - val_AUPR: 0.6949\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4990 - accuracy: 0.7612 - precision: 0.7799 - recall: 0.8450 - AUC: 0.6230 - AUPR: 0.6771 - val_loss: 0.4752 - val_accuracy: 0.7764 - val_precision: 0.7845 - val_recall: 0.8757 - val_AUC: 0.6512 - val_AUPR: 0.6994\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4867 - accuracy: 0.7687 - precision: 0.7793 - recall: 0.8633 - AUC: 0.6439 - AUPR: 0.6912 - val_loss: 0.4756 - val_accuracy: 0.7772 - val_precision: 0.7932 - val_recall: 0.8609 - val_AUC: 0.6559 - val_AUPR: 0.7026\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4751 - accuracy: 0.7737 - precision: 0.7920 - recall: 0.8506 - AUC: 0.6741 - AUPR: 0.7058 - val_loss: 0.4686 - val_accuracy: 0.7814 - val_precision: 0.7909 - val_recall: 0.8743 - val_AUC: 0.6624 - val_AUPR: 0.7057\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4656 - accuracy: 0.7818 - precision: 0.7931 - recall: 0.8666 - AUC: 0.6890 - AUPR: 0.7176 - val_loss: 0.4672 - val_accuracy: 0.7806 - val_precision: 0.7935 - val_recall: 0.8679 - val_AUC: 0.6683 - val_AUPR: 0.7114\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4581 - accuracy: 0.7838 - precision: 0.7959 - recall: 0.8657 - AUC: 0.7042 - AUPR: 0.7263 - val_loss: 0.4640 - val_accuracy: 0.7818 - val_precision: 0.7946 - val_recall: 0.8685 - val_AUC: 0.6740 - val_AUPR: 0.7146\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.4505 - accuracy: 0.7872 - precision: 0.7977 - recall: 0.8699 - AUC: 0.7214 - AUPR: 0.7374 - val_loss: 0.4651 - val_accuracy: 0.7804 - val_precision: 0.7980 - val_recall: 0.8592 - val_AUC: 0.6739 - val_AUPR: 0.7139\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4425 - accuracy: 0.7894 - precision: 0.8033 - recall: 0.8648 - AUC: 0.7356 - AUPR: 0.7463 - val_loss: 0.4655 - val_accuracy: 0.7812 - val_precision: 0.8000 - val_recall: 0.8571 - val_AUC: 0.6759 - val_AUPR: 0.7138\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.4340 - accuracy: 0.7955 - precision: 0.8083 - recall: 0.8692 - AUC: 0.7489 - AUPR: 0.7569 - val_loss: 0.4625 - val_accuracy: 0.7826 - val_precision: 0.8008 - val_recall: 0.8589 - val_AUC: 0.6823 - val_AUPR: 0.7181\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4293 - accuracy: 0.7980 - precision: 0.8145 - recall: 0.8640 - AUC: 0.7555 - AUPR: 0.7614 - val_loss: 0.4640 - val_accuracy: 0.7808 - val_precision: 0.7993 - val_recall: 0.8576 - val_AUC: 0.6817 - val_AUPR: 0.7175\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4277 - accuracy: 0.7981 - precision: 0.8083 - recall: 0.8748 - AUC: 0.7604 - AUPR: 0.7659 - val_loss: 0.4623 - val_accuracy: 0.7853 - val_precision: 0.8086 - val_recall: 0.8511 - val_AUC: 0.6863 - val_AUPR: 0.7192\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.4178 - accuracy: 0.8059 - precision: 0.8186 - recall: 0.8738 - AUC: 0.7745 - AUPR: 0.7783 - val_loss: 0.4612 - val_accuracy: 0.7847 - val_precision: 0.8106 - val_recall: 0.8465 - val_AUC: 0.6917 - val_AUPR: 0.7227\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4176 - accuracy: 0.8040 - precision: 0.8163 - recall: 0.8737 - AUC: 0.7779 - AUPR: 0.7757 - val_loss: 0.4627 - val_accuracy: 0.7818 - val_precision: 0.8122 - val_recall: 0.8375 - val_AUC: 0.6919 - val_AUPR: 0.7214\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.4098 - accuracy: 0.8091 - precision: 0.8235 - recall: 0.8724 - AUC: 0.7869 - AUPR: 0.7809 - val_loss: 0.4623 - val_accuracy: 0.7873 - val_precision: 0.8073 - val_recall: 0.8576 - val_AUC: 0.6905 - val_AUPR: 0.7196\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.4040 - accuracy: 0.8134 - precision: 0.8239 - recall: 0.8807 - AUC: 0.7948 - AUPR: 0.7875 - val_loss: 0.4619 - val_accuracy: 0.7842 - val_precision: 0.8112 - val_recall: 0.8444 - val_AUC: 0.6947 - val_AUPR: 0.7211\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 55ms/step - loss: 0.4013 - accuracy: 0.8129 - precision: 0.8293 - recall: 0.8710 - AUC: 0.7984 - AUPR: 0.7926 - val_loss: 0.4616 - val_accuracy: 0.7851 - val_precision: 0.8103 - val_recall: 0.8478 - val_AUC: 0.6962 - val_AUPR: 0.7216\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3943 - accuracy: 0.8172 - precision: 0.8304 - recall: 0.8782 - AUC: 0.8066 - AUPR: 0.8032 - val_loss: 0.4599 - val_accuracy: 0.7897 - val_precision: 0.8085 - val_recall: 0.8607 - val_AUC: 0.6990 - val_AUPR: 0.7238\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3899 - accuracy: 0.8204 - precision: 0.8347 - recall: 0.8780 - AUC: 0.8131 - AUPR: 0.8002 - val_loss: 0.4605 - val_accuracy: 0.7878 - val_precision: 0.8109 - val_recall: 0.8525 - val_AUC: 0.7013 - val_AUPR: 0.7231\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3898 - accuracy: 0.8195 - precision: 0.8300 - recall: 0.8836 - AUC: 0.8128 - AUPR: 0.8024 - val_loss: 0.4619 - val_accuracy: 0.7874 - val_precision: 0.8242 - val_recall: 0.8300 - val_AUC: 0.7045 - val_AUPR: 0.7264\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3867 - accuracy: 0.8202 - precision: 0.8382 - recall: 0.8720 - AUC: 0.8166 - AUPR: 0.8065 - val_loss: 0.4608 - val_accuracy: 0.7869 - val_precision: 0.8149 - val_recall: 0.8438 - val_AUC: 0.7031 - val_AUPR: 0.7244\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3780 - accuracy: 0.8249 - precision: 0.8400 - recall: 0.8789 - AUC: 0.8263 - AUPR: 0.8143 - val_loss: 0.4635 - val_accuracy: 0.7842 - val_precision: 0.8205 - val_recall: 0.8293 - val_AUC: 0.7007 - val_AUPR: 0.7251\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3769 - accuracy: 0.8247 - precision: 0.8420 - recall: 0.8753 - AUC: 0.8311 - AUPR: 0.8185 - val_loss: 0.4609 - val_accuracy: 0.7884 - val_precision: 0.8106 - val_recall: 0.8543 - val_AUC: 0.7061 - val_AUPR: 0.7273\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3698 - accuracy: 0.8278 - precision: 0.8397 - recall: 0.8852 - AUC: 0.8389 - AUPR: 0.8222 - val_loss: 0.4667 - val_accuracy: 0.7858 - val_precision: 0.8282 - val_recall: 0.8208 - val_AUC: 0.7041 - val_AUPR: 0.7271\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3705 - accuracy: 0.8295 - precision: 0.8465 - recall: 0.8784 - AUC: 0.8360 - AUPR: 0.8201 - val_loss: 0.4646 - val_accuracy: 0.7870 - val_precision: 0.8159 - val_recall: 0.8426 - val_AUC: 0.7051 - val_AUPR: 0.7288\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3693 - accuracy: 0.8290 - precision: 0.8436 - recall: 0.8818 - AUC: 0.8395 - AUPR: 0.8239 - val_loss: 0.4660 - val_accuracy: 0.7863 - val_precision: 0.8225 - val_recall: 0.8305 - val_AUC: 0.7049 - val_AUPR: 0.7278\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3643 - accuracy: 0.8280 - precision: 0.8399 - recall: 0.8853 - AUC: 0.8438 - AUPR: 0.8287 - val_loss: 0.4668 - val_accuracy: 0.7858 - val_precision: 0.8202 - val_recall: 0.8329 - val_AUC: 0.7038 - val_AUPR: 0.7260\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.3603 - accuracy: 0.8346 - precision: 0.8553 - recall: 0.8755 - AUC: 0.8478 - AUPR: 0.8308 - val_loss: 0.4664 - val_accuracy: 0.7894 - val_precision: 0.8135 - val_recall: 0.8516 - val_AUC: 0.7067 - val_AUPR: 0.7272\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3494 - accuracy: 0.8378 - precision: 0.8468 - recall: 0.8946 - AUC: 0.8601 - AUPR: 0.8387 - val_loss: 0.4657 - val_accuracy: 0.7879 - val_precision: 0.8166 - val_recall: 0.8432 - val_AUC: 0.7073 - val_AUPR: 0.7283\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3521 - accuracy: 0.8379 - precision: 0.8531 - recall: 0.8854 - AUC: 0.8580 - AUPR: 0.8363 - val_loss: 0.4661 - val_accuracy: 0.7875 - val_precision: 0.8226 - val_recall: 0.8327 - val_AUC: 0.7077 - val_AUPR: 0.7287\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3509 - accuracy: 0.8403 - precision: 0.8574 - recall: 0.8838 - AUC: 0.8574 - AUPR: 0.8366 - val_loss: 0.4671 - val_accuracy: 0.7870 - val_precision: 0.8239 - val_recall: 0.8297 - val_AUC: 0.7065 - val_AUPR: 0.7285\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3476 - accuracy: 0.8407 - precision: 0.8560 - recall: 0.8866 - AUC: 0.8614 - AUPR: 0.8411 - val_loss: 0.4677 - val_accuracy: 0.7897 - val_precision: 0.8192 - val_recall: 0.8428 - val_AUC: 0.7058 - val_AUPR: 0.7284\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3452 - accuracy: 0.8416 - precision: 0.8554 - recall: 0.8892 - AUC: 0.8618 - AUPR: 0.8415 - val_loss: 0.4677 - val_accuracy: 0.7884 - val_precision: 0.8220 - val_recall: 0.8356 - val_AUC: 0.7061 - val_AUPR: 0.7291\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3474 - accuracy: 0.8405 - precision: 0.8560 - recall: 0.8862 - AUC: 0.8593 - AUPR: 0.8413 - val_loss: 0.4690 - val_accuracy: 0.7881 - val_precision: 0.8223 - val_recall: 0.8345 - val_AUC: 0.7062 - val_AUPR: 0.7294\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3458 - accuracy: 0.8405 - precision: 0.8562 - recall: 0.8858 - AUC: 0.8622 - AUPR: 0.8387 - val_loss: 0.4690 - val_accuracy: 0.7891 - val_precision: 0.8204 - val_recall: 0.8398 - val_AUC: 0.7069 - val_AUPR: 0.7293\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3434 - accuracy: 0.8436 - precision: 0.8559 - recall: 0.8925 - AUC: 0.8630 - AUPR: 0.8452 - val_loss: 0.4684 - val_accuracy: 0.7882 - val_precision: 0.8233 - val_recall: 0.8332 - val_AUC: 0.7080 - val_AUPR: 0.7300\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3418 - accuracy: 0.8415 - precision: 0.8591 - recall: 0.8839 - AUC: 0.8657 - AUPR: 0.8415 - val_loss: 0.4685 - val_accuracy: 0.7882 - val_precision: 0.8216 - val_recall: 0.8359 - val_AUC: 0.7076 - val_AUPR: 0.7299\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 62ms/step - loss: 0.3403 - accuracy: 0.8445 - precision: 0.8580 - recall: 0.8913 - AUC: 0.8683 - AUPR: 0.8456 - val_loss: 0.4682 - val_accuracy: 0.7880 - val_precision: 0.8190 - val_recall: 0.8395 - val_AUC: 0.7074 - val_AUPR: 0.7300\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.3401 - accuracy: 0.8449 - precision: 0.8567 - recall: 0.8940 - AUC: 0.8662 - AUPR: 0.8452 - val_loss: 0.4682 - val_accuracy: 0.7879 - val_precision: 0.8195 - val_recall: 0.8384 - val_AUC: 0.7075 - val_AUPR: 0.7300\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3398 - accuracy: 0.8443 - precision: 0.8576 - recall: 0.8913 - AUC: 0.8683 - AUPR: 0.8465 - val_loss: 0.4682 - val_accuracy: 0.7877 - val_precision: 0.8211 - val_recall: 0.8356 - val_AUC: 0.7078 - val_AUPR: 0.7302\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3414 - accuracy: 0.8432 - precision: 0.8594 - recall: 0.8866 - AUC: 0.8676 - AUPR: 0.8454 - val_loss: 0.4683 - val_accuracy: 0.7878 - val_precision: 0.8212 - val_recall: 0.8356 - val_AUC: 0.7079 - val_AUPR: 0.7303\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3377 - accuracy: 0.8443 - precision: 0.8611 - recall: 0.8865 - AUC: 0.8700 - AUPR: 0.8507 - val_loss: 0.4685 - val_accuracy: 0.7877 - val_precision: 0.8205 - val_recall: 0.8365 - val_AUC: 0.7079 - val_AUPR: 0.7305\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3387 - accuracy: 0.8438 - precision: 0.8563 - recall: 0.8924 - AUC: 0.8706 - AUPR: 0.8475 - val_loss: 0.4684 - val_accuracy: 0.7875 - val_precision: 0.8200 - val_recall: 0.8369 - val_AUC: 0.7079 - val_AUPR: 0.7305\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3416 - accuracy: 0.8431 - precision: 0.8564 - recall: 0.8908 - AUC: 0.8671 - AUPR: 0.8437 - val_loss: 0.4687 - val_accuracy: 0.7875 - val_precision: 0.8209 - val_recall: 0.8354 - val_AUC: 0.7079 - val_AUPR: 0.7304\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3384 - accuracy: 0.8446 - precision: 0.8584 - recall: 0.8908 - AUC: 0.8684 - AUPR: 0.8476 - val_loss: 0.4686 - val_accuracy: 0.7879 - val_precision: 0.8209 - val_recall: 0.8362 - val_AUC: 0.7080 - val_AUPR: 0.7307\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.3392 - accuracy: 0.8439 - precision: 0.8592 - recall: 0.8884 - AUC: 0.8698 - AUPR: 0.8464 - val_loss: 0.4686 - val_accuracy: 0.7878 - val_precision: 0.8207 - val_recall: 0.8363 - val_AUC: 0.7083 - val_AUPR: 0.7305\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 57ms/step - loss: 0.3372 - accuracy: 0.8440 - precision: 0.8587 - recall: 0.8892 - AUC: 0.8717 - AUPR: 0.8487 - val_loss: 0.4688 - val_accuracy: 0.7876 - val_precision: 0.8206 - val_recall: 0.8362 - val_AUC: 0.7082 - val_AUPR: 0.7305\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3368 - accuracy: 0.8470 - precision: 0.8606 - recall: 0.8924 - AUC: 0.8683 - AUPR: 0.8481 - val_loss: 0.4691 - val_accuracy: 0.7872 - val_precision: 0.8200 - val_recall: 0.8363 - val_AUC: 0.7082 - val_AUPR: 0.7304\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3415 - accuracy: 0.8442 - precision: 0.8589 - recall: 0.8894 - AUC: 0.8664 - AUPR: 0.8414 - val_loss: 0.4691 - val_accuracy: 0.7875 - val_precision: 0.8202 - val_recall: 0.8366 - val_AUC: 0.7082 - val_AUPR: 0.7304\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3348 - accuracy: 0.8473 - precision: 0.8619 - recall: 0.8912 - AUC: 0.8732 - AUPR: 0.8480 - val_loss: 0.4691 - val_accuracy: 0.7875 - val_precision: 0.8204 - val_recall: 0.8363 - val_AUC: 0.7081 - val_AUPR: 0.7304\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3391 - accuracy: 0.8449 - precision: 0.8596 - recall: 0.8897 - AUC: 0.8696 - AUPR: 0.8464 - val_loss: 0.4692 - val_accuracy: 0.7875 - val_precision: 0.8204 - val_recall: 0.8363 - val_AUC: 0.7082 - val_AUPR: 0.7307\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3392 - accuracy: 0.8441 - precision: 0.8582 - recall: 0.8901 - AUC: 0.8684 - AUPR: 0.8496 - val_loss: 0.4692 - val_accuracy: 0.7875 - val_precision: 0.8204 - val_recall: 0.8363 - val_AUC: 0.7082 - val_AUPR: 0.7307\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3377 - accuracy: 0.8460 - precision: 0.8590 - recall: 0.8929 - AUC: 0.8702 - AUPR: 0.8506 - val_loss: 0.4692 - val_accuracy: 0.7876 - val_precision: 0.8206 - val_recall: 0.8362 - val_AUC: 0.7082 - val_AUPR: 0.7306\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3373 - accuracy: 0.8444 - precision: 0.8590 - recall: 0.8896 - AUC: 0.8708 - AUPR: 0.8470 - val_loss: 0.4692 - val_accuracy: 0.7878 - val_precision: 0.8207 - val_recall: 0.8363 - val_AUC: 0.7082 - val_AUPR: 0.7306\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3392 - accuracy: 0.8440 - precision: 0.8606 - recall: 0.8865 - AUC: 0.8682 - AUPR: 0.8435 - val_loss: 0.4692 - val_accuracy: 0.7877 - val_precision: 0.8206 - val_recall: 0.8363 - val_AUC: 0.7082 - val_AUPR: 0.7306\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 1s 58ms/step - loss: 0.3388 - accuracy: 0.8424 - precision: 0.8561 - recall: 0.8899 - AUC: 0.8702 - AUPR: 0.8517 - val_loss: 0.4693 - val_accuracy: 0.7875 - val_precision: 0.8205 - val_recall: 0.8362 - val_AUC: 0.7081 - val_AUPR: 0.7307\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.3398 - accuracy: 0.8445 - precision: 0.8586 - recall: 0.8903 - AUC: 0.8683 - AUPR: 0.8479 - val_loss: 0.4693 - val_accuracy: 0.7876 - val_precision: 0.8206 - val_recall: 0.8362 - val_AUC: 0.7082 - val_AUPR: 0.7307\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 1s 59ms/step - loss: 0.3391 - accuracy: 0.8452 - precision: 0.8596 - recall: 0.8902 - AUC: 0.8688 - AUPR: 0.8465 - val_loss: 0.4693 - val_accuracy: 0.7879 - val_precision: 0.8209 - val_recall: 0.8363 - val_AUC: 0.7081 - val_AUPR: 0.7305\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00058: early stopping\n",
            "loss :  0.45994776487350464\n",
            "accuracy :  0.7896955609321594\n",
            "precision :  0.8084598183631897\n",
            "recall :  0.8607121706008911\n",
            "AUC :  0.6990330815315247\n",
            "AUPR :  0.723825991153717\n",
            "\n",
            "******************************************************************\n",
            "[[0.46563879 0.78582531 0.78894049 0.8694371  0.71557957 0.71187657]\n",
            " [0.45813128 0.78994048 0.81163245 0.86149991 0.67623204 0.71597457]\n",
            " [0.46161407 0.78408778 0.79547948 0.86996257 0.68853414 0.72106999]\n",
            " [0.48876935 0.76980197 0.78205305 0.86018741 0.65481007 0.69556892]\n",
            " [0.45994776 0.78969556 0.80845982 0.86071217 0.69903308 0.72382599]]\n",
            "-Accuracy score_mean:0.7838702201843262\n",
            "-Accuracy score_mean:[[0.78582531]\n",
            " [0.78994048]\n",
            " [0.78408778]\n",
            " [0.76980197]\n",
            " [0.78969556]]\n",
            "-Accuracy score_mean:0.007383330732093559\n",
            "-Precision score_mean:0.7973130583763123\n",
            "-Precision score_mean:0.011274972716707314\n",
            "-Recall score_mean:0.8643598318099975\n",
            "-Recall score_mean:0.004383219128369949\n",
            "-AUC score_mean:0.6868377804756165\n",
            "-AUC score_mean:0.02057157913206383\n",
            "-AUPR score_mean:0.7136632084846497\n",
            "-AUPR score_mean:0.009940627290872472\n",
            "total running time: 4.333875954151154 minites\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yBeIbGTwYNC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn-zvSlRLMyq"
      },
      "source": [
        "METRICS = [\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='AUC',multi_label=True,num_labels=27,num_thresholds=498),\n",
        "      keras.metrics.AUC(name='AUPR',curve='PR',multi_label=True,num_labels=27,num_thresholds=498), # precision-recall curve\n",
        "]\n",
        "\n",
        "def create_model4(metrics=METRICS):\n",
        "  model = Sequential([\n",
        "    # layers.LSTM(256),\n",
        "    layers.Flatten(name=\"my_intermediate_layer\"),\n",
        "    layers.Dropout(0.4),\n",
        "      \n",
        "    layers.Dense(1024,name=\"my_feature\"),\n",
        "    layers.ReLU(),\n",
        "    layers.Dropout(0.4),\n",
        "    # layers.Dense(512),\n",
        "    # layers.ReLU(),\n",
        "    # layers.Dropout(0.4),\n",
        "    # layers.Dense(256),\n",
        "    # layers.ReLU(),\n",
        "    # layers.Dropout(0.4),\n",
        "    # layers.Dense(54),\n",
        "    # layers.ReLU(),\n",
        "    # layers.Dropout(0.4),\n",
        "    layers.Dense(27, activation='sigmoid', name=\"my_last_layer\"),\n",
        "    ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H5U4HNvLPih"
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-w7hrrDLUgS",
        "outputId": "4c8659f1-a53f-438e-fa30-b8d67f0b32ac"
      },
      "source": [
        "results=[]\n",
        "# 运行计时部分\n",
        "time_start = time.time()\n",
        "\n",
        "kfolder = KFold(n_splits=5,shuffle=True,random_state=2021)\n",
        "for i, (tra_id,val_id) in enumerate(kfolder.split(c_X_train,c_Y_train)):\n",
        "  print(f\"***********fold-{i+1}***********\")\n",
        "\n",
        "  c_x_train = c_X_train[tra_id]\n",
        "  c_y_train = c_Y_train.iloc[tra_id]\n",
        "\n",
        "  c_x_valid = c_X_train[val_id]\n",
        "  c_y_valid = c_Y_train.iloc[val_id]\n",
        "\n",
        "\n",
        "\n",
        "  # scaler = preprocessing.StandardScaler().fit(c_x_train)\n",
        "  # c_x_train = scaler.transform(c_x_train)\n",
        "\n",
        "  \n",
        "  # scaler = preprocessing.StandardScaler().fit(c_x_valid)\n",
        "  # c_x_valid = scaler.transform(c_x_valid)\n",
        "\n",
        "  \n",
        "\n",
        "  # reshape for cnn training\n",
        "  # c_x_test = np.array(c_x_test).reshape(c_x_test.shape[0], c_x_test.shape[1],1)\n",
        "  c_x_valid = np.array(c_x_valid).reshape(c_x_valid.shape[0], c_x_valid.shape[1],1)\n",
        "  c_x_train = np.array(c_x_train).reshape(c_x_train.shape[0], c_x_train.shape[1],1)\n",
        "    \n",
        "  model = create_model4()\n",
        "\n",
        "  opt = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "    \n",
        "  # training\n",
        "  history = model.fit(c_x_train, c_y_train.values, batch_size=128, epochs=300,validation_data=(c_x_valid, c_y_valid.values),\n",
        "                      callbacks=callbacks)\n",
        "\n",
        "\n",
        "  baseline_results = model.evaluate(c_x_valid, c_y_valid.values, verbose=0)\n",
        "  for name, value in zip(model.metrics_names, baseline_results):\n",
        "    print(name, ': ', value)\n",
        "  print()\n",
        "\n",
        "\n",
        "  model.save('./model/model_FP_masking_cross'+str(i+1)+'.h5')\n",
        "\n",
        "  result = np.array(baseline_results)\n",
        "  results.append(result)\n",
        "\n",
        "\n",
        "\n",
        "print(\"******************************************************************\")\n",
        "print(np.array(results))\n",
        "\n",
        "print(f\"-Accuracy score_mean:{np.mean(np.array(results)[:,[1]])}\")\n",
        "print(f\"-Accuracy score_mean:{np.array(results)[:,[1]]}\")\n",
        "print(f\"-Accuracy score_mean:{np.std(np.array(results)[:,[1]])}\")\n",
        "\n",
        "print(f\"-Precision score_mean:{np.mean(np.array(results)[:,[2]])}\")\n",
        "print(f\"-Precision score_mean:{np.std(np.array(results)[:,[2]])}\")\n",
        "\n",
        "print(f\"-Recall score_mean:{np.mean(np.array(results)[:,[3]])}\")\n",
        "print(f\"-Recall score_mean:{np.std(np.array(results)[:,[3]])}\")\n",
        "\n",
        "print(f\"-AUC score_mean:{np.mean(np.array(results)[:,[4]])}\")\n",
        "print(f\"-AUC score_mean:{np.std(np.array(results)[:,[4]])}\")\n",
        "\n",
        "print(f\"-AUPR score_mean:{np.mean(np.array(results)[:,[5]])}\")\n",
        "print(f\"-AUPR score_mean:{np.std(np.array(results)[:,[5]])}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# 运行计时部分\n",
        "time_end = time.time()\n",
        "print(f\"total running time: {(time_end - time_start)/60} minites\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***********fold-1***********\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 3s 90ms/step - loss: 0.8564 - accuracy: 0.7070 - precision: 0.7505 - recall: 0.7853 - AUC: 0.5583 - AUPR: 0.6440 - val_loss: 0.5635 - val_accuracy: 0.7369 - val_precision: 0.7293 - val_recall: 0.8808 - val_AUC: 0.6151 - val_AUPR: 0.6452\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6154 - accuracy: 0.7302 - precision: 0.7649 - recall: 0.8080 - AUC: 0.5842 - AUPR: 0.6608 - val_loss: 0.5103 - val_accuracy: 0.7594 - val_precision: 0.7561 - val_recall: 0.8739 - val_AUC: 0.6274 - val_AUPR: 0.6535\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.5354 - accuracy: 0.7503 - precision: 0.7824 - recall: 0.8205 - AUC: 0.6122 - AUPR: 0.6763 - val_loss: 0.5156 - val_accuracy: 0.7637 - val_precision: 0.7540 - val_recall: 0.8896 - val_AUC: 0.6358 - val_AUPR: 0.6603\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.5054 - accuracy: 0.7643 - precision: 0.7845 - recall: 0.8483 - AUC: 0.6283 - AUPR: 0.6857 - val_loss: 0.5123 - val_accuracy: 0.7675 - val_precision: 0.7554 - val_recall: 0.8960 - val_AUC: 0.6404 - val_AUPR: 0.6657\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4940 - accuracy: 0.7693 - precision: 0.7851 - recall: 0.8584 - AUC: 0.6428 - AUPR: 0.6904 - val_loss: 0.5115 - val_accuracy: 0.7636 - val_precision: 0.7570 - val_recall: 0.8825 - val_AUC: 0.6440 - val_AUPR: 0.6677\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4782 - accuracy: 0.7754 - precision: 0.7978 - recall: 0.8483 - AUC: 0.6652 - AUPR: 0.7075 - val_loss: 0.5067 - val_accuracy: 0.7670 - val_precision: 0.7578 - val_recall: 0.8891 - val_AUC: 0.6546 - val_AUPR: 0.6729\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4691 - accuracy: 0.7802 - precision: 0.7960 - recall: 0.8621 - AUC: 0.6847 - AUPR: 0.7168 - val_loss: 0.5011 - val_accuracy: 0.7667 - val_precision: 0.7564 - val_recall: 0.8916 - val_AUC: 0.6652 - val_AUPR: 0.6798\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4622 - accuracy: 0.7825 - precision: 0.7987 - recall: 0.8623 - AUC: 0.6987 - AUPR: 0.7227 - val_loss: 0.5012 - val_accuracy: 0.7726 - val_precision: 0.7686 - val_recall: 0.8791 - val_AUC: 0.6650 - val_AUPR: 0.6797\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4571 - accuracy: 0.7841 - precision: 0.8011 - recall: 0.8614 - AUC: 0.7064 - AUPR: 0.7293 - val_loss: 0.4948 - val_accuracy: 0.7743 - val_precision: 0.7651 - val_recall: 0.8908 - val_AUC: 0.6716 - val_AUPR: 0.6839\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4502 - accuracy: 0.7901 - precision: 0.8057 - recall: 0.8663 - AUC: 0.7161 - AUPR: 0.7352 - val_loss: 0.4962 - val_accuracy: 0.7770 - val_precision: 0.7723 - val_recall: 0.8818 - val_AUC: 0.6709 - val_AUPR: 0.6838\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4427 - accuracy: 0.7938 - precision: 0.8063 - recall: 0.8731 - AUC: 0.7304 - AUPR: 0.7440 - val_loss: 0.4974 - val_accuracy: 0.7745 - val_precision: 0.7688 - val_recall: 0.8832 - val_AUC: 0.6675 - val_AUPR: 0.6835\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4376 - accuracy: 0.7966 - precision: 0.8148 - recall: 0.8644 - AUC: 0.7383 - AUPR: 0.7498 - val_loss: 0.4896 - val_accuracy: 0.7766 - val_precision: 0.7700 - val_recall: 0.8857 - val_AUC: 0.6801 - val_AUPR: 0.6910\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4355 - accuracy: 0.7992 - precision: 0.8103 - recall: 0.8777 - AUC: 0.7437 - AUPR: 0.7550 - val_loss: 0.4905 - val_accuracy: 0.7790 - val_precision: 0.7775 - val_recall: 0.8759 - val_AUC: 0.6856 - val_AUPR: 0.6952\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4276 - accuracy: 0.8028 - precision: 0.8231 - recall: 0.8638 - AUC: 0.7569 - AUPR: 0.7667 - val_loss: 0.4834 - val_accuracy: 0.7794 - val_precision: 0.7724 - val_recall: 0.8876 - val_AUC: 0.6936 - val_AUPR: 0.7004\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4202 - accuracy: 0.8072 - precision: 0.8175 - recall: 0.8821 - AUC: 0.7683 - AUPR: 0.7688 - val_loss: 0.4819 - val_accuracy: 0.7798 - val_precision: 0.7764 - val_recall: 0.8800 - val_AUC: 0.6929 - val_AUPR: 0.7007\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4144 - accuracy: 0.8098 - precision: 0.8276 - recall: 0.8709 - AUC: 0.7752 - AUPR: 0.7762 - val_loss: 0.4793 - val_accuracy: 0.7777 - val_precision: 0.7688 - val_recall: 0.8910 - val_AUC: 0.6981 - val_AUPR: 0.7012\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4116 - accuracy: 0.8111 - precision: 0.8210 - recall: 0.8845 - AUC: 0.7792 - AUPR: 0.7820 - val_loss: 0.4854 - val_accuracy: 0.7821 - val_precision: 0.7939 - val_recall: 0.8516 - val_AUC: 0.6902 - val_AUPR: 0.6972\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.4088 - accuracy: 0.8141 - precision: 0.8295 - recall: 0.8767 - AUC: 0.7825 - AUPR: 0.7852 - val_loss: 0.4838 - val_accuracy: 0.7824 - val_precision: 0.7836 - val_recall: 0.8716 - val_AUC: 0.6897 - val_AUPR: 0.6947\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4047 - accuracy: 0.8157 - precision: 0.8305 - recall: 0.8784 - AUC: 0.7907 - AUPR: 0.7928 - val_loss: 0.4846 - val_accuracy: 0.7813 - val_precision: 0.7834 - val_recall: 0.8697 - val_AUC: 0.6872 - val_AUPR: 0.6961\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4009 - accuracy: 0.8180 - precision: 0.8328 - recall: 0.8795 - AUC: 0.7957 - AUPR: 0.7923 - val_loss: 0.4809 - val_accuracy: 0.7808 - val_precision: 0.7778 - val_recall: 0.8797 - val_AUC: 0.6916 - val_AUPR: 0.7005\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3983 - accuracy: 0.8179 - precision: 0.8357 - recall: 0.8747 - AUC: 0.8030 - AUPR: 0.7952 - val_loss: 0.4758 - val_accuracy: 0.7823 - val_precision: 0.7744 - val_recall: 0.8901 - val_AUC: 0.6967 - val_AUPR: 0.7033\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3887 - accuracy: 0.8246 - precision: 0.8365 - recall: 0.8870 - AUC: 0.8128 - AUPR: 0.8053 - val_loss: 0.4780 - val_accuracy: 0.7846 - val_precision: 0.7903 - val_recall: 0.8642 - val_AUC: 0.7001 - val_AUPR: 0.7019\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3886 - accuracy: 0.8224 - precision: 0.8360 - recall: 0.8833 - AUC: 0.8134 - AUPR: 0.8033 - val_loss: 0.4791 - val_accuracy: 0.7825 - val_precision: 0.7871 - val_recall: 0.8654 - val_AUC: 0.6999 - val_AUPR: 0.6969\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3861 - accuracy: 0.8253 - precision: 0.8366 - recall: 0.8884 - AUC: 0.8146 - AUPR: 0.8101 - val_loss: 0.4788 - val_accuracy: 0.7853 - val_precision: 0.7865 - val_recall: 0.8728 - val_AUC: 0.7014 - val_AUPR: 0.7012\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3810 - accuracy: 0.8263 - precision: 0.8435 - recall: 0.8796 - AUC: 0.8228 - AUPR: 0.8110 - val_loss: 0.4738 - val_accuracy: 0.7829 - val_precision: 0.7795 - val_recall: 0.8812 - val_AUC: 0.7033 - val_AUPR: 0.7044\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3708 - accuracy: 0.8315 - precision: 0.8506 - recall: 0.8793 - AUC: 0.8358 - AUPR: 0.8223 - val_loss: 0.4770 - val_accuracy: 0.7828 - val_precision: 0.7834 - val_recall: 0.8732 - val_AUC: 0.7013 - val_AUPR: 0.7048\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3742 - accuracy: 0.8313 - precision: 0.8404 - recall: 0.8944 - AUC: 0.8328 - AUPR: 0.8199 - val_loss: 0.4767 - val_accuracy: 0.7866 - val_precision: 0.7945 - val_recall: 0.8609 - val_AUC: 0.6972 - val_AUPR: 0.7029\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3686 - accuracy: 0.8331 - precision: 0.8502 - recall: 0.8830 - AUC: 0.8358 - AUPR: 0.8231 - val_loss: 0.4743 - val_accuracy: 0.7815 - val_precision: 0.7744 - val_recall: 0.8884 - val_AUC: 0.7035 - val_AUPR: 0.7070\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3664 - accuracy: 0.8343 - precision: 0.8489 - recall: 0.8875 - AUC: 0.8397 - AUPR: 0.8258 - val_loss: 0.4736 - val_accuracy: 0.7820 - val_precision: 0.7878 - val_recall: 0.8626 - val_AUC: 0.7000 - val_AUPR: 0.7064\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3665 - accuracy: 0.8336 - precision: 0.8478 - recall: 0.8877 - AUC: 0.8387 - AUPR: 0.8260 - val_loss: 0.4738 - val_accuracy: 0.7825 - val_precision: 0.7871 - val_recall: 0.8653 - val_AUC: 0.7006 - val_AUPR: 0.7060\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3623 - accuracy: 0.8371 - precision: 0.8517 - recall: 0.8889 - AUC: 0.8464 - AUPR: 0.8295 - val_loss: 0.4748 - val_accuracy: 0.7844 - val_precision: 0.7908 - val_recall: 0.8626 - val_AUC: 0.7003 - val_AUPR: 0.7078\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3622 - accuracy: 0.8339 - precision: 0.8483 - recall: 0.8875 - AUC: 0.8465 - AUPR: 0.8304 - val_loss: 0.4726 - val_accuracy: 0.7830 - val_precision: 0.7845 - val_recall: 0.8715 - val_AUC: 0.7001 - val_AUPR: 0.7093\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3566 - accuracy: 0.8394 - precision: 0.8594 - recall: 0.8822 - AUC: 0.8492 - AUPR: 0.8309 - val_loss: 0.4745 - val_accuracy: 0.7851 - val_precision: 0.7870 - val_recall: 0.8715 - val_AUC: 0.7002 - val_AUPR: 0.7087\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3538 - accuracy: 0.8390 - precision: 0.8536 - recall: 0.8898 - AUC: 0.8549 - AUPR: 0.8346 - val_loss: 0.4752 - val_accuracy: 0.7849 - val_precision: 0.7878 - val_recall: 0.8696 - val_AUC: 0.6973 - val_AUPR: 0.7066\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3499 - accuracy: 0.8412 - precision: 0.8540 - recall: 0.8936 - AUC: 0.8580 - AUPR: 0.8377 - val_loss: 0.4785 - val_accuracy: 0.7840 - val_precision: 0.7913 - val_recall: 0.8608 - val_AUC: 0.6967 - val_AUPR: 0.7061\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3436 - accuracy: 0.8446 - precision: 0.8550 - recall: 0.8988 - AUC: 0.8647 - AUPR: 0.8493 - val_loss: 0.4737 - val_accuracy: 0.7845 - val_precision: 0.7944 - val_recall: 0.8561 - val_AUC: 0.7024 - val_AUPR: 0.7083\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3457 - accuracy: 0.8435 - precision: 0.8604 - recall: 0.8888 - AUC: 0.8623 - AUPR: 0.8432 - val_loss: 0.4736 - val_accuracy: 0.7833 - val_precision: 0.7886 - val_recall: 0.8642 - val_AUC: 0.7072 - val_AUPR: 0.7112\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3389 - accuracy: 0.8481 - precision: 0.8636 - recall: 0.8931 - AUC: 0.8695 - AUPR: 0.8472 - val_loss: 0.4746 - val_accuracy: 0.7821 - val_precision: 0.7904 - val_recall: 0.8580 - val_AUC: 0.7056 - val_AUPR: 0.7099\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3408 - accuracy: 0.8464 - precision: 0.8615 - recall: 0.8928 - AUC: 0.8661 - AUPR: 0.8479 - val_loss: 0.4760 - val_accuracy: 0.7829 - val_precision: 0.7915 - val_recall: 0.8578 - val_AUC: 0.7030 - val_AUPR: 0.7096\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3389 - accuracy: 0.8478 - precision: 0.8630 - recall: 0.8933 - AUC: 0.8711 - AUPR: 0.8530 - val_loss: 0.4775 - val_accuracy: 0.7828 - val_precision: 0.7926 - val_recall: 0.8556 - val_AUC: 0.7054 - val_AUPR: 0.7111\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3360 - accuracy: 0.8502 - precision: 0.8644 - recall: 0.8961 - AUC: 0.8728 - AUPR: 0.8562 - val_loss: 0.4779 - val_accuracy: 0.7798 - val_precision: 0.7943 - val_recall: 0.8456 - val_AUC: 0.7032 - val_AUPR: 0.7098\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3340 - accuracy: 0.8488 - precision: 0.8642 - recall: 0.8936 - AUC: 0.8737 - AUPR: 0.8549 - val_loss: 0.4769 - val_accuracy: 0.7805 - val_precision: 0.7879 - val_recall: 0.8592 - val_AUC: 0.7073 - val_AUPR: 0.7109\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3292 - accuracy: 0.8513 - precision: 0.8633 - recall: 0.8997 - AUC: 0.8790 - AUPR: 0.8555 - val_loss: 0.4760 - val_accuracy: 0.7813 - val_precision: 0.7903 - val_recall: 0.8566 - val_AUC: 0.7089 - val_AUPR: 0.7118\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3266 - accuracy: 0.8556 - precision: 0.8709 - recall: 0.8974 - AUC: 0.8797 - AUPR: 0.8605 - val_loss: 0.4750 - val_accuracy: 0.7820 - val_precision: 0.7926 - val_recall: 0.8538 - val_AUC: 0.7088 - val_AUPR: 0.7123\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3257 - accuracy: 0.8550 - precision: 0.8717 - recall: 0.8951 - AUC: 0.8818 - AUPR: 0.8661 - val_loss: 0.4752 - val_accuracy: 0.7816 - val_precision: 0.7909 - val_recall: 0.8559 - val_AUC: 0.7092 - val_AUPR: 0.7120\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3247 - accuracy: 0.8543 - precision: 0.8664 - recall: 0.9010 - AUC: 0.8818 - AUPR: 0.8636 - val_loss: 0.4755 - val_accuracy: 0.7815 - val_precision: 0.7879 - val_recall: 0.8614 - val_AUC: 0.7100 - val_AUPR: 0.7128\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3204 - accuracy: 0.8569 - precision: 0.8704 - recall: 0.9005 - AUC: 0.8860 - AUPR: 0.8662 - val_loss: 0.4762 - val_accuracy: 0.7824 - val_precision: 0.7938 - val_recall: 0.8524 - val_AUC: 0.7090 - val_AUPR: 0.7130\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3165 - accuracy: 0.8597 - precision: 0.8736 - recall: 0.9013 - AUC: 0.8902 - AUPR: 0.8734 - val_loss: 0.4755 - val_accuracy: 0.7826 - val_precision: 0.7905 - val_recall: 0.8590 - val_AUC: 0.7095 - val_AUPR: 0.7128\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3205 - accuracy: 0.8573 - precision: 0.8730 - recall: 0.8976 - AUC: 0.8844 - AUPR: 0.8606 - val_loss: 0.4760 - val_accuracy: 0.7824 - val_precision: 0.7916 - val_recall: 0.8564 - val_AUC: 0.7098 - val_AUPR: 0.7133\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3198 - accuracy: 0.8573 - precision: 0.8718 - recall: 0.8993 - AUC: 0.8874 - AUPR: 0.8644 - val_loss: 0.4765 - val_accuracy: 0.7824 - val_precision: 0.7914 - val_recall: 0.8569 - val_AUC: 0.7090 - val_AUPR: 0.7131\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3203 - accuracy: 0.8587 - precision: 0.8713 - recall: 0.9027 - AUC: 0.8842 - AUPR: 0.8689 - val_loss: 0.4762 - val_accuracy: 0.7824 - val_precision: 0.7917 - val_recall: 0.8564 - val_AUC: 0.7091 - val_AUPR: 0.7130\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3167 - accuracy: 0.8589 - precision: 0.8732 - recall: 0.9006 - AUC: 0.8890 - AUPR: 0.8734 - val_loss: 0.4762 - val_accuracy: 0.7824 - val_precision: 0.7914 - val_recall: 0.8569 - val_AUC: 0.7093 - val_AUPR: 0.7136\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3147 - accuracy: 0.8589 - precision: 0.8724 - recall: 0.9015 - AUC: 0.8896 - AUPR: 0.8685 - val_loss: 0.4764 - val_accuracy: 0.7823 - val_precision: 0.7915 - val_recall: 0.8564 - val_AUC: 0.7092 - val_AUPR: 0.7136\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3136 - accuracy: 0.8607 - precision: 0.8731 - recall: 0.9041 - AUC: 0.8905 - AUPR: 0.8678 - val_loss: 0.4765 - val_accuracy: 0.7821 - val_precision: 0.7913 - val_recall: 0.8564 - val_AUC: 0.7092 - val_AUPR: 0.7136\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3139 - accuracy: 0.8603 - precision: 0.8715 - recall: 0.9054 - AUC: 0.8925 - AUPR: 0.8711 - val_loss: 0.4765 - val_accuracy: 0.7819 - val_precision: 0.7914 - val_recall: 0.8558 - val_AUC: 0.7093 - val_AUPR: 0.7136\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3120 - accuracy: 0.8617 - precision: 0.8755 - recall: 0.9027 - AUC: 0.8933 - AUPR: 0.8758 - val_loss: 0.4765 - val_accuracy: 0.7819 - val_precision: 0.7919 - val_recall: 0.8549 - val_AUC: 0.7091 - val_AUPR: 0.7137\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3131 - accuracy: 0.8592 - precision: 0.8722 - recall: 0.9022 - AUC: 0.8933 - AUPR: 0.8695 - val_loss: 0.4764 - val_accuracy: 0.7818 - val_precision: 0.7918 - val_recall: 0.8547 - val_AUC: 0.7093 - val_AUPR: 0.7140\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3186 - accuracy: 0.8577 - precision: 0.8722 - recall: 0.8996 - AUC: 0.8867 - AUPR: 0.8642 - val_loss: 0.4763 - val_accuracy: 0.7823 - val_precision: 0.7926 - val_recall: 0.8544 - val_AUC: 0.7095 - val_AUPR: 0.7140\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3139 - accuracy: 0.8606 - precision: 0.8749 - recall: 0.9014 - AUC: 0.8917 - AUPR: 0.8669 - val_loss: 0.4764 - val_accuracy: 0.7821 - val_precision: 0.7924 - val_recall: 0.8542 - val_AUC: 0.7095 - val_AUPR: 0.7141\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3130 - accuracy: 0.8629 - precision: 0.8750 - recall: 0.9056 - AUC: 0.8921 - AUPR: 0.8674 - val_loss: 0.4765 - val_accuracy: 0.7825 - val_precision: 0.7923 - val_recall: 0.8555 - val_AUC: 0.7094 - val_AUPR: 0.7143\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3184 - accuracy: 0.8571 - precision: 0.8700 - recall: 0.9014 - AUC: 0.8876 - AUPR: 0.8671 - val_loss: 0.4766 - val_accuracy: 0.7824 - val_precision: 0.7926 - val_recall: 0.8547 - val_AUC: 0.7096 - val_AUPR: 0.7145\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3140 - accuracy: 0.8606 - precision: 0.8740 - recall: 0.9027 - AUC: 0.8916 - AUPR: 0.8694 - val_loss: 0.4766 - val_accuracy: 0.7822 - val_precision: 0.7921 - val_recall: 0.8550 - val_AUC: 0.7094 - val_AUPR: 0.7144\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3146 - accuracy: 0.8592 - precision: 0.8722 - recall: 0.9023 - AUC: 0.8914 - AUPR: 0.8737 - val_loss: 0.4766 - val_accuracy: 0.7824 - val_precision: 0.7922 - val_recall: 0.8553 - val_AUC: 0.7094 - val_AUPR: 0.7144\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3113 - accuracy: 0.8624 - precision: 0.8762 - recall: 0.9030 - AUC: 0.8936 - AUPR: 0.8732 - val_loss: 0.4766 - val_accuracy: 0.7824 - val_precision: 0.7922 - val_recall: 0.8553 - val_AUC: 0.7095 - val_AUPR: 0.7145\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3131 - accuracy: 0.8604 - precision: 0.8756 - recall: 0.8999 - AUC: 0.8912 - AUPR: 0.8672 - val_loss: 0.4765 - val_accuracy: 0.7824 - val_precision: 0.7922 - val_recall: 0.8553 - val_AUC: 0.7095 - val_AUPR: 0.7146\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3102 - accuracy: 0.8612 - precision: 0.8765 - recall: 0.9003 - AUC: 0.8950 - AUPR: 0.8752 - val_loss: 0.4765 - val_accuracy: 0.7823 - val_precision: 0.7920 - val_recall: 0.8555 - val_AUC: 0.7095 - val_AUPR: 0.7145\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3121 - accuracy: 0.8621 - precision: 0.8764 - recall: 0.9021 - AUC: 0.8937 - AUPR: 0.8714 - val_loss: 0.4764 - val_accuracy: 0.7826 - val_precision: 0.7921 - val_recall: 0.8561 - val_AUC: 0.7096 - val_AUPR: 0.7146\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3091 - accuracy: 0.8600 - precision: 0.8739 - recall: 0.9015 - AUC: 0.8953 - AUPR: 0.8767 - val_loss: 0.4765 - val_accuracy: 0.7826 - val_precision: 0.7922 - val_recall: 0.8559 - val_AUC: 0.7096 - val_AUPR: 0.7145\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3145 - accuracy: 0.8600 - precision: 0.8729 - recall: 0.9028 - AUC: 0.8899 - AUPR: 0.8648 - val_loss: 0.4765 - val_accuracy: 0.7827 - val_precision: 0.7922 - val_recall: 0.8561 - val_AUC: 0.7096 - val_AUPR: 0.7146\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3156 - accuracy: 0.8598 - precision: 0.8752 - recall: 0.8994 - AUC: 0.8910 - AUPR: 0.8720 - val_loss: 0.4765 - val_accuracy: 0.7826 - val_precision: 0.7922 - val_recall: 0.8559 - val_AUC: 0.7096 - val_AUPR: 0.7146\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3141 - accuracy: 0.8595 - precision: 0.8721 - recall: 0.9030 - AUC: 0.8918 - AUPR: 0.8711 - val_loss: 0.4765 - val_accuracy: 0.7826 - val_precision: 0.7922 - val_recall: 0.8559 - val_AUC: 0.7096 - val_AUPR: 0.7146\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3138 - accuracy: 0.8604 - precision: 0.8754 - recall: 0.9003 - AUC: 0.8916 - AUPR: 0.8727 - val_loss: 0.4765 - val_accuracy: 0.7825 - val_precision: 0.7922 - val_recall: 0.8558 - val_AUC: 0.7096 - val_AUPR: 0.7147\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00072: early stopping\n",
            "loss :  0.47255566716194153\n",
            "accuracy :  0.7829903364181519\n",
            "precision :  0.784477949142456\n",
            "recall :  0.8714529275894165\n",
            "AUC :  0.7000660300254822\n",
            "AUPR :  0.7093129754066467\n",
            "\n",
            "***********fold-2***********\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 3s 92ms/step - loss: 0.8410 - accuracy: 0.7196 - precision: 0.7501 - recall: 0.8009 - AUC: 0.5711 - AUPR: 0.6353 - val_loss: 0.5250 - val_accuracy: 0.7518 - val_precision: 0.7854 - val_recall: 0.8257 - val_AUC: 0.6034 - val_AUPR: 0.6727\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.6022 - accuracy: 0.7254 - precision: 0.7648 - recall: 0.7886 - AUC: 0.5948 - AUPR: 0.6561 - val_loss: 0.5029 - val_accuracy: 0.7745 - val_precision: 0.7894 - val_recall: 0.8683 - val_AUC: 0.6241 - val_AUPR: 0.6836\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.5313 - accuracy: 0.7494 - precision: 0.7757 - recall: 0.8238 - AUC: 0.6235 - AUPR: 0.6733 - val_loss: 0.4954 - val_accuracy: 0.7777 - val_precision: 0.7949 - val_recall: 0.8650 - val_AUC: 0.6326 - val_AUPR: 0.6876\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.5059 - accuracy: 0.7604 - precision: 0.7848 - recall: 0.8320 - AUC: 0.6397 - AUPR: 0.6838 - val_loss: 0.4954 - val_accuracy: 0.7821 - val_precision: 0.7877 - val_recall: 0.8883 - val_AUC: 0.6395 - val_AUPR: 0.6932\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4919 - accuracy: 0.7680 - precision: 0.7825 - recall: 0.8538 - AUC: 0.6553 - AUPR: 0.6921 - val_loss: 0.4954 - val_accuracy: 0.7845 - val_precision: 0.8002 - val_recall: 0.8699 - val_AUC: 0.6463 - val_AUPR: 0.6978\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4812 - accuracy: 0.7728 - precision: 0.7922 - recall: 0.8465 - AUC: 0.6722 - AUPR: 0.7012 - val_loss: 0.4934 - val_accuracy: 0.7847 - val_precision: 0.8014 - val_recall: 0.8684 - val_AUC: 0.6577 - val_AUPR: 0.7049\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4718 - accuracy: 0.7768 - precision: 0.7954 - recall: 0.8495 - AUC: 0.6865 - AUPR: 0.7123 - val_loss: 0.4832 - val_accuracy: 0.7867 - val_precision: 0.8011 - val_recall: 0.8733 - val_AUC: 0.6647 - val_AUPR: 0.7087\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4638 - accuracy: 0.7811 - precision: 0.7947 - recall: 0.8603 - AUC: 0.7024 - AUPR: 0.7189 - val_loss: 0.4880 - val_accuracy: 0.7877 - val_precision: 0.8080 - val_recall: 0.8630 - val_AUC: 0.6700 - val_AUPR: 0.7124\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4569 - accuracy: 0.7857 - precision: 0.8022 - recall: 0.8569 - AUC: 0.7123 - AUPR: 0.7265 - val_loss: 0.4796 - val_accuracy: 0.7895 - val_precision: 0.7998 - val_recall: 0.8814 - val_AUC: 0.6732 - val_AUPR: 0.7147\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4521 - accuracy: 0.7871 - precision: 0.8052 - recall: 0.8549 - AUC: 0.7248 - AUPR: 0.7335 - val_loss: 0.4772 - val_accuracy: 0.7888 - val_precision: 0.8050 - val_recall: 0.8705 - val_AUC: 0.6771 - val_AUPR: 0.7197\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4464 - accuracy: 0.7909 - precision: 0.8044 - recall: 0.8645 - AUC: 0.7328 - AUPR: 0.7372 - val_loss: 0.4775 - val_accuracy: 0.7906 - val_precision: 0.8082 - val_recall: 0.8687 - val_AUC: 0.6838 - val_AUPR: 0.7197\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4375 - accuracy: 0.7951 - precision: 0.8069 - recall: 0.8693 - AUC: 0.7489 - AUPR: 0.7489 - val_loss: 0.4750 - val_accuracy: 0.7905 - val_precision: 0.8115 - val_recall: 0.8628 - val_AUC: 0.6851 - val_AUPR: 0.7228\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4352 - accuracy: 0.7967 - precision: 0.8126 - recall: 0.8629 - AUC: 0.7496 - AUPR: 0.7484 - val_loss: 0.4758 - val_accuracy: 0.7883 - val_precision: 0.8067 - val_recall: 0.8665 - val_AUC: 0.6807 - val_AUPR: 0.7213\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4248 - accuracy: 0.8017 - precision: 0.8153 - recall: 0.8690 - AUC: 0.7685 - AUPR: 0.7607 - val_loss: 0.4738 - val_accuracy: 0.7908 - val_precision: 0.8178 - val_recall: 0.8530 - val_AUC: 0.6845 - val_AUPR: 0.7228\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4216 - accuracy: 0.8042 - precision: 0.8204 - recall: 0.8658 - AUC: 0.7698 - AUPR: 0.7662 - val_loss: 0.4695 - val_accuracy: 0.7901 - val_precision: 0.8068 - val_recall: 0.8702 - val_AUC: 0.6885 - val_AUPR: 0.7253\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4149 - accuracy: 0.8081 - precision: 0.8219 - recall: 0.8717 - AUC: 0.7825 - AUPR: 0.7727 - val_loss: 0.4653 - val_accuracy: 0.7911 - val_precision: 0.8134 - val_recall: 0.8609 - val_AUC: 0.6948 - val_AUPR: 0.7298\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4149 - accuracy: 0.8077 - precision: 0.8239 - recall: 0.8676 - AUC: 0.7808 - AUPR: 0.7714 - val_loss: 0.4682 - val_accuracy: 0.7884 - val_precision: 0.8154 - val_recall: 0.8519 - val_AUC: 0.6979 - val_AUPR: 0.7324\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4066 - accuracy: 0.8138 - precision: 0.8261 - recall: 0.8768 - AUC: 0.7927 - AUPR: 0.7787 - val_loss: 0.4679 - val_accuracy: 0.7898 - val_precision: 0.8188 - val_recall: 0.8493 - val_AUC: 0.6987 - val_AUPR: 0.7312\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.4088 - accuracy: 0.8127 - precision: 0.8238 - recall: 0.8782 - AUC: 0.7898 - AUPR: 0.7768 - val_loss: 0.4664 - val_accuracy: 0.7904 - val_precision: 0.8189 - val_recall: 0.8503 - val_AUC: 0.6961 - val_AUPR: 0.7301\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4013 - accuracy: 0.8159 - precision: 0.8373 - recall: 0.8635 - AUC: 0.8021 - AUPR: 0.7872 - val_loss: 0.4581 - val_accuracy: 0.7909 - val_precision: 0.8070 - val_recall: 0.8715 - val_AUC: 0.6960 - val_AUPR: 0.7333\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3977 - accuracy: 0.8184 - precision: 0.8298 - recall: 0.8804 - AUC: 0.8065 - AUPR: 0.7909 - val_loss: 0.4715 - val_accuracy: 0.7847 - val_precision: 0.8265 - val_recall: 0.8267 - val_AUC: 0.6994 - val_AUPR: 0.7333\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3928 - accuracy: 0.8187 - precision: 0.8339 - recall: 0.8744 - AUC: 0.8106 - AUPR: 0.8003 - val_loss: 0.4638 - val_accuracy: 0.7897 - val_precision: 0.8168 - val_recall: 0.8522 - val_AUC: 0.6962 - val_AUPR: 0.7329\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3856 - accuracy: 0.8222 - precision: 0.8386 - recall: 0.8743 - AUC: 0.8215 - AUPR: 0.8043 - val_loss: 0.4610 - val_accuracy: 0.7913 - val_precision: 0.8197 - val_recall: 0.8509 - val_AUC: 0.6996 - val_AUPR: 0.7338\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3855 - accuracy: 0.8233 - precision: 0.8363 - recall: 0.8803 - AUC: 0.8221 - AUPR: 0.8052 - val_loss: 0.4653 - val_accuracy: 0.7905 - val_precision: 0.8289 - val_recall: 0.8347 - val_AUC: 0.7015 - val_AUPR: 0.7361\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.3799 - accuracy: 0.8250 - precision: 0.8367 - recall: 0.8830 - AUC: 0.8282 - AUPR: 0.8103 - val_loss: 0.4657 - val_accuracy: 0.7866 - val_precision: 0.8260 - val_recall: 0.8314 - val_AUC: 0.6994 - val_AUPR: 0.7354\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3752 - accuracy: 0.8297 - precision: 0.8482 - recall: 0.8750 - AUC: 0.8354 - AUPR: 0.8118 - val_loss: 0.4555 - val_accuracy: 0.7908 - val_precision: 0.8112 - val_recall: 0.8640 - val_AUC: 0.7035 - val_AUPR: 0.7370\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3706 - accuracy: 0.8304 - precision: 0.8452 - recall: 0.8809 - AUC: 0.8392 - AUPR: 0.8222 - val_loss: 0.4592 - val_accuracy: 0.7885 - val_precision: 0.8162 - val_recall: 0.8507 - val_AUC: 0.7033 - val_AUPR: 0.7385\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3708 - accuracy: 0.8324 - precision: 0.8459 - recall: 0.8840 - AUC: 0.8377 - AUPR: 0.8170 - val_loss: 0.4575 - val_accuracy: 0.7902 - val_precision: 0.8211 - val_recall: 0.8465 - val_AUC: 0.7042 - val_AUPR: 0.7415\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3690 - accuracy: 0.8322 - precision: 0.8512 - recall: 0.8756 - AUC: 0.8417 - AUPR: 0.8182 - val_loss: 0.4610 - val_accuracy: 0.7910 - val_precision: 0.8256 - val_recall: 0.8410 - val_AUC: 0.7047 - val_AUPR: 0.7404\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3627 - accuracy: 0.8364 - precision: 0.8477 - recall: 0.8894 - AUC: 0.8487 - AUPR: 0.8240 - val_loss: 0.4577 - val_accuracy: 0.7909 - val_precision: 0.8237 - val_recall: 0.8435 - val_AUC: 0.7019 - val_AUPR: 0.7392\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3597 - accuracy: 0.8376 - precision: 0.8508 - recall: 0.8871 - AUC: 0.8508 - AUPR: 0.8292 - val_loss: 0.4615 - val_accuracy: 0.7877 - val_precision: 0.8217 - val_recall: 0.8401 - val_AUC: 0.7024 - val_AUPR: 0.7411\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3608 - accuracy: 0.8364 - precision: 0.8552 - recall: 0.8782 - AUC: 0.8465 - AUPR: 0.8246 - val_loss: 0.4557 - val_accuracy: 0.7891 - val_precision: 0.8132 - val_recall: 0.8571 - val_AUC: 0.7047 - val_AUPR: 0.7439\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3560 - accuracy: 0.8376 - precision: 0.8483 - recall: 0.8909 - AUC: 0.8546 - AUPR: 0.8310 - val_loss: 0.4621 - val_accuracy: 0.7865 - val_precision: 0.8314 - val_recall: 0.8227 - val_AUC: 0.7067 - val_AUPR: 0.7421\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3498 - accuracy: 0.8412 - precision: 0.8586 - recall: 0.8828 - AUC: 0.8615 - AUPR: 0.8381 - val_loss: 0.4531 - val_accuracy: 0.7941 - val_precision: 0.8219 - val_recall: 0.8532 - val_AUC: 0.7082 - val_AUPR: 0.7417\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3510 - accuracy: 0.8419 - precision: 0.8588 - recall: 0.8839 - AUC: 0.8599 - AUPR: 0.8363 - val_loss: 0.4546 - val_accuracy: 0.7920 - val_precision: 0.8159 - val_recall: 0.8586 - val_AUC: 0.7053 - val_AUPR: 0.7404\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3448 - accuracy: 0.8445 - precision: 0.8597 - recall: 0.8878 - AUC: 0.8662 - AUPR: 0.8415 - val_loss: 0.4562 - val_accuracy: 0.7920 - val_precision: 0.8232 - val_recall: 0.8468 - val_AUC: 0.7085 - val_AUPR: 0.7425\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3433 - accuracy: 0.8461 - precision: 0.8594 - recall: 0.8914 - AUC: 0.8677 - AUPR: 0.8417 - val_loss: 0.4553 - val_accuracy: 0.7910 - val_precision: 0.8277 - val_recall: 0.8378 - val_AUC: 0.7138 - val_AUPR: 0.7461\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3432 - accuracy: 0.8429 - precision: 0.8579 - recall: 0.8873 - AUC: 0.8682 - AUPR: 0.8403 - val_loss: 0.4523 - val_accuracy: 0.7921 - val_precision: 0.8275 - val_recall: 0.8403 - val_AUC: 0.7147 - val_AUPR: 0.7472\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3386 - accuracy: 0.8475 - precision: 0.8621 - recall: 0.8903 - AUC: 0.8705 - AUPR: 0.8506 - val_loss: 0.4566 - val_accuracy: 0.7912 - val_precision: 0.8166 - val_recall: 0.8558 - val_AUC: 0.7075 - val_AUPR: 0.7435\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3362 - accuracy: 0.8484 - precision: 0.8644 - recall: 0.8887 - AUC: 0.8756 - AUPR: 0.8498 - val_loss: 0.4526 - val_accuracy: 0.7939 - val_precision: 0.8249 - val_recall: 0.8479 - val_AUC: 0.7123 - val_AUPR: 0.7444\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3344 - accuracy: 0.8495 - precision: 0.8652 - recall: 0.8899 - AUC: 0.8749 - AUPR: 0.8453 - val_loss: 0.4547 - val_accuracy: 0.7916 - val_precision: 0.8222 - val_recall: 0.8475 - val_AUC: 0.7090 - val_AUPR: 0.7443\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3323 - accuracy: 0.8506 - precision: 0.8647 - recall: 0.8927 - AUC: 0.8779 - AUPR: 0.8538 - val_loss: 0.4589 - val_accuracy: 0.7891 - val_precision: 0.8257 - val_recall: 0.8369 - val_AUC: 0.7092 - val_AUPR: 0.7427\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3306 - accuracy: 0.8513 - precision: 0.8639 - recall: 0.8951 - AUC: 0.8798 - AUPR: 0.8552 - val_loss: 0.4553 - val_accuracy: 0.7928 - val_precision: 0.8309 - val_recall: 0.8363 - val_AUC: 0.7140 - val_AUPR: 0.7458\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3267 - accuracy: 0.8511 - precision: 0.8671 - recall: 0.8903 - AUC: 0.8834 - AUPR: 0.8633 - val_loss: 0.4534 - val_accuracy: 0.7920 - val_precision: 0.8213 - val_recall: 0.8497 - val_AUC: 0.7154 - val_AUPR: 0.7480\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3310 - accuracy: 0.8488 - precision: 0.8657 - recall: 0.8877 - AUC: 0.8791 - AUPR: 0.8593 - val_loss: 0.4566 - val_accuracy: 0.7898 - val_precision: 0.8213 - val_recall: 0.8453 - val_AUC: 0.7113 - val_AUPR: 0.7453\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3271 - accuracy: 0.8530 - precision: 0.8689 - recall: 0.8914 - AUC: 0.8821 - AUPR: 0.8576 - val_loss: 0.4574 - val_accuracy: 0.7902 - val_precision: 0.8206 - val_recall: 0.8472 - val_AUC: 0.7102 - val_AUPR: 0.7437\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3167 - accuracy: 0.8604 - precision: 0.8722 - recall: 0.9012 - AUC: 0.8905 - AUPR: 0.8631 - val_loss: 0.4599 - val_accuracy: 0.7917 - val_precision: 0.8333 - val_recall: 0.8306 - val_AUC: 0.7113 - val_AUPR: 0.7439\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3159 - accuracy: 0.8572 - precision: 0.8727 - recall: 0.8944 - AUC: 0.8918 - AUPR: 0.8632 - val_loss: 0.4532 - val_accuracy: 0.7950 - val_precision: 0.8253 - val_recall: 0.8494 - val_AUC: 0.7132 - val_AUPR: 0.7463\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3167 - accuracy: 0.8595 - precision: 0.8712 - recall: 0.9009 - AUC: 0.8905 - AUPR: 0.8625 - val_loss: 0.4546 - val_accuracy: 0.7931 - val_precision: 0.8279 - val_recall: 0.8418 - val_AUC: 0.7139 - val_AUPR: 0.7471\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3116 - accuracy: 0.8609 - precision: 0.8747 - recall: 0.8989 - AUC: 0.8954 - AUPR: 0.8728 - val_loss: 0.4566 - val_accuracy: 0.7925 - val_precision: 0.8298 - val_recall: 0.8375 - val_AUC: 0.7143 - val_AUPR: 0.7474\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3092 - accuracy: 0.8641 - precision: 0.8776 - recall: 0.9011 - AUC: 0.8960 - AUPR: 0.8656 - val_loss: 0.4557 - val_accuracy: 0.7918 - val_precision: 0.8274 - val_recall: 0.8397 - val_AUC: 0.7146 - val_AUPR: 0.7474\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3135 - accuracy: 0.8573 - precision: 0.8736 - recall: 0.8934 - AUC: 0.8941 - AUPR: 0.8633 - val_loss: 0.4553 - val_accuracy: 0.7932 - val_precision: 0.8288 - val_recall: 0.8404 - val_AUC: 0.7163 - val_AUPR: 0.7477\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3106 - accuracy: 0.8610 - precision: 0.8733 - recall: 0.9009 - AUC: 0.8958 - AUPR: 0.8716 - val_loss: 0.4559 - val_accuracy: 0.7928 - val_precision: 0.8298 - val_recall: 0.8381 - val_AUC: 0.7164 - val_AUPR: 0.7478\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3079 - accuracy: 0.8634 - precision: 0.8779 - recall: 0.8992 - AUC: 0.8979 - AUPR: 0.8721 - val_loss: 0.4554 - val_accuracy: 0.7934 - val_precision: 0.8309 - val_recall: 0.8376 - val_AUC: 0.7166 - val_AUPR: 0.7480\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3049 - accuracy: 0.8632 - precision: 0.8783 - recall: 0.8983 - AUC: 0.9001 - AUPR: 0.8731 - val_loss: 0.4556 - val_accuracy: 0.7926 - val_precision: 0.8303 - val_recall: 0.8369 - val_AUC: 0.7163 - val_AUPR: 0.7480\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3066 - accuracy: 0.8650 - precision: 0.8790 - recall: 0.9009 - AUC: 0.9005 - AUPR: 0.8764 - val_loss: 0.4566 - val_accuracy: 0.7926 - val_precision: 0.8293 - val_recall: 0.8384 - val_AUC: 0.7165 - val_AUPR: 0.7481\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3015 - accuracy: 0.8663 - precision: 0.8779 - recall: 0.9048 - AUC: 0.9042 - AUPR: 0.8816 - val_loss: 0.4556 - val_accuracy: 0.7938 - val_precision: 0.8272 - val_recall: 0.8441 - val_AUC: 0.7165 - val_AUPR: 0.7482\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3001 - accuracy: 0.8674 - precision: 0.8799 - recall: 0.9042 - AUC: 0.9028 - AUPR: 0.8772 - val_loss: 0.4562 - val_accuracy: 0.7941 - val_precision: 0.8301 - val_recall: 0.8403 - val_AUC: 0.7168 - val_AUPR: 0.7480\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3050 - accuracy: 0.8640 - precision: 0.8777 - recall: 0.9007 - AUC: 0.9002 - AUPR: 0.8806 - val_loss: 0.4563 - val_accuracy: 0.7941 - val_precision: 0.8299 - val_recall: 0.8406 - val_AUC: 0.7166 - val_AUPR: 0.7481\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3030 - accuracy: 0.8661 - precision: 0.8830 - recall: 0.8976 - AUC: 0.9022 - AUPR: 0.8762 - val_loss: 0.4560 - val_accuracy: 0.7944 - val_precision: 0.8297 - val_recall: 0.8415 - val_AUC: 0.7166 - val_AUPR: 0.7480\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3008 - accuracy: 0.8646 - precision: 0.8765 - recall: 0.9035 - AUC: 0.9051 - AUPR: 0.8813 - val_loss: 0.4562 - val_accuracy: 0.7941 - val_precision: 0.8303 - val_recall: 0.8398 - val_AUC: 0.7168 - val_AUPR: 0.7480\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3042 - accuracy: 0.8649 - precision: 0.8782 - recall: 0.9018 - AUC: 0.9019 - AUPR: 0.8720 - val_loss: 0.4561 - val_accuracy: 0.7941 - val_precision: 0.8301 - val_recall: 0.8403 - val_AUC: 0.7169 - val_AUPR: 0.7480\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3050 - accuracy: 0.8639 - precision: 0.8787 - recall: 0.8991 - AUC: 0.9011 - AUPR: 0.8763 - val_loss: 0.4560 - val_accuracy: 0.7942 - val_precision: 0.8301 - val_recall: 0.8406 - val_AUC: 0.7171 - val_AUPR: 0.7481\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3031 - accuracy: 0.8636 - precision: 0.8759 - recall: 0.9024 - AUC: 0.9010 - AUPR: 0.8770 - val_loss: 0.4561 - val_accuracy: 0.7945 - val_precision: 0.8304 - val_recall: 0.8406 - val_AUC: 0.7171 - val_AUPR: 0.7481\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3032 - accuracy: 0.8654 - precision: 0.8766 - recall: 0.9047 - AUC: 0.9018 - AUPR: 0.8731 - val_loss: 0.4564 - val_accuracy: 0.7941 - val_precision: 0.8303 - val_recall: 0.8398 - val_AUC: 0.7169 - val_AUPR: 0.7482\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3055 - accuracy: 0.8639 - precision: 0.8784 - recall: 0.8996 - AUC: 0.9007 - AUPR: 0.8762 - val_loss: 0.4565 - val_accuracy: 0.7941 - val_precision: 0.8304 - val_recall: 0.8398 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3028 - accuracy: 0.8671 - precision: 0.8810 - recall: 0.9021 - AUC: 0.9020 - AUPR: 0.8796 - val_loss: 0.4564 - val_accuracy: 0.7942 - val_precision: 0.8306 - val_recall: 0.8397 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3055 - accuracy: 0.8644 - precision: 0.8779 - recall: 0.9012 - AUC: 0.9010 - AUPR: 0.8782 - val_loss: 0.4564 - val_accuracy: 0.7941 - val_precision: 0.8307 - val_recall: 0.8393 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3000 - accuracy: 0.8667 - precision: 0.8797 - recall: 0.9032 - AUC: 0.9018 - AUPR: 0.8778 - val_loss: 0.4563 - val_accuracy: 0.7940 - val_precision: 0.8305 - val_recall: 0.8394 - val_AUC: 0.7172 - val_AUPR: 0.7484\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.2994 - accuracy: 0.8665 - precision: 0.8805 - recall: 0.9016 - AUC: 0.9053 - AUPR: 0.8882 - val_loss: 0.4562 - val_accuracy: 0.7941 - val_precision: 0.8305 - val_recall: 0.8395 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.2997 - accuracy: 0.8679 - precision: 0.8807 - recall: 0.9041 - AUC: 0.9043 - AUPR: 0.8768 - val_loss: 0.4562 - val_accuracy: 0.7938 - val_precision: 0.8302 - val_recall: 0.8394 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3048 - accuracy: 0.8618 - precision: 0.8778 - recall: 0.8963 - AUC: 0.9011 - AUPR: 0.8746 - val_loss: 0.4562 - val_accuracy: 0.7938 - val_precision: 0.8302 - val_recall: 0.8394 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3021 - accuracy: 0.8662 - precision: 0.8789 - recall: 0.9032 - AUC: 0.9020 - AUPR: 0.8785 - val_loss: 0.4562 - val_accuracy: 0.7940 - val_precision: 0.8304 - val_recall: 0.8395 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.2990 - accuracy: 0.8660 - precision: 0.8808 - recall: 0.9002 - AUC: 0.9053 - AUPR: 0.8804 - val_loss: 0.4561 - val_accuracy: 0.7941 - val_precision: 0.8305 - val_recall: 0.8395 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3040 - accuracy: 0.8646 - precision: 0.8770 - recall: 0.9026 - AUC: 0.9018 - AUPR: 0.8812 - val_loss: 0.4562 - val_accuracy: 0.7939 - val_precision: 0.8304 - val_recall: 0.8393 - val_AUC: 0.7170 - val_AUPR: 0.7484\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3062 - accuracy: 0.8628 - precision: 0.8756 - recall: 0.9011 - AUC: 0.8999 - AUPR: 0.8757 - val_loss: 0.4562 - val_accuracy: 0.7940 - val_precision: 0.8305 - val_recall: 0.8394 - val_AUC: 0.7170 - val_AUPR: 0.7484\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3007 - accuracy: 0.8662 - precision: 0.8791 - recall: 0.9029 - AUC: 0.9041 - AUPR: 0.8810 - val_loss: 0.4562 - val_accuracy: 0.7941 - val_precision: 0.8307 - val_recall: 0.8393 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.2959 - accuracy: 0.8697 - precision: 0.8817 - recall: 0.9061 - AUC: 0.9062 - AUPR: 0.8792 - val_loss: 0.4563 - val_accuracy: 0.7942 - val_precision: 0.8310 - val_recall: 0.8391 - val_AUC: 0.7171 - val_AUPR: 0.7484\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00078: early stopping\n",
            "loss :  0.4522629380226135\n",
            "accuracy :  0.7921352982521057\n",
            "precision :  0.8274811506271362\n",
            "recall :  0.8402829170227051\n",
            "AUC :  0.7146632075309753\n",
            "AUPR :  0.7472096681594849\n",
            "\n",
            "***********fold-3***********\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 19s 1s/step - loss: 0.8902 - accuracy: 0.7149 - precision: 0.7538 - recall: 0.7913 - AUC: 0.5680 - AUPR: 0.6407 - val_loss: 0.5301 - val_accuracy: 0.7540 - val_precision: 0.7855 - val_recall: 0.8213 - val_AUC: 0.6012 - val_AUPR: 0.6669\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.6295 - accuracy: 0.7191 - precision: 0.7574 - recall: 0.7907 - AUC: 0.5825 - AUPR: 0.6532 - val_loss: 0.5047 - val_accuracy: 0.7697 - val_precision: 0.7714 - val_recall: 0.8851 - val_AUC: 0.6225 - val_AUPR: 0.6786\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.5462 - accuracy: 0.7456 - precision: 0.7744 - recall: 0.8199 - AUC: 0.6080 - AUPR: 0.6671 - val_loss: 0.5008 - val_accuracy: 0.7725 - val_precision: 0.7805 - val_recall: 0.8727 - val_AUC: 0.6241 - val_AUPR: 0.6854\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.5107 - accuracy: 0.7574 - precision: 0.7791 - recall: 0.8384 - AUC: 0.6318 - AUPR: 0.6776 - val_loss: 0.5017 - val_accuracy: 0.7782 - val_precision: 0.7787 - val_recall: 0.8894 - val_AUC: 0.6272 - val_AUPR: 0.6919\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4943 - accuracy: 0.7668 - precision: 0.7838 - recall: 0.8508 - AUC: 0.6449 - AUPR: 0.6900 - val_loss: 0.4980 - val_accuracy: 0.7802 - val_precision: 0.7828 - val_recall: 0.8858 - val_AUC: 0.6374 - val_AUPR: 0.6947\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4832 - accuracy: 0.7748 - precision: 0.7900 - recall: 0.8573 - AUC: 0.6616 - AUPR: 0.6979 - val_loss: 0.5011 - val_accuracy: 0.7801 - val_precision: 0.7891 - val_recall: 0.8730 - val_AUC: 0.6396 - val_AUPR: 0.6956\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4742 - accuracy: 0.7771 - precision: 0.7950 - recall: 0.8531 - AUC: 0.6789 - AUPR: 0.7075 - val_loss: 0.4948 - val_accuracy: 0.7804 - val_precision: 0.7868 - val_recall: 0.8784 - val_AUC: 0.6488 - val_AUPR: 0.7008\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4670 - accuracy: 0.7794 - precision: 0.7953 - recall: 0.8576 - AUC: 0.6884 - AUPR: 0.7152 - val_loss: 0.4931 - val_accuracy: 0.7851 - val_precision: 0.7912 - val_recall: 0.8803 - val_AUC: 0.6538 - val_AUPR: 0.7049\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4598 - accuracy: 0.7878 - precision: 0.8035 - recall: 0.8614 - AUC: 0.7014 - AUPR: 0.7191 - val_loss: 0.4867 - val_accuracy: 0.7839 - val_precision: 0.7917 - val_recall: 0.8767 - val_AUC: 0.6618 - val_AUPR: 0.7084\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4505 - accuracy: 0.7904 - precision: 0.8045 - recall: 0.8652 - AUC: 0.7182 - AUPR: 0.7276 - val_loss: 0.4873 - val_accuracy: 0.7839 - val_precision: 0.7961 - val_recall: 0.8685 - val_AUC: 0.6690 - val_AUPR: 0.7123\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4471 - accuracy: 0.7919 - precision: 0.8086 - recall: 0.8613 - AUC: 0.7256 - AUPR: 0.7350 - val_loss: 0.4842 - val_accuracy: 0.7824 - val_precision: 0.7893 - val_recall: 0.8781 - val_AUC: 0.6732 - val_AUPR: 0.7138\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4376 - accuracy: 0.7980 - precision: 0.8129 - recall: 0.8669 - AUC: 0.7403 - AUPR: 0.7457 - val_loss: 0.4799 - val_accuracy: 0.7812 - val_precision: 0.7913 - val_recall: 0.8713 - val_AUC: 0.6794 - val_AUPR: 0.7163\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4335 - accuracy: 0.7993 - precision: 0.8117 - recall: 0.8718 - AUC: 0.7473 - AUPR: 0.7495 - val_loss: 0.4793 - val_accuracy: 0.7834 - val_precision: 0.7924 - val_recall: 0.8743 - val_AUC: 0.6858 - val_AUPR: 0.7211\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4288 - accuracy: 0.8011 - precision: 0.8163 - recall: 0.8679 - AUC: 0.7566 - AUPR: 0.7560 - val_loss: 0.4786 - val_accuracy: 0.7878 - val_precision: 0.8009 - val_recall: 0.8683 - val_AUC: 0.6870 - val_AUPR: 0.7218\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4256 - accuracy: 0.8037 - precision: 0.8205 - recall: 0.8663 - AUC: 0.7599 - AUPR: 0.7591 - val_loss: 0.4758 - val_accuracy: 0.7861 - val_precision: 0.7966 - val_recall: 0.8724 - val_AUC: 0.6911 - val_AUPR: 0.7263\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4174 - accuracy: 0.8079 - precision: 0.8195 - recall: 0.8769 - AUC: 0.7742 - AUPR: 0.7665 - val_loss: 0.4795 - val_accuracy: 0.7866 - val_precision: 0.8078 - val_recall: 0.8536 - val_AUC: 0.6860 - val_AUPR: 0.7239\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.4138 - accuracy: 0.8119 - precision: 0.8316 - recall: 0.8656 - AUC: 0.7781 - AUPR: 0.7738 - val_loss: 0.4725 - val_accuracy: 0.7827 - val_precision: 0.7915 - val_recall: 0.8745 - val_AUC: 0.6899 - val_AUPR: 0.7321\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4125 - accuracy: 0.8097 - precision: 0.8262 - recall: 0.8696 - AUC: 0.7849 - AUPR: 0.7738 - val_loss: 0.4688 - val_accuracy: 0.7857 - val_precision: 0.7968 - val_recall: 0.8712 - val_AUC: 0.6969 - val_AUPR: 0.7363\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4018 - accuracy: 0.8152 - precision: 0.8259 - recall: 0.8817 - AUC: 0.7995 - AUPR: 0.7854 - val_loss: 0.4814 - val_accuracy: 0.7844 - val_precision: 0.8149 - val_recall: 0.8369 - val_AUC: 0.6919 - val_AUPR: 0.7345\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4006 - accuracy: 0.8166 - precision: 0.8326 - recall: 0.8736 - AUC: 0.8001 - AUPR: 0.7841 - val_loss: 0.4668 - val_accuracy: 0.7906 - val_precision: 0.8039 - val_recall: 0.8689 - val_AUC: 0.7000 - val_AUPR: 0.7363\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3980 - accuracy: 0.8195 - precision: 0.8340 - recall: 0.8775 - AUC: 0.8027 - AUPR: 0.7852 - val_loss: 0.4708 - val_accuracy: 0.7932 - val_precision: 0.8104 - val_recall: 0.8632 - val_AUC: 0.7005 - val_AUPR: 0.7357\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3945 - accuracy: 0.8194 - precision: 0.8313 - recall: 0.8816 - AUC: 0.8070 - AUPR: 0.7914 - val_loss: 0.4696 - val_accuracy: 0.7903 - val_precision: 0.8143 - val_recall: 0.8505 - val_AUC: 0.6999 - val_AUPR: 0.7347\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.3895 - accuracy: 0.8212 - precision: 0.8377 - recall: 0.8753 - AUC: 0.8125 - AUPR: 0.7974 - val_loss: 0.4696 - val_accuracy: 0.7848 - val_precision: 0.8035 - val_recall: 0.8571 - val_AUC: 0.7000 - val_AUPR: 0.7350\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3850 - accuracy: 0.8239 - precision: 0.8387 - recall: 0.8791 - AUC: 0.8190 - AUPR: 0.8019 - val_loss: 0.4621 - val_accuracy: 0.7895 - val_precision: 0.8016 - val_recall: 0.8706 - val_AUC: 0.7037 - val_AUPR: 0.7386\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3783 - accuracy: 0.8275 - precision: 0.8426 - recall: 0.8804 - AUC: 0.8292 - AUPR: 0.8060 - val_loss: 0.4692 - val_accuracy: 0.7876 - val_precision: 0.8098 - val_recall: 0.8521 - val_AUC: 0.6981 - val_AUPR: 0.7389\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3757 - accuracy: 0.8295 - precision: 0.8422 - recall: 0.8851 - AUC: 0.8311 - AUPR: 0.8039 - val_loss: 0.4652 - val_accuracy: 0.7899 - val_precision: 0.8103 - val_recall: 0.8563 - val_AUC: 0.7020 - val_AUPR: 0.7408\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3766 - accuracy: 0.8285 - precision: 0.8416 - recall: 0.8840 - AUC: 0.8307 - AUPR: 0.8112 - val_loss: 0.4659 - val_accuracy: 0.7842 - val_precision: 0.8034 - val_recall: 0.8559 - val_AUC: 0.7020 - val_AUPR: 0.7413\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3750 - accuracy: 0.8293 - precision: 0.8495 - recall: 0.8736 - AUC: 0.8311 - AUPR: 0.8114 - val_loss: 0.4607 - val_accuracy: 0.7890 - val_precision: 0.7999 - val_recall: 0.8727 - val_AUC: 0.7044 - val_AUPR: 0.7417\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3668 - accuracy: 0.8337 - precision: 0.8468 - recall: 0.8866 - AUC: 0.8414 - AUPR: 0.8189 - val_loss: 0.4613 - val_accuracy: 0.7905 - val_precision: 0.8118 - val_recall: 0.8550 - val_AUC: 0.7063 - val_AUPR: 0.7426\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3649 - accuracy: 0.8360 - precision: 0.8506 - recall: 0.8855 - AUC: 0.8434 - AUPR: 0.8158 - val_loss: 0.4624 - val_accuracy: 0.7889 - val_precision: 0.8073 - val_recall: 0.8593 - val_AUC: 0.7023 - val_AUPR: 0.7414\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3603 - accuracy: 0.8358 - precision: 0.8541 - recall: 0.8800 - AUC: 0.8502 - AUPR: 0.8257 - val_loss: 0.4648 - val_accuracy: 0.7880 - val_precision: 0.8105 - val_recall: 0.8520 - val_AUC: 0.7024 - val_AUPR: 0.7420\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3598 - accuracy: 0.8397 - precision: 0.8564 - recall: 0.8844 - AUC: 0.8468 - AUPR: 0.8233 - val_loss: 0.4628 - val_accuracy: 0.7860 - val_precision: 0.8041 - val_recall: 0.8586 - val_AUC: 0.7018 - val_AUPR: 0.7436\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3505 - accuracy: 0.8411 - precision: 0.8517 - recall: 0.8941 - AUC: 0.8589 - AUPR: 0.8344 - val_loss: 0.4669 - val_accuracy: 0.7841 - val_precision: 0.8132 - val_recall: 0.8390 - val_AUC: 0.6976 - val_AUPR: 0.7423\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3526 - accuracy: 0.8408 - precision: 0.8573 - recall: 0.8853 - AUC: 0.8545 - AUPR: 0.8314 - val_loss: 0.4587 - val_accuracy: 0.7877 - val_precision: 0.8029 - val_recall: 0.8646 - val_AUC: 0.7055 - val_AUPR: 0.7453\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3551 - accuracy: 0.8391 - precision: 0.8528 - recall: 0.8884 - AUC: 0.8524 - AUPR: 0.8258 - val_loss: 0.4748 - val_accuracy: 0.7771 - val_precision: 0.8231 - val_recall: 0.8087 - val_AUC: 0.7004 - val_AUPR: 0.7436\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3524 - accuracy: 0.8399 - precision: 0.8569 - recall: 0.8841 - AUC: 0.8558 - AUPR: 0.8304 - val_loss: 0.4601 - val_accuracy: 0.7825 - val_precision: 0.7975 - val_recall: 0.8629 - val_AUC: 0.7055 - val_AUPR: 0.7472\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3467 - accuracy: 0.8467 - precision: 0.8626 - recall: 0.8894 - AUC: 0.8607 - AUPR: 0.8329 - val_loss: 0.4582 - val_accuracy: 0.7856 - val_precision: 0.8070 - val_recall: 0.8526 - val_AUC: 0.7119 - val_AUPR: 0.7500\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3414 - accuracy: 0.8480 - precision: 0.8590 - recall: 0.8969 - AUC: 0.8651 - AUPR: 0.8399 - val_loss: 0.4600 - val_accuracy: 0.7862 - val_precision: 0.8114 - val_recall: 0.8464 - val_AUC: 0.7128 - val_AUPR: 0.7499\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3395 - accuracy: 0.8467 - precision: 0.8616 - recall: 0.8906 - AUC: 0.8688 - AUPR: 0.8445 - val_loss: 0.4648 - val_accuracy: 0.7856 - val_precision: 0.8196 - val_recall: 0.8318 - val_AUC: 0.7077 - val_AUPR: 0.7470\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3397 - accuracy: 0.8453 - precision: 0.8576 - recall: 0.8937 - AUC: 0.8678 - AUPR: 0.8476 - val_loss: 0.4678 - val_accuracy: 0.7843 - val_precision: 0.8118 - val_recall: 0.8416 - val_AUC: 0.7003 - val_AUPR: 0.7445\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3360 - accuracy: 0.8476 - precision: 0.8669 - recall: 0.8849 - AUC: 0.8715 - AUPR: 0.8485 - val_loss: 0.4628 - val_accuracy: 0.7831 - val_precision: 0.8096 - val_recall: 0.8428 - val_AUC: 0.7052 - val_AUPR: 0.7470\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.8502 - precision: 0.8666 - recall: 0.8904 - AUC: 0.8727 - AUPR: 0.8470 - val_loss: 0.4629 - val_accuracy: 0.7855 - val_precision: 0.8095 - val_recall: 0.8481 - val_AUC: 0.7063 - val_AUPR: 0.7485\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3297 - accuracy: 0.8513 - precision: 0.8644 - recall: 0.8958 - AUC: 0.8781 - AUPR: 0.8515 - val_loss: 0.4641 - val_accuracy: 0.7834 - val_precision: 0.8153 - val_recall: 0.8342 - val_AUC: 0.7078 - val_AUPR: 0.7514\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3277 - accuracy: 0.8537 - precision: 0.8667 - recall: 0.8972 - AUC: 0.8792 - AUPR: 0.8522 - val_loss: 0.4637 - val_accuracy: 0.7845 - val_precision: 0.8136 - val_recall: 0.8391 - val_AUC: 0.7119 - val_AUPR: 0.7523\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3253 - accuracy: 0.8548 - precision: 0.8695 - recall: 0.8952 - AUC: 0.8804 - AUPR: 0.8522 - val_loss: 0.4632 - val_accuracy: 0.7856 - val_precision: 0.8098 - val_recall: 0.8478 - val_AUC: 0.7084 - val_AUPR: 0.7491\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3216 - accuracy: 0.8562 - precision: 0.8719 - recall: 0.8947 - AUC: 0.8842 - AUPR: 0.8548 - val_loss: 0.4674 - val_accuracy: 0.7822 - val_precision: 0.8087 - val_recall: 0.8424 - val_AUC: 0.7036 - val_AUPR: 0.7484\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3207 - accuracy: 0.8552 - precision: 0.8679 - recall: 0.8984 - AUC: 0.8854 - AUPR: 0.8605 - val_loss: 0.4643 - val_accuracy: 0.7845 - val_precision: 0.8124 - val_recall: 0.8413 - val_AUC: 0.7080 - val_AUPR: 0.7515\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3195 - accuracy: 0.8580 - precision: 0.8749 - recall: 0.8941 - AUC: 0.8870 - AUPR: 0.8581 - val_loss: 0.4642 - val_accuracy: 0.7862 - val_precision: 0.8113 - val_recall: 0.8467 - val_AUC: 0.7083 - val_AUPR: 0.7522\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3143 - accuracy: 0.8585 - precision: 0.8695 - recall: 0.9025 - AUC: 0.8912 - AUPR: 0.8618 - val_loss: 0.4646 - val_accuracy: 0.7871 - val_precision: 0.8105 - val_recall: 0.8499 - val_AUC: 0.7079 - val_AUPR: 0.7513\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3150 - accuracy: 0.8608 - precision: 0.8772 - recall: 0.8963 - AUC: 0.8898 - AUPR: 0.8664 - val_loss: 0.4657 - val_accuracy: 0.7852 - val_precision: 0.8140 - val_recall: 0.8400 - val_AUC: 0.7066 - val_AUPR: 0.7514\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3125 - accuracy: 0.8610 - precision: 0.8755 - recall: 0.8989 - AUC: 0.8925 - AUPR: 0.8644 - val_loss: 0.4659 - val_accuracy: 0.7854 - val_precision: 0.8128 - val_recall: 0.8424 - val_AUC: 0.7061 - val_AUPR: 0.7507\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3099 - accuracy: 0.8632 - precision: 0.8782 - recall: 0.8995 - AUC: 0.8957 - AUPR: 0.8686 - val_loss: 0.4645 - val_accuracy: 0.7867 - val_precision: 0.8121 - val_recall: 0.8464 - val_AUC: 0.7071 - val_AUPR: 0.7510\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3088 - accuracy: 0.8614 - precision: 0.8758 - recall: 0.8994 - AUC: 0.8967 - AUPR: 0.8652 - val_loss: 0.4639 - val_accuracy: 0.7873 - val_precision: 0.8121 - val_recall: 0.8476 - val_AUC: 0.7076 - val_AUPR: 0.7507\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3073 - accuracy: 0.8646 - precision: 0.8788 - recall: 0.9014 - AUC: 0.8959 - AUPR: 0.8697 - val_loss: 0.4648 - val_accuracy: 0.7868 - val_precision: 0.8138 - val_recall: 0.8439 - val_AUC: 0.7077 - val_AUPR: 0.7509\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3086 - accuracy: 0.8609 - precision: 0.8776 - recall: 0.8959 - AUC: 0.8968 - AUPR: 0.8690 - val_loss: 0.4640 - val_accuracy: 0.7866 - val_precision: 0.8110 - val_recall: 0.8481 - val_AUC: 0.7083 - val_AUPR: 0.7515\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3055 - accuracy: 0.8630 - precision: 0.8752 - recall: 0.9033 - AUC: 0.8969 - AUPR: 0.8705 - val_loss: 0.4644 - val_accuracy: 0.7861 - val_precision: 0.8137 - val_recall: 0.8425 - val_AUC: 0.7085 - val_AUPR: 0.7515\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3101 - accuracy: 0.8629 - precision: 0.8798 - recall: 0.8968 - AUC: 0.8943 - AUPR: 0.8632 - val_loss: 0.4644 - val_accuracy: 0.7860 - val_precision: 0.8127 - val_recall: 0.8439 - val_AUC: 0.7081 - val_AUPR: 0.7512\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3035 - accuracy: 0.8653 - precision: 0.8829 - recall: 0.8972 - AUC: 0.9007 - AUPR: 0.8708 - val_loss: 0.4645 - val_accuracy: 0.7866 - val_precision: 0.8123 - val_recall: 0.8460 - val_AUC: 0.7077 - val_AUPR: 0.7509\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3086 - accuracy: 0.8627 - precision: 0.8762 - recall: 0.9014 - AUC: 0.8961 - AUPR: 0.8692 - val_loss: 0.4643 - val_accuracy: 0.7871 - val_precision: 0.8114 - val_recall: 0.8484 - val_AUC: 0.7079 - val_AUPR: 0.7509\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3112 - accuracy: 0.8597 - precision: 0.8746 - recall: 0.8978 - AUC: 0.8942 - AUPR: 0.8693 - val_loss: 0.4643 - val_accuracy: 0.7873 - val_precision: 0.8110 - val_recall: 0.8494 - val_AUC: 0.7078 - val_AUPR: 0.7509\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3024 - accuracy: 0.8658 - precision: 0.8779 - recall: 0.9050 - AUC: 0.9017 - AUPR: 0.8749 - val_loss: 0.4643 - val_accuracy: 0.7867 - val_precision: 0.8111 - val_recall: 0.8482 - val_AUC: 0.7077 - val_AUPR: 0.7512\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3050 - accuracy: 0.8639 - precision: 0.8795 - recall: 0.8990 - AUC: 0.8998 - AUPR: 0.8812 - val_loss: 0.4644 - val_accuracy: 0.7862 - val_precision: 0.8113 - val_recall: 0.8467 - val_AUC: 0.7075 - val_AUPR: 0.7513\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3029 - accuracy: 0.8653 - precision: 0.8790 - recall: 0.9025 - AUC: 0.9004 - AUPR: 0.8721 - val_loss: 0.4646 - val_accuracy: 0.7865 - val_precision: 0.8117 - val_recall: 0.8466 - val_AUC: 0.7073 - val_AUPR: 0.7512\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3044 - accuracy: 0.8649 - precision: 0.8803 - recall: 0.9000 - AUC: 0.8999 - AUPR: 0.8732 - val_loss: 0.4647 - val_accuracy: 0.7871 - val_precision: 0.8119 - val_recall: 0.8476 - val_AUC: 0.7073 - val_AUPR: 0.7511\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3062 - accuracy: 0.8636 - precision: 0.8800 - recall: 0.8979 - AUC: 0.8977 - AUPR: 0.8707 - val_loss: 0.4645 - val_accuracy: 0.7874 - val_precision: 0.8111 - val_recall: 0.8496 - val_AUC: 0.7073 - val_AUPR: 0.7508\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3087 - accuracy: 0.8616 - precision: 0.8747 - recall: 0.9013 - AUC: 0.8960 - AUPR: 0.8638 - val_loss: 0.4647 - val_accuracy: 0.7868 - val_precision: 0.8107 - val_recall: 0.8490 - val_AUC: 0.7072 - val_AUPR: 0.7508\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3070 - accuracy: 0.8649 - precision: 0.8771 - recall: 0.9042 - AUC: 0.8979 - AUPR: 0.8702 - val_loss: 0.4647 - val_accuracy: 0.7867 - val_precision: 0.8112 - val_recall: 0.8479 - val_AUC: 0.7070 - val_AUPR: 0.7507\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3018 - accuracy: 0.8690 - precision: 0.8831 - recall: 0.9041 - AUC: 0.9010 - AUPR: 0.8661 - val_loss: 0.4648 - val_accuracy: 0.7868 - val_precision: 0.8114 - val_recall: 0.8479 - val_AUC: 0.7070 - val_AUPR: 0.7508\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3004 - accuracy: 0.8671 - precision: 0.8767 - recall: 0.9091 - AUC: 0.9027 - AUPR: 0.8705 - val_loss: 0.4648 - val_accuracy: 0.7867 - val_precision: 0.8114 - val_recall: 0.8476 - val_AUC: 0.7069 - val_AUPR: 0.7507\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3057 - accuracy: 0.8632 - precision: 0.8768 - recall: 0.9014 - AUC: 0.8990 - AUPR: 0.8680 - val_loss: 0.4649 - val_accuracy: 0.7868 - val_precision: 0.8114 - val_recall: 0.8478 - val_AUC: 0.7068 - val_AUPR: 0.7508\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3054 - accuracy: 0.8647 - precision: 0.8792 - recall: 0.9011 - AUC: 0.8978 - AUPR: 0.8711 - val_loss: 0.4649 - val_accuracy: 0.7869 - val_precision: 0.8115 - val_recall: 0.8479 - val_AUC: 0.7070 - val_AUPR: 0.7507\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3053 - accuracy: 0.8652 - precision: 0.8793 - recall: 0.9019 - AUC: 0.8971 - AUPR: 0.8690 - val_loss: 0.4649 - val_accuracy: 0.7869 - val_precision: 0.8115 - val_recall: 0.8479 - val_AUC: 0.7070 - val_AUPR: 0.7507\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3012 - accuracy: 0.8674 - precision: 0.8808 - recall: 0.9041 - AUC: 0.9014 - AUPR: 0.8698 - val_loss: 0.4650 - val_accuracy: 0.7867 - val_precision: 0.8116 - val_recall: 0.8473 - val_AUC: 0.7070 - val_AUPR: 0.7508\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3043 - accuracy: 0.8648 - precision: 0.8798 - recall: 0.9004 - AUC: 0.9009 - AUPR: 0.8720 - val_loss: 0.4649 - val_accuracy: 0.7865 - val_precision: 0.8114 - val_recall: 0.8470 - val_AUC: 0.7070 - val_AUPR: 0.7508\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3039 - accuracy: 0.8646 - precision: 0.8787 - recall: 0.9014 - AUC: 0.9013 - AUPR: 0.8693 - val_loss: 0.4649 - val_accuracy: 0.7867 - val_precision: 0.8114 - val_recall: 0.8476 - val_AUC: 0.7071 - val_AUPR: 0.7509\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3055 - accuracy: 0.8654 - precision: 0.8784 - recall: 0.9034 - AUC: 0.8982 - AUPR: 0.8701 - val_loss: 0.4650 - val_accuracy: 0.7866 - val_precision: 0.8115 - val_recall: 0.8473 - val_AUC: 0.7072 - val_AUPR: 0.7509\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3018 - accuracy: 0.8675 - precision: 0.8805 - recall: 0.9046 - AUC: 0.8996 - AUPR: 0.8652 - val_loss: 0.4649 - val_accuracy: 0.7869 - val_precision: 0.8117 - val_recall: 0.8475 - val_AUC: 0.7070 - val_AUPR: 0.7509\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00077: early stopping\n",
            "loss :  0.45816078782081604\n",
            "accuracy :  0.7855510115623474\n",
            "precision :  0.8070051074028015\n",
            "recall :  0.8525842428207397\n",
            "AUC :  0.7119255661964417\n",
            "AUPR :  0.7500460743904114\n",
            "\n",
            "***********fold-4***********\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 3s 92ms/step - loss: 0.8758 - accuracy: 0.7139 - precision: 0.7541 - recall: 0.7864 - AUC: 0.5725 - AUPR: 0.6446 - val_loss: 0.5927 - val_accuracy: 0.7370 - val_precision: 0.7613 - val_recall: 0.8251 - val_AUC: 0.5761 - val_AUPR: 0.6496\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.6239 - accuracy: 0.7325 - precision: 0.7672 - recall: 0.8044 - AUC: 0.5921 - AUPR: 0.6590 - val_loss: 0.5195 - val_accuracy: 0.7541 - val_precision: 0.7686 - val_recall: 0.8507 - val_AUC: 0.5948 - val_AUPR: 0.6627\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.5397 - accuracy: 0.7486 - precision: 0.7799 - recall: 0.8173 - AUC: 0.6126 - AUPR: 0.6735 - val_loss: 0.5159 - val_accuracy: 0.7587 - val_precision: 0.7659 - val_recall: 0.8673 - val_AUC: 0.6026 - val_AUPR: 0.6662\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.5046 - accuracy: 0.7647 - precision: 0.7865 - recall: 0.8418 - AUC: 0.6406 - AUPR: 0.6846 - val_loss: 0.5131 - val_accuracy: 0.7619 - val_precision: 0.7642 - val_recall: 0.8786 - val_AUC: 0.6129 - val_AUPR: 0.6709\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4851 - accuracy: 0.7730 - precision: 0.7875 - recall: 0.8585 - AUC: 0.6599 - AUPR: 0.6987 - val_loss: 0.5107 - val_accuracy: 0.7643 - val_precision: 0.7683 - val_recall: 0.8753 - val_AUC: 0.6223 - val_AUPR: 0.6771\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4770 - accuracy: 0.7758 - precision: 0.7955 - recall: 0.8500 - AUC: 0.6674 - AUPR: 0.7034 - val_loss: 0.5094 - val_accuracy: 0.7649 - val_precision: 0.7681 - val_recall: 0.8771 - val_AUC: 0.6260 - val_AUPR: 0.6807\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4638 - accuracy: 0.7807 - precision: 0.7979 - recall: 0.8563 - AUC: 0.6925 - AUPR: 0.7157 - val_loss: 0.5063 - val_accuracy: 0.7666 - val_precision: 0.7695 - val_recall: 0.8782 - val_AUC: 0.6305 - val_AUPR: 0.6822\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4545 - accuracy: 0.7879 - precision: 0.8062 - recall: 0.8575 - AUC: 0.7099 - AUPR: 0.7251 - val_loss: 0.5036 - val_accuracy: 0.7671 - val_precision: 0.7728 - val_recall: 0.8724 - val_AUC: 0.6375 - val_AUPR: 0.6879\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.4506 - accuracy: 0.7915 - precision: 0.8059 - recall: 0.8657 - AUC: 0.7195 - AUPR: 0.7272 - val_loss: 0.5022 - val_accuracy: 0.7666 - val_precision: 0.7808 - val_recall: 0.8552 - val_AUC: 0.6462 - val_AUPR: 0.6930\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4402 - accuracy: 0.7961 - precision: 0.8163 - recall: 0.8579 - AUC: 0.7365 - AUPR: 0.7386 - val_loss: 0.4970 - val_accuracy: 0.7686 - val_precision: 0.7726 - val_recall: 0.8765 - val_AUC: 0.6515 - val_AUPR: 0.6956\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4353 - accuracy: 0.7977 - precision: 0.8080 - recall: 0.8755 - AUC: 0.7434 - AUPR: 0.7441 - val_loss: 0.4981 - val_accuracy: 0.7681 - val_precision: 0.7827 - val_recall: 0.8549 - val_AUC: 0.6578 - val_AUPR: 0.7026\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4320 - accuracy: 0.8010 - precision: 0.8187 - recall: 0.8643 - AUC: 0.7470 - AUPR: 0.7488 - val_loss: 0.4936 - val_accuracy: 0.7693 - val_precision: 0.7804 - val_recall: 0.8623 - val_AUC: 0.6586 - val_AUPR: 0.7042\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4269 - accuracy: 0.8020 - precision: 0.8179 - recall: 0.8678 - AUC: 0.7567 - AUPR: 0.7552 - val_loss: 0.4958 - val_accuracy: 0.7694 - val_precision: 0.7789 - val_recall: 0.8656 - val_AUC: 0.6554 - val_AUPR: 0.7021\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4209 - accuracy: 0.8066 - precision: 0.8202 - recall: 0.8736 - AUC: 0.7667 - AUPR: 0.7640 - val_loss: 0.4946 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.8628 - val_AUC: 0.6588 - val_AUPR: 0.7054\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4167 - accuracy: 0.8099 - precision: 0.8258 - recall: 0.8714 - AUC: 0.7706 - AUPR: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7684 - val_precision: 0.7786 - val_recall: 0.8638 - val_AUC: 0.6600 - val_AUPR: 0.7071\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4114 - accuracy: 0.8111 - precision: 0.8290 - recall: 0.8687 - AUC: 0.7822 - AUPR: 0.7693 - val_loss: 0.4923 - val_accuracy: 0.7691 - val_precision: 0.7765 - val_recall: 0.8696 - val_AUC: 0.6644 - val_AUPR: 0.7092\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4093 - accuracy: 0.8115 - precision: 0.8283 - recall: 0.8706 - AUC: 0.7837 - AUPR: 0.7755 - val_loss: 0.4921 - val_accuracy: 0.7692 - val_precision: 0.7814 - val_recall: 0.8600 - val_AUC: 0.6655 - val_AUPR: 0.7085\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4058 - accuracy: 0.8134 - precision: 0.8295 - recall: 0.8726 - AUC: 0.7892 - AUPR: 0.7786 - val_loss: 0.4917 - val_accuracy: 0.7685 - val_precision: 0.7819 - val_recall: 0.8576 - val_AUC: 0.6653 - val_AUPR: 0.7117\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4006 - accuracy: 0.8172 - precision: 0.8334 - recall: 0.8743 - AUC: 0.7972 - AUPR: 0.7834 - val_loss: 0.4893 - val_accuracy: 0.7705 - val_precision: 0.7824 - val_recall: 0.8612 - val_AUC: 0.6719 - val_AUPR: 0.7151\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3955 - accuracy: 0.8204 - precision: 0.8341 - recall: 0.8798 - AUC: 0.8013 - AUPR: 0.7892 - val_loss: 0.4916 - val_accuracy: 0.7695 - val_precision: 0.7858 - val_recall: 0.8523 - val_AUC: 0.6690 - val_AUPR: 0.7162\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3948 - accuracy: 0.8200 - precision: 0.8382 - recall: 0.8726 - AUC: 0.8035 - AUPR: 0.7876 - val_loss: 0.4867 - val_accuracy: 0.7710 - val_precision: 0.7835 - val_recall: 0.8602 - val_AUC: 0.6740 - val_AUPR: 0.7203\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3940 - accuracy: 0.8197 - precision: 0.8344 - recall: 0.8779 - AUC: 0.8058 - AUPR: 0.7929 - val_loss: 0.4896 - val_accuracy: 0.7707 - val_precision: 0.7851 - val_recall: 0.8564 - val_AUC: 0.6723 - val_AUPR: 0.7211\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3830 - accuracy: 0.8249 - precision: 0.8400 - recall: 0.8798 - AUC: 0.8186 - AUPR: 0.8054 - val_loss: 0.4912 - val_accuracy: 0.7695 - val_precision: 0.7891 - val_recall: 0.8461 - val_AUC: 0.6711 - val_AUPR: 0.7203\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3806 - accuracy: 0.8252 - precision: 0.8394 - recall: 0.8813 - AUC: 0.8225 - AUPR: 0.8027 - val_loss: 0.4858 - val_accuracy: 0.7715 - val_precision: 0.7882 - val_recall: 0.8523 - val_AUC: 0.6772 - val_AUPR: 0.7211\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3736 - accuracy: 0.8311 - precision: 0.8514 - recall: 0.8752 - AUC: 0.8309 - AUPR: 0.8113 - val_loss: 0.4868 - val_accuracy: 0.7719 - val_precision: 0.7855 - val_recall: 0.8584 - val_AUC: 0.6766 - val_AUPR: 0.7224\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3721 - accuracy: 0.8300 - precision: 0.8434 - recall: 0.8850 - AUC: 0.8322 - AUPR: 0.8114 - val_loss: 0.4858 - val_accuracy: 0.7738 - val_precision: 0.7930 - val_recall: 0.8485 - val_AUC: 0.6782 - val_AUPR: 0.7245\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3678 - accuracy: 0.8337 - precision: 0.8476 - recall: 0.8860 - AUC: 0.8373 - AUPR: 0.8139 - val_loss: 0.4876 - val_accuracy: 0.7707 - val_precision: 0.7955 - val_recall: 0.8372 - val_AUC: 0.6780 - val_AUPR: 0.7260\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3649 - accuracy: 0.8348 - precision: 0.8494 - recall: 0.8855 - AUC: 0.8415 - AUPR: 0.8196 - val_loss: 0.4859 - val_accuracy: 0.7741 - val_precision: 0.7925 - val_recall: 0.8502 - val_AUC: 0.6806 - val_AUPR: 0.7262\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3647 - accuracy: 0.8337 - precision: 0.8538 - recall: 0.8769 - AUC: 0.8414 - AUPR: 0.8216 - val_loss: 0.4855 - val_accuracy: 0.7710 - val_precision: 0.7817 - val_recall: 0.8635 - val_AUC: 0.6826 - val_AUPR: 0.7274\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3621 - accuracy: 0.8363 - precision: 0.8500 - recall: 0.8875 - AUC: 0.8418 - AUPR: 0.8189 - val_loss: 0.4886 - val_accuracy: 0.7692 - val_precision: 0.7937 - val_recall: 0.8369 - val_AUC: 0.6800 - val_AUPR: 0.7273\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3582 - accuracy: 0.8387 - precision: 0.8563 - recall: 0.8831 - AUC: 0.8477 - AUPR: 0.8273 - val_loss: 0.4857 - val_accuracy: 0.7732 - val_precision: 0.7881 - val_recall: 0.8563 - val_AUC: 0.6822 - val_AUPR: 0.7283\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3511 - accuracy: 0.8394 - precision: 0.8551 - recall: 0.8862 - AUC: 0.8551 - AUPR: 0.8355 - val_loss: 0.4880 - val_accuracy: 0.7719 - val_precision: 0.7974 - val_recall: 0.8365 - val_AUC: 0.6807 - val_AUPR: 0.7294\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3472 - accuracy: 0.8432 - precision: 0.8559 - recall: 0.8926 - AUC: 0.8605 - AUPR: 0.8362 - val_loss: 0.4878 - val_accuracy: 0.7719 - val_precision: 0.7967 - val_recall: 0.8377 - val_AUC: 0.6826 - val_AUPR: 0.7309\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3459 - accuracy: 0.8449 - precision: 0.8646 - recall: 0.8833 - AUC: 0.8594 - AUPR: 0.8342 - val_loss: 0.4871 - val_accuracy: 0.7732 - val_precision: 0.7913 - val_recall: 0.8504 - val_AUC: 0.6809 - val_AUPR: 0.7292\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3474 - accuracy: 0.8406 - precision: 0.8549 - recall: 0.8890 - AUC: 0.8595 - AUPR: 0.8327 - val_loss: 0.4930 - val_accuracy: 0.7683 - val_precision: 0.7976 - val_recall: 0.8281 - val_AUC: 0.6771 - val_AUPR: 0.7276\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3477 - accuracy: 0.8443 - precision: 0.8606 - recall: 0.8879 - AUC: 0.8595 - AUPR: 0.8405 - val_loss: 0.4853 - val_accuracy: 0.7726 - val_precision: 0.7906 - val_recall: 0.8504 - val_AUC: 0.6798 - val_AUPR: 0.7298\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3345 - accuracy: 0.8497 - precision: 0.8632 - recall: 0.8948 - AUC: 0.8718 - AUPR: 0.8486 - val_loss: 0.4886 - val_accuracy: 0.7697 - val_precision: 0.7981 - val_recall: 0.8304 - val_AUC: 0.6817 - val_AUPR: 0.7298\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.3332 - accuracy: 0.8549 - precision: 0.8701 - recall: 0.8953 - AUC: 0.8724 - AUPR: 0.8438 - val_loss: 0.4867 - val_accuracy: 0.7707 - val_precision: 0.7936 - val_recall: 0.8405 - val_AUC: 0.6858 - val_AUPR: 0.7336\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3323 - accuracy: 0.8498 - precision: 0.8632 - recall: 0.8950 - AUC: 0.8744 - AUPR: 0.8519 - val_loss: 0.4884 - val_accuracy: 0.7706 - val_precision: 0.7939 - val_recall: 0.8398 - val_AUC: 0.6852 - val_AUPR: 0.7341\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3324 - accuracy: 0.8506 - precision: 0.8659 - recall: 0.8926 - AUC: 0.8744 - AUPR: 0.8518 - val_loss: 0.4881 - val_accuracy: 0.7709 - val_precision: 0.7960 - val_recall: 0.8368 - val_AUC: 0.6865 - val_AUPR: 0.7351\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3308 - accuracy: 0.8496 - precision: 0.8654 - recall: 0.8914 - AUC: 0.8764 - AUPR: 0.8452 - val_loss: 0.4872 - val_accuracy: 0.7698 - val_precision: 0.7892 - val_recall: 0.8466 - val_AUC: 0.6855 - val_AUPR: 0.7345\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3277 - accuracy: 0.8527 - precision: 0.8701 - recall: 0.8910 - AUC: 0.8798 - AUPR: 0.8493 - val_loss: 0.4869 - val_accuracy: 0.7680 - val_precision: 0.7876 - val_recall: 0.8454 - val_AUC: 0.6846 - val_AUPR: 0.7330\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3253 - accuracy: 0.8554 - precision: 0.8703 - recall: 0.8957 - AUC: 0.8823 - AUPR: 0.8520 - val_loss: 0.4861 - val_accuracy: 0.7693 - val_precision: 0.7927 - val_recall: 0.8392 - val_AUC: 0.6857 - val_AUPR: 0.7324\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3231 - accuracy: 0.8547 - precision: 0.8717 - recall: 0.8925 - AUC: 0.8824 - AUPR: 0.8533 - val_loss: 0.4857 - val_accuracy: 0.7715 - val_precision: 0.7905 - val_recall: 0.8481 - val_AUC: 0.6912 - val_AUPR: 0.7354\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3186 - accuracy: 0.8569 - precision: 0.8716 - recall: 0.8970 - AUC: 0.8869 - AUPR: 0.8572 - val_loss: 0.4862 - val_accuracy: 0.7724 - val_precision: 0.7935 - val_recall: 0.8445 - val_AUC: 0.6909 - val_AUPR: 0.7340\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3147 - accuracy: 0.8598 - precision: 0.8730 - recall: 0.9005 - AUC: 0.8900 - AUPR: 0.8655 - val_loss: 0.4931 - val_accuracy: 0.7716 - val_precision: 0.8016 - val_recall: 0.8286 - val_AUC: 0.6881 - val_AUPR: 0.7336\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3183 - accuracy: 0.8581 - precision: 0.8802 - recall: 0.8876 - AUC: 0.8880 - AUPR: 0.8632 - val_loss: 0.4913 - val_accuracy: 0.7738 - val_precision: 0.7942 - val_recall: 0.8464 - val_AUC: 0.6877 - val_AUPR: 0.7335\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3137 - accuracy: 0.8619 - precision: 0.8756 - recall: 0.9011 - AUC: 0.8905 - AUPR: 0.8587 - val_loss: 0.4911 - val_accuracy: 0.7725 - val_precision: 0.7923 - val_recall: 0.8469 - val_AUC: 0.6869 - val_AUPR: 0.7334\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3114 - accuracy: 0.8601 - precision: 0.8749 - recall: 0.8986 - AUC: 0.8926 - AUPR: 0.8585 - val_loss: 0.4919 - val_accuracy: 0.7732 - val_precision: 0.7972 - val_recall: 0.8396 - val_AUC: 0.6858 - val_AUPR: 0.7325\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3063 - accuracy: 0.8635 - precision: 0.8789 - recall: 0.8997 - AUC: 0.8969 - AUPR: 0.8712 - val_loss: 0.4905 - val_accuracy: 0.7732 - val_precision: 0.7946 - val_recall: 0.8443 - val_AUC: 0.6867 - val_AUPR: 0.7330\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3148 - accuracy: 0.8606 - precision: 0.8731 - recall: 0.9019 - AUC: 0.8902 - AUPR: 0.8672 - val_loss: 0.4910 - val_accuracy: 0.7717 - val_precision: 0.7951 - val_recall: 0.8401 - val_AUC: 0.6864 - val_AUPR: 0.7333\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3074 - accuracy: 0.8666 - precision: 0.8835 - recall: 0.8993 - AUC: 0.8956 - AUPR: 0.8690 - val_loss: 0.4907 - val_accuracy: 0.7715 - val_precision: 0.7919 - val_recall: 0.8455 - val_AUC: 0.6869 - val_AUPR: 0.7339\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3118 - accuracy: 0.8604 - precision: 0.8724 - recall: 0.9025 - AUC: 0.8916 - AUPR: 0.8630 - val_loss: 0.4902 - val_accuracy: 0.7721 - val_precision: 0.7932 - val_recall: 0.8445 - val_AUC: 0.6871 - val_AUPR: 0.7339\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3071 - accuracy: 0.8629 - precision: 0.8763 - recall: 0.9020 - AUC: 0.8959 - AUPR: 0.8671 - val_loss: 0.4908 - val_accuracy: 0.7719 - val_precision: 0.7963 - val_recall: 0.8384 - val_AUC: 0.6869 - val_AUPR: 0.7335\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.3068 - accuracy: 0.8635 - precision: 0.8767 - recall: 0.9025 - AUC: 0.8971 - AUPR: 0.8697 - val_loss: 0.4913 - val_accuracy: 0.7706 - val_precision: 0.7963 - val_recall: 0.8356 - val_AUC: 0.6873 - val_AUPR: 0.7338\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3069 - accuracy: 0.8660 - precision: 0.8822 - recall: 0.8998 - AUC: 0.8956 - AUPR: 0.8717 - val_loss: 0.4905 - val_accuracy: 0.7711 - val_precision: 0.7913 - val_recall: 0.8455 - val_AUC: 0.6871 - val_AUPR: 0.7340\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3080 - accuracy: 0.8630 - precision: 0.8738 - recall: 0.9057 - AUC: 0.8964 - AUPR: 0.8693 - val_loss: 0.4907 - val_accuracy: 0.7712 - val_precision: 0.7919 - val_recall: 0.8448 - val_AUC: 0.6871 - val_AUPR: 0.7339\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3037 - accuracy: 0.8632 - precision: 0.8758 - recall: 0.9032 - AUC: 0.8999 - AUPR: 0.8697 - val_loss: 0.4910 - val_accuracy: 0.7704 - val_precision: 0.7928 - val_recall: 0.8414 - val_AUC: 0.6871 - val_AUPR: 0.7339\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3064 - accuracy: 0.8637 - precision: 0.8761 - recall: 0.9038 - AUC: 0.8979 - AUPR: 0.8699 - val_loss: 0.4915 - val_accuracy: 0.7701 - val_precision: 0.7938 - val_recall: 0.8389 - val_AUC: 0.6871 - val_AUPR: 0.7338\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3022 - accuracy: 0.8659 - precision: 0.8804 - recall: 0.9021 - AUC: 0.9004 - AUPR: 0.8770 - val_loss: 0.4917 - val_accuracy: 0.7700 - val_precision: 0.7941 - val_recall: 0.8381 - val_AUC: 0.6871 - val_AUPR: 0.7338\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.2965 - accuracy: 0.8672 - precision: 0.8823 - recall: 0.9020 - AUC: 0.9060 - AUPR: 0.8748 - val_loss: 0.4916 - val_accuracy: 0.7701 - val_precision: 0.7944 - val_recall: 0.8378 - val_AUC: 0.6871 - val_AUPR: 0.7336\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3015 - accuracy: 0.8690 - precision: 0.8826 - recall: 0.9050 - AUC: 0.9002 - AUPR: 0.8741 - val_loss: 0.4916 - val_accuracy: 0.7708 - val_precision: 0.7947 - val_recall: 0.8389 - val_AUC: 0.6872 - val_AUPR: 0.7337\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3000 - accuracy: 0.8665 - precision: 0.8811 - recall: 0.9023 - AUC: 0.9030 - AUPR: 0.8741 - val_loss: 0.4918 - val_accuracy: 0.7715 - val_precision: 0.7954 - val_recall: 0.8390 - val_AUC: 0.6870 - val_AUPR: 0.7337\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3045 - accuracy: 0.8668 - precision: 0.8803 - recall: 0.9040 - AUC: 0.8988 - AUPR: 0.8675 - val_loss: 0.4917 - val_accuracy: 0.7708 - val_precision: 0.7941 - val_recall: 0.8399 - val_AUC: 0.6869 - val_AUPR: 0.7336\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3018 - accuracy: 0.8672 - precision: 0.8817 - recall: 0.9029 - AUC: 0.9000 - AUPR: 0.8766 - val_loss: 0.4919 - val_accuracy: 0.7712 - val_precision: 0.7946 - val_recall: 0.8398 - val_AUC: 0.6870 - val_AUPR: 0.7337\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3018 - accuracy: 0.8667 - precision: 0.8826 - recall: 0.9007 - AUC: 0.9004 - AUPR: 0.8715 - val_loss: 0.4918 - val_accuracy: 0.7708 - val_precision: 0.7935 - val_recall: 0.8410 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3038 - accuracy: 0.8666 - precision: 0.8812 - recall: 0.9025 - AUC: 0.8996 - AUPR: 0.8683 - val_loss: 0.4918 - val_accuracy: 0.7708 - val_precision: 0.7932 - val_recall: 0.8416 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3007 - accuracy: 0.8660 - precision: 0.8784 - recall: 0.9050 - AUC: 0.9029 - AUPR: 0.8724 - val_loss: 0.4918 - val_accuracy: 0.7711 - val_precision: 0.7935 - val_recall: 0.8416 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.2983 - accuracy: 0.8679 - precision: 0.8815 - recall: 0.9045 - AUC: 0.9031 - AUPR: 0.8743 - val_loss: 0.4917 - val_accuracy: 0.7709 - val_precision: 0.7932 - val_recall: 0.8417 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.2994 - accuracy: 0.8689 - precision: 0.8810 - recall: 0.9072 - AUC: 0.9012 - AUPR: 0.8767 - val_loss: 0.4918 - val_accuracy: 0.7709 - val_precision: 0.7932 - val_recall: 0.8417 - val_AUC: 0.6872 - val_AUPR: 0.7337\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3023 - accuracy: 0.8647 - precision: 0.8771 - recall: 0.9044 - AUC: 0.9016 - AUPR: 0.8737 - val_loss: 0.4918 - val_accuracy: 0.7709 - val_precision: 0.7934 - val_recall: 0.8414 - val_AUC: 0.6871 - val_AUPR: 0.7336\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3047 - accuracy: 0.8648 - precision: 0.8791 - recall: 0.9017 - AUC: 0.8989 - AUPR: 0.8707 - val_loss: 0.4919 - val_accuracy: 0.7709 - val_precision: 0.7934 - val_recall: 0.8414 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3037 - accuracy: 0.8659 - precision: 0.8778 - recall: 0.9057 - AUC: 0.8989 - AUPR: 0.8735 - val_loss: 0.4919 - val_accuracy: 0.7708 - val_precision: 0.7933 - val_recall: 0.8413 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3056 - accuracy: 0.8638 - precision: 0.8752 - recall: 0.9051 - AUC: 0.8957 - AUPR: 0.8711 - val_loss: 0.4919 - val_accuracy: 0.7708 - val_precision: 0.7934 - val_recall: 0.8411 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3011 - accuracy: 0.8676 - precision: 0.8820 - recall: 0.9033 - AUC: 0.9019 - AUPR: 0.8716 - val_loss: 0.4920 - val_accuracy: 0.7707 - val_precision: 0.7933 - val_recall: 0.8411 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3056 - accuracy: 0.8634 - precision: 0.8772 - recall: 0.9017 - AUC: 0.8980 - AUPR: 0.8743 - val_loss: 0.4920 - val_accuracy: 0.7709 - val_precision: 0.7935 - val_recall: 0.8411 - val_AUC: 0.6871 - val_AUPR: 0.7337\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00076: early stopping\n",
            "loss :  0.48528265953063965\n",
            "accuracy :  0.7726439833641052\n",
            "precision :  0.7906126976013184\n",
            "recall :  0.8503627777099609\n",
            "AUC :  0.6798481345176697\n",
            "AUPR :  0.729797899723053\n",
            "\n",
            "***********fold-5***********\n",
            "Epoch 1/300\n",
            "13/13 [==============================] - 3s 91ms/step - loss: 0.8485 - accuracy: 0.7102 - precision: 0.7466 - recall: 0.7908 - AUC: 0.5690 - AUPR: 0.6391 - val_loss: 0.5427 - val_accuracy: 0.7421 - val_precision: 0.7827 - val_recall: 0.8018 - val_AUC: 0.6039 - val_AUPR: 0.6710\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.6329 - accuracy: 0.7281 - precision: 0.7622 - recall: 0.8024 - AUC: 0.5895 - AUPR: 0.6547 - val_loss: 0.4928 - val_accuracy: 0.7687 - val_precision: 0.7927 - val_recall: 0.8431 - val_AUC: 0.6319 - val_AUPR: 0.6937\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.5359 - accuracy: 0.7472 - precision: 0.7816 - recall: 0.8097 - AUC: 0.6237 - AUPR: 0.6751 - val_loss: 0.4985 - val_accuracy: 0.7732 - val_precision: 0.7813 - val_recall: 0.8746 - val_AUC: 0.6337 - val_AUPR: 0.6934\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.5051 - accuracy: 0.7654 - precision: 0.7802 - recall: 0.8539 - AUC: 0.6449 - AUPR: 0.6885 - val_loss: 0.5022 - val_accuracy: 0.7729 - val_precision: 0.7929 - val_recall: 0.8519 - val_AUC: 0.6369 - val_AUPR: 0.6952\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4926 - accuracy: 0.7680 - precision: 0.7898 - recall: 0.8418 - AUC: 0.6495 - AUPR: 0.6917 - val_loss: 0.4974 - val_accuracy: 0.7765 - val_precision: 0.7913 - val_recall: 0.8628 - val_AUC: 0.6464 - val_AUPR: 0.7004\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4785 - accuracy: 0.7757 - precision: 0.7925 - recall: 0.8541 - AUC: 0.6746 - AUPR: 0.7021 - val_loss: 0.4978 - val_accuracy: 0.7779 - val_precision: 0.7910 - val_recall: 0.8664 - val_AUC: 0.6557 - val_AUPR: 0.7067\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4725 - accuracy: 0.7787 - precision: 0.7925 - recall: 0.8606 - AUC: 0.6810 - AUPR: 0.7083 - val_loss: 0.4925 - val_accuracy: 0.7776 - val_precision: 0.7932 - val_recall: 0.8618 - val_AUC: 0.6624 - val_AUPR: 0.7094\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4597 - accuracy: 0.7852 - precision: 0.8025 - recall: 0.8569 - AUC: 0.7034 - AUPR: 0.7208 - val_loss: 0.4882 - val_accuracy: 0.7780 - val_precision: 0.7938 - val_recall: 0.8613 - val_AUC: 0.6695 - val_AUPR: 0.7127\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4531 - accuracy: 0.7881 - precision: 0.8000 - recall: 0.8678 - AUC: 0.7169 - AUPR: 0.7278 - val_loss: 0.4877 - val_accuracy: 0.7787 - val_precision: 0.7974 - val_recall: 0.8564 - val_AUC: 0.6725 - val_AUPR: 0.7147\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4481 - accuracy: 0.7915 - precision: 0.8108 - recall: 0.8563 - AUC: 0.7263 - AUPR: 0.7343 - val_loss: 0.4837 - val_accuracy: 0.7799 - val_precision: 0.7976 - val_recall: 0.8588 - val_AUC: 0.6752 - val_AUPR: 0.7176\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4439 - accuracy: 0.7943 - precision: 0.8087 - recall: 0.8658 - AUC: 0.7314 - AUPR: 0.7382 - val_loss: 0.4819 - val_accuracy: 0.7811 - val_precision: 0.7978 - val_recall: 0.8610 - val_AUC: 0.6793 - val_AUPR: 0.7190\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4353 - accuracy: 0.7965 - precision: 0.8124 - recall: 0.8642 - AUC: 0.7479 - AUPR: 0.7513 - val_loss: 0.4782 - val_accuracy: 0.7800 - val_precision: 0.7999 - val_recall: 0.8547 - val_AUC: 0.6814 - val_AUPR: 0.7222\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4331 - accuracy: 0.7974 - precision: 0.8144 - recall: 0.8628 - AUC: 0.7533 - AUPR: 0.7529 - val_loss: 0.4808 - val_accuracy: 0.7821 - val_precision: 0.8049 - val_recall: 0.8505 - val_AUC: 0.6835 - val_AUPR: 0.7230\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4274 - accuracy: 0.8037 - precision: 0.8159 - recall: 0.8737 - AUC: 0.7563 - AUPR: 0.7574 - val_loss: 0.4818 - val_accuracy: 0.7839 - val_precision: 0.8079 - val_recall: 0.8493 - val_AUC: 0.6896 - val_AUPR: 0.7236\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.4207 - accuracy: 0.8056 - precision: 0.8221 - recall: 0.8674 - AUC: 0.7696 - AUPR: 0.7666 - val_loss: 0.4750 - val_accuracy: 0.7850 - val_precision: 0.8056 - val_recall: 0.8556 - val_AUC: 0.6889 - val_AUPR: 0.7229\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4137 - accuracy: 0.8077 - precision: 0.8212 - recall: 0.8733 - AUC: 0.7808 - AUPR: 0.7769 - val_loss: 0.4837 - val_accuracy: 0.7849 - val_precision: 0.8104 - val_recall: 0.8472 - val_AUC: 0.6822 - val_AUPR: 0.7195\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4078 - accuracy: 0.8119 - precision: 0.8300 - recall: 0.8678 - AUC: 0.7862 - AUPR: 0.7805 - val_loss: 0.4690 - val_accuracy: 0.7865 - val_precision: 0.8027 - val_recall: 0.8639 - val_AUC: 0.6892 - val_AUPR: 0.7213\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.4057 - accuracy: 0.8155 - precision: 0.8299 - recall: 0.8752 - AUC: 0.7904 - AUPR: 0.7811 - val_loss: 0.4789 - val_accuracy: 0.7859 - val_precision: 0.8168 - val_recall: 0.8389 - val_AUC: 0.6845 - val_AUPR: 0.7205\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3998 - accuracy: 0.8159 - precision: 0.8317 - recall: 0.8733 - AUC: 0.7995 - AUPR: 0.7905 - val_loss: 0.4687 - val_accuracy: 0.7891 - val_precision: 0.8110 - val_recall: 0.8552 - val_AUC: 0.6903 - val_AUPR: 0.7216\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.3997 - accuracy: 0.8163 - precision: 0.8337 - recall: 0.8711 - AUC: 0.7997 - AUPR: 0.7897 - val_loss: 0.4728 - val_accuracy: 0.7880 - val_precision: 0.8150 - val_recall: 0.8459 - val_AUC: 0.6906 - val_AUPR: 0.7277\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3941 - accuracy: 0.8211 - precision: 0.8334 - recall: 0.8814 - AUC: 0.8080 - AUPR: 0.7941 - val_loss: 0.4735 - val_accuracy: 0.7842 - val_precision: 0.8181 - val_recall: 0.8330 - val_AUC: 0.6919 - val_AUPR: 0.7266\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3828 - accuracy: 0.8257 - precision: 0.8429 - recall: 0.8762 - AUC: 0.8205 - AUPR: 0.8071 - val_loss: 0.4676 - val_accuracy: 0.7868 - val_precision: 0.8074 - val_recall: 0.8562 - val_AUC: 0.6917 - val_AUPR: 0.7257\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3844 - accuracy: 0.8250 - precision: 0.8383 - recall: 0.8818 - AUC: 0.8197 - AUPR: 0.8048 - val_loss: 0.4743 - val_accuracy: 0.7834 - val_precision: 0.8181 - val_recall: 0.8312 - val_AUC: 0.6933 - val_AUPR: 0.7247\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3805 - accuracy: 0.8282 - precision: 0.8396 - recall: 0.8861 - AUC: 0.8225 - AUPR: 0.8118 - val_loss: 0.4750 - val_accuracy: 0.7851 - val_precision: 0.8235 - val_recall: 0.8265 - val_AUC: 0.6953 - val_AUPR: 0.7243\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3776 - accuracy: 0.8272 - precision: 0.8481 - recall: 0.8713 - AUC: 0.8273 - AUPR: 0.8103 - val_loss: 0.4626 - val_accuracy: 0.7916 - val_precision: 0.8067 - val_recall: 0.8679 - val_AUC: 0.6998 - val_AUPR: 0.7270\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3744 - accuracy: 0.8319 - precision: 0.8447 - recall: 0.8859 - AUC: 0.8304 - AUPR: 0.8113 - val_loss: 0.4689 - val_accuracy: 0.7909 - val_precision: 0.8245 - val_recall: 0.8369 - val_AUC: 0.6986 - val_AUPR: 0.7265\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.3669 - accuracy: 0.8338 - precision: 0.8506 - recall: 0.8808 - AUC: 0.8398 - AUPR: 0.8153 - val_loss: 0.4692 - val_accuracy: 0.7884 - val_precision: 0.8161 - val_recall: 0.8452 - val_AUC: 0.6957 - val_AUPR: 0.7230\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3674 - accuracy: 0.8328 - precision: 0.8468 - recall: 0.8846 - AUC: 0.8400 - AUPR: 0.8184 - val_loss: 0.4710 - val_accuracy: 0.7909 - val_precision: 0.8202 - val_recall: 0.8437 - val_AUC: 0.6964 - val_AUPR: 0.7214\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3624 - accuracy: 0.8352 - precision: 0.8505 - recall: 0.8838 - AUC: 0.8443 - AUPR: 0.8252 - val_loss: 0.4677 - val_accuracy: 0.7905 - val_precision: 0.8181 - val_recall: 0.8463 - val_AUC: 0.6960 - val_AUPR: 0.7233\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3605 - accuracy: 0.8376 - precision: 0.8500 - recall: 0.8893 - AUC: 0.8448 - AUPR: 0.8247 - val_loss: 0.4762 - val_accuracy: 0.7872 - val_precision: 0.8255 - val_recall: 0.8276 - val_AUC: 0.6961 - val_AUPR: 0.7252\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3582 - accuracy: 0.8376 - precision: 0.8523 - recall: 0.8858 - AUC: 0.8495 - AUPR: 0.8277 - val_loss: 0.4717 - val_accuracy: 0.7865 - val_precision: 0.8268 - val_recall: 0.8242 - val_AUC: 0.6977 - val_AUPR: 0.7243\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3562 - accuracy: 0.8405 - precision: 0.8551 - recall: 0.8874 - AUC: 0.8536 - AUPR: 0.8311 - val_loss: 0.4685 - val_accuracy: 0.7908 - val_precision: 0.8217 - val_recall: 0.8411 - val_AUC: 0.7008 - val_AUPR: 0.7259\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3516 - accuracy: 0.8407 - precision: 0.8586 - recall: 0.8830 - AUC: 0.8578 - AUPR: 0.8330 - val_loss: 0.4666 - val_accuracy: 0.7886 - val_precision: 0.8160 - val_recall: 0.8458 - val_AUC: 0.7024 - val_AUPR: 0.7277\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3450 - accuracy: 0.8463 - precision: 0.8602 - recall: 0.8915 - AUC: 0.8623 - AUPR: 0.8313 - val_loss: 0.4651 - val_accuracy: 0.7906 - val_precision: 0.8165 - val_recall: 0.8492 - val_AUC: 0.7051 - val_AUPR: 0.7272\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3475 - accuracy: 0.8419 - precision: 0.8554 - recall: 0.8900 - AUC: 0.8616 - AUPR: 0.8413 - val_loss: 0.4654 - val_accuracy: 0.7917 - val_precision: 0.8195 - val_recall: 0.8465 - val_AUC: 0.7074 - val_AUPR: 0.7285\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3399 - accuracy: 0.8482 - precision: 0.8611 - recall: 0.8941 - AUC: 0.8670 - AUPR: 0.8453 - val_loss: 0.4678 - val_accuracy: 0.7907 - val_precision: 0.8246 - val_recall: 0.8363 - val_AUC: 0.7066 - val_AUPR: 0.7287\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.3435 - accuracy: 0.8477 - precision: 0.8619 - recall: 0.8920 - AUC: 0.8638 - AUPR: 0.8394 - val_loss: 0.4682 - val_accuracy: 0.7911 - val_precision: 0.8221 - val_recall: 0.8411 - val_AUC: 0.7054 - val_AUPR: 0.7287\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3403 - accuracy: 0.8475 - precision: 0.8614 - recall: 0.8922 - AUC: 0.8679 - AUPR: 0.8425 - val_loss: 0.4686 - val_accuracy: 0.7902 - val_precision: 0.8239 - val_recall: 0.8365 - val_AUC: 0.7043 - val_AUPR: 0.7283\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3386 - accuracy: 0.8472 - precision: 0.8615 - recall: 0.8915 - AUC: 0.8699 - AUPR: 0.8488 - val_loss: 0.4665 - val_accuracy: 0.7912 - val_precision: 0.8198 - val_recall: 0.8449 - val_AUC: 0.7052 - val_AUPR: 0.7293\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3358 - accuracy: 0.8487 - precision: 0.8603 - recall: 0.8962 - AUC: 0.8724 - AUPR: 0.8444 - val_loss: 0.4666 - val_accuracy: 0.7905 - val_precision: 0.8211 - val_recall: 0.8414 - val_AUC: 0.7058 - val_AUPR: 0.7294\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3376 - accuracy: 0.8488 - precision: 0.8636 - recall: 0.8917 - AUC: 0.8720 - AUPR: 0.8422 - val_loss: 0.4673 - val_accuracy: 0.7896 - val_precision: 0.8220 - val_recall: 0.8381 - val_AUC: 0.7061 - val_AUPR: 0.7301\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3320 - accuracy: 0.8519 - precision: 0.8641 - recall: 0.8970 - AUC: 0.8761 - AUPR: 0.8541 - val_loss: 0.4674 - val_accuracy: 0.7908 - val_precision: 0.8237 - val_recall: 0.8380 - val_AUC: 0.7066 - val_AUPR: 0.7303\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3381 - accuracy: 0.8458 - precision: 0.8622 - recall: 0.8878 - AUC: 0.8690 - AUPR: 0.8447 - val_loss: 0.4688 - val_accuracy: 0.7900 - val_precision: 0.8262 - val_recall: 0.8323 - val_AUC: 0.7065 - val_AUPR: 0.7299\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3330 - accuracy: 0.8489 - precision: 0.8634 - recall: 0.8923 - AUC: 0.8775 - AUPR: 0.8555 - val_loss: 0.4687 - val_accuracy: 0.7893 - val_precision: 0.8233 - val_recall: 0.8356 - val_AUC: 0.7063 - val_AUPR: 0.7296\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3332 - accuracy: 0.8512 - precision: 0.8664 - recall: 0.8924 - AUC: 0.8747 - AUPR: 0.8517 - val_loss: 0.4682 - val_accuracy: 0.7905 - val_precision: 0.8229 - val_recall: 0.8386 - val_AUC: 0.7055 - val_AUPR: 0.7293\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3324 - accuracy: 0.8512 - precision: 0.8646 - recall: 0.8949 - AUC: 0.8750 - AUPR: 0.8489 - val_loss: 0.4679 - val_accuracy: 0.7907 - val_precision: 0.8226 - val_recall: 0.8395 - val_AUC: 0.7057 - val_AUPR: 0.7293\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3317 - accuracy: 0.8510 - precision: 0.8635 - recall: 0.8960 - AUC: 0.8759 - AUPR: 0.8487 - val_loss: 0.4678 - val_accuracy: 0.7902 - val_precision: 0.8225 - val_recall: 0.8384 - val_AUC: 0.7057 - val_AUPR: 0.7293\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3294 - accuracy: 0.8535 - precision: 0.8664 - recall: 0.8969 - AUC: 0.8770 - AUPR: 0.8526 - val_loss: 0.4682 - val_accuracy: 0.7905 - val_precision: 0.8239 - val_recall: 0.8371 - val_AUC: 0.7056 - val_AUPR: 0.7294\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3269 - accuracy: 0.8540 - precision: 0.8672 - recall: 0.8967 - AUC: 0.8807 - AUPR: 0.8505 - val_loss: 0.4681 - val_accuracy: 0.7906 - val_precision: 0.8241 - val_recall: 0.8369 - val_AUC: 0.7057 - val_AUPR: 0.7294\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3231 - accuracy: 0.8565 - precision: 0.8725 - recall: 0.8943 - AUC: 0.8827 - AUPR: 0.8564 - val_loss: 0.4676 - val_accuracy: 0.7917 - val_precision: 0.8246 - val_recall: 0.8384 - val_AUC: 0.7056 - val_AUPR: 0.7295\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3265 - accuracy: 0.8550 - precision: 0.8673 - recall: 0.8985 - AUC: 0.8798 - AUPR: 0.8545 - val_loss: 0.4677 - val_accuracy: 0.7917 - val_precision: 0.8245 - val_recall: 0.8386 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3325 - accuracy: 0.8519 - precision: 0.8662 - recall: 0.8940 - AUC: 0.8764 - AUPR: 0.8519 - val_loss: 0.4677 - val_accuracy: 0.7911 - val_precision: 0.8241 - val_recall: 0.8378 - val_AUC: 0.7058 - val_AUPR: 0.7295\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3278 - accuracy: 0.8538 - precision: 0.8684 - recall: 0.8945 - AUC: 0.8798 - AUPR: 0.8566 - val_loss: 0.4676 - val_accuracy: 0.7907 - val_precision: 0.8237 - val_recall: 0.8377 - val_AUC: 0.7058 - val_AUPR: 0.7295\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3295 - accuracy: 0.8522 - precision: 0.8643 - recall: 0.8974 - AUC: 0.8787 - AUPR: 0.8511 - val_loss: 0.4674 - val_accuracy: 0.7910 - val_precision: 0.8234 - val_recall: 0.8387 - val_AUC: 0.7057 - val_AUPR: 0.7296\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3240 - accuracy: 0.8567 - precision: 0.8716 - recall: 0.8958 - AUC: 0.8836 - AUPR: 0.8571 - val_loss: 0.4676 - val_accuracy: 0.7905 - val_precision: 0.8234 - val_recall: 0.8378 - val_AUC: 0.7058 - val_AUPR: 0.7296\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3272 - accuracy: 0.8548 - precision: 0.8694 - recall: 0.8953 - AUC: 0.8801 - AUPR: 0.8518 - val_loss: 0.4676 - val_accuracy: 0.7902 - val_precision: 0.8230 - val_recall: 0.8378 - val_AUC: 0.7058 - val_AUPR: 0.7296\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3283 - accuracy: 0.8546 - precision: 0.8684 - recall: 0.8962 - AUC: 0.8781 - AUPR: 0.8581 - val_loss: 0.4676 - val_accuracy: 0.7905 - val_precision: 0.8233 - val_recall: 0.8380 - val_AUC: 0.7059 - val_AUPR: 0.7297\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3237 - accuracy: 0.8542 - precision: 0.8664 - recall: 0.8981 - AUC: 0.8838 - AUPR: 0.8620 - val_loss: 0.4677 - val_accuracy: 0.7902 - val_precision: 0.8232 - val_recall: 0.8375 - val_AUC: 0.7058 - val_AUPR: 0.7296\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3251 - accuracy: 0.8547 - precision: 0.8687 - recall: 0.8960 - AUC: 0.8819 - AUPR: 0.8561 - val_loss: 0.4677 - val_accuracy: 0.7902 - val_precision: 0.8232 - val_recall: 0.8375 - val_AUC: 0.7058 - val_AUPR: 0.7295\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3227 - accuracy: 0.8571 - precision: 0.8702 - recall: 0.8986 - AUC: 0.8857 - AUPR: 0.8636 - val_loss: 0.4676 - val_accuracy: 0.7906 - val_precision: 0.8235 - val_recall: 0.8378 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3282 - accuracy: 0.8544 - precision: 0.8703 - recall: 0.8932 - AUC: 0.8792 - AUPR: 0.8518 - val_loss: 0.4676 - val_accuracy: 0.7902 - val_precision: 0.8230 - val_recall: 0.8380 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.3233 - accuracy: 0.8561 - precision: 0.8696 - recall: 0.8974 - AUC: 0.8842 - AUPR: 0.8570 - val_loss: 0.4676 - val_accuracy: 0.7903 - val_precision: 0.8230 - val_recall: 0.8381 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 0.3267 - accuracy: 0.8543 - precision: 0.8661 - recall: 0.8988 - AUC: 0.8807 - AUPR: 0.8650 - val_loss: 0.4676 - val_accuracy: 0.7903 - val_precision: 0.8233 - val_recall: 0.8377 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.3279 - accuracy: 0.8521 - precision: 0.8651 - recall: 0.8960 - AUC: 0.8788 - AUPR: 0.8507 - val_loss: 0.4677 - val_accuracy: 0.7905 - val_precision: 0.8234 - val_recall: 0.8378 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.3296 - accuracy: 0.8523 - precision: 0.8642 - recall: 0.8977 - AUC: 0.8785 - AUPR: 0.8565 - val_loss: 0.4678 - val_accuracy: 0.7907 - val_precision: 0.8238 - val_recall: 0.8375 - val_AUC: 0.7057 - val_AUPR: 0.7295\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00065: early stopping\n",
            "loss :  0.46255847811698914\n",
            "accuracy :  0.7916208505630493\n",
            "precision :  0.8067028522491455\n",
            "recall :  0.8678934574127197\n",
            "AUC :  0.6997802257537842\n",
            "AUPR :  0.7269598841667175\n",
            "\n",
            "******************************************************************\n",
            "[[0.47255567 0.78299034 0.78447795 0.87145293 0.70006603 0.70931298]\n",
            " [0.45226294 0.7921353  0.82748115 0.84028292 0.71466321 0.74720967]\n",
            " [0.45816079 0.78555101 0.80700511 0.85258424 0.71192557 0.75004607]\n",
            " [0.48528266 0.77264398 0.7906127  0.85036278 0.67984813 0.7297979 ]\n",
            " [0.46255848 0.79162085 0.80670285 0.86789346 0.69978023 0.72695988]]\n",
            "-Accuracy score_mean:0.7849882960319519\n",
            "-Accuracy score_mean:[[0.78299034]\n",
            " [0.7921353 ]\n",
            " [0.78555101]\n",
            " [0.77264398]\n",
            " [0.79162085]]\n",
            "-Accuracy score_mean:0.007095927944546064\n",
            "-Precision score_mean:0.8032559514045715\n",
            "-Precision score_mean:0.015001751958980177\n",
            "-Recall score_mean:0.8565152645111084\n",
            "-Recall score_mean:0.011570584966198068\n",
            "-AUC score_mean:0.7012566328048706\n",
            "-AUC score_mean:0.012292139742715914\n",
            "-AUPR score_mean:0.7326653003692627\n",
            "-AUPR score_mean:0.014830608764722064\n",
            "total running time: 2.656311889489492 minites\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJPjOnDSSxxX",
        "outputId": "c652ac9b-8d02-4bcc-b7cd-e03d452aa96c"
      },
      "source": [
        "model.evaluate(c_x_test,c_y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 6ms/step - loss: 0.4384 - accuracy: 0.7979 - precision: 0.8241 - recall: 0.8691 - AUC: 0.7203 - AUPR: 0.7723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.7202785611152649,\n",
              " 'AUPR': 0.7722816467285156,\n",
              " 'accuracy': 0.7978600859642029,\n",
              " 'loss': 0.4383724331855774,\n",
              " 'precision': 0.8240898847579956,\n",
              " 'recall': 0.869105875492096}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg5JLigX3SKR"
      },
      "source": [
        "results = np.array(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU2k3hOk3USh",
        "outputId": "f477ac1b-d544-480e-d35b-69ce2ffdeea2"
      },
      "source": [
        "results[:,[0,1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45393258, 0.79259253],\n",
              "       [0.44793907, 0.7912758 ],\n",
              "       [0.47174028, 0.77547336],\n",
              "       [0.46548608, 0.78016984],\n",
              "       [0.46501675, 0.78833622]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MHgC_32LZFY",
        "outputId": "a170786d-aaa2-43ce-c495-dfdfeaaf0710"
      },
      "source": [
        "#加载最佳参数，重新训练整个训练集+验证集，再将训练好的模型在测试集上测试\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "model2 = load_model('./model/model_FP_masking_cross5.h5')\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(c_X_train)\n",
        "c_X_train = scaler.transform(c_X_train)\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(c_x_test)\n",
        "c_x_test = scaler.transform(c_x_test)\n",
        "\n",
        "\n",
        "history  = model2.fit(c_X_train,c_Y_train,batch_size=128, epochs=400,validation_data=(c_x_test,c_y_test),callbacks=callbacks)\n",
        "# history  = model2.fit(c_X_train,c_Y_train,batch_size=128, epochs=400)\n",
        "model2.evaluate(c_x_test,c_y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "16/16 [==============================] - 3s 75ms/step - loss: 0.8837 - accuracy: 0.7700 - precision: 0.8076 - recall: 0.8187 - AUC: 0.6850 - AUPR: 0.7126 - val_loss: 0.6622 - val_accuracy: 0.7376 - val_precision: 0.8144 - val_recall: 0.7632 - val_AUC: 0.6279 - val_AUPR: 0.7016\n",
            "Epoch 2/400\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.5805 - accuracy: 0.7809 - precision: 0.8200 - recall: 0.8197 - AUC: 0.7375 - AUPR: 0.7479 - val_loss: 0.5426 - val_accuracy: 0.7845 - val_precision: 0.8185 - val_recall: 0.8516 - val_AUC: 0.6529 - val_AUPR: 0.7191\n",
            "Epoch 3/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.5050 - accuracy: 0.7938 - precision: 0.8261 - recall: 0.8370 - AUC: 0.7544 - AUPR: 0.7616 - val_loss: 0.4862 - val_accuracy: 0.7834 - val_precision: 0.8243 - val_recall: 0.8400 - val_AUC: 0.6868 - val_AUPR: 0.7477\n",
            "Epoch 4/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4704 - accuracy: 0.7995 - precision: 0.8244 - recall: 0.8515 - AUC: 0.7671 - AUPR: 0.7664 - val_loss: 0.4718 - val_accuracy: 0.7908 - val_precision: 0.8463 - val_recall: 0.8217 - val_AUC: 0.7026 - val_AUPR: 0.7573\n",
            "Epoch 5/400\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.4529 - accuracy: 0.8042 - precision: 0.8309 - recall: 0.8511 - AUC: 0.7794 - AUPR: 0.7815 - val_loss: 0.4579 - val_accuracy: 0.7956 - val_precision: 0.8418 - val_recall: 0.8374 - val_AUC: 0.7136 - val_AUPR: 0.7701\n",
            "Epoch 6/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4307 - accuracy: 0.8105 - precision: 0.8327 - recall: 0.8613 - AUC: 0.7932 - AUPR: 0.7886 - val_loss: 0.4478 - val_accuracy: 0.8003 - val_precision: 0.8391 - val_recall: 0.8506 - val_AUC: 0.7192 - val_AUPR: 0.7747\n",
            "Epoch 7/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4135 - accuracy: 0.8155 - precision: 0.8388 - recall: 0.8624 - AUC: 0.8078 - AUPR: 0.8063 - val_loss: 0.4457 - val_accuracy: 0.7984 - val_precision: 0.8325 - val_recall: 0.8567 - val_AUC: 0.7202 - val_AUPR: 0.7754\n",
            "Epoch 8/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4122 - accuracy: 0.8165 - precision: 0.8395 - recall: 0.8631 - AUC: 0.8084 - AUPR: 0.7990 - val_loss: 0.4605 - val_accuracy: 0.7990 - val_precision: 0.8573 - val_recall: 0.8222 - val_AUC: 0.7294 - val_AUPR: 0.7789\n",
            "Epoch 9/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.4011 - accuracy: 0.8192 - precision: 0.8371 - recall: 0.8724 - AUC: 0.8192 - AUPR: 0.8091 - val_loss: 0.4408 - val_accuracy: 0.8043 - val_precision: 0.8451 - val_recall: 0.8493 - val_AUC: 0.7248 - val_AUPR: 0.7806\n",
            "Epoch 10/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3979 - accuracy: 0.8208 - precision: 0.8474 - recall: 0.8600 - AUC: 0.8234 - AUPR: 0.8110 - val_loss: 0.4379 - val_accuracy: 0.8058 - val_precision: 0.8370 - val_recall: 0.8642 - val_AUC: 0.7262 - val_AUPR: 0.7812\n",
            "Epoch 11/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3869 - accuracy: 0.8261 - precision: 0.8474 - recall: 0.8707 - AUC: 0.8287 - AUPR: 0.8191 - val_loss: 0.4410 - val_accuracy: 0.8063 - val_precision: 0.8504 - val_recall: 0.8454 - val_AUC: 0.7349 - val_AUPR: 0.7843\n",
            "Epoch 12/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3788 - accuracy: 0.8295 - precision: 0.8473 - recall: 0.8778 - AUC: 0.8370 - AUPR: 0.8252 - val_loss: 0.4361 - val_accuracy: 0.8069 - val_precision: 0.8506 - val_recall: 0.8464 - val_AUC: 0.7358 - val_AUPR: 0.7862\n",
            "Epoch 13/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3779 - accuracy: 0.8306 - precision: 0.8526 - recall: 0.8723 - AUC: 0.8375 - AUPR: 0.8243 - val_loss: 0.4315 - val_accuracy: 0.8114 - val_precision: 0.8473 - val_recall: 0.8596 - val_AUC: 0.7400 - val_AUPR: 0.7888\n",
            "Epoch 14/400\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3688 - accuracy: 0.8339 - precision: 0.8523 - recall: 0.8792 - AUC: 0.8479 - AUPR: 0.8365 - val_loss: 0.4345 - val_accuracy: 0.8084 - val_precision: 0.8553 - val_recall: 0.8426 - val_AUC: 0.7380 - val_AUPR: 0.7886\n",
            "Epoch 15/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3664 - accuracy: 0.8330 - precision: 0.8538 - recall: 0.8753 - AUC: 0.8474 - AUPR: 0.8354 - val_loss: 0.4323 - val_accuracy: 0.8100 - val_precision: 0.8437 - val_recall: 0.8624 - val_AUC: 0.7377 - val_AUPR: 0.7858\n",
            "Epoch 16/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3610 - accuracy: 0.8373 - precision: 0.8549 - recall: 0.8822 - AUC: 0.8540 - AUPR: 0.8376 - val_loss: 0.4373 - val_accuracy: 0.8069 - val_precision: 0.8548 - val_recall: 0.8405 - val_AUC: 0.7440 - val_AUPR: 0.7901\n",
            "Epoch 17/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3620 - accuracy: 0.8370 - precision: 0.8567 - recall: 0.8789 - AUC: 0.8546 - AUPR: 0.8407 - val_loss: 0.4340 - val_accuracy: 0.8095 - val_precision: 0.8427 - val_recall: 0.8629 - val_AUC: 0.7391 - val_AUPR: 0.7895\n",
            "Epoch 18/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3527 - accuracy: 0.8400 - precision: 0.8567 - recall: 0.8849 - AUC: 0.8609 - AUPR: 0.8435 - val_loss: 0.4393 - val_accuracy: 0.8059 - val_precision: 0.8513 - val_recall: 0.8436 - val_AUC: 0.7363 - val_AUPR: 0.7893\n",
            "Epoch 19/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3463 - accuracy: 0.8449 - precision: 0.8611 - recall: 0.8881 - AUC: 0.8663 - AUPR: 0.8479 - val_loss: 0.4368 - val_accuracy: 0.8054 - val_precision: 0.8528 - val_recall: 0.8405 - val_AUC: 0.7426 - val_AUPR: 0.7915\n",
            "Epoch 20/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3496 - accuracy: 0.8429 - precision: 0.8594 - recall: 0.8868 - AUC: 0.8638 - AUPR: 0.8431 - val_loss: 0.4391 - val_accuracy: 0.8077 - val_precision: 0.8616 - val_recall: 0.8328 - val_AUC: 0.7443 - val_AUPR: 0.7924\n",
            "Epoch 21/400\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3472 - accuracy: 0.8436 - precision: 0.8634 - recall: 0.8824 - AUC: 0.8667 - AUPR: 0.8522 - val_loss: 0.4358 - val_accuracy: 0.8087 - val_precision: 0.8458 - val_recall: 0.8567 - val_AUC: 0.7372 - val_AUPR: 0.7891\n",
            "Epoch 22/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3429 - accuracy: 0.8455 - precision: 0.8643 - recall: 0.8848 - AUC: 0.8712 - AUPR: 0.8554 - val_loss: 0.4437 - val_accuracy: 0.8074 - val_precision: 0.8507 - val_recall: 0.8472 - val_AUC: 0.7334 - val_AUPR: 0.7886\n",
            "Epoch 23/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3419 - accuracy: 0.8467 - precision: 0.8637 - recall: 0.8881 - AUC: 0.8701 - AUPR: 0.8557 - val_loss: 0.4471 - val_accuracy: 0.8044 - val_precision: 0.8554 - val_recall: 0.8351 - val_AUC: 0.7345 - val_AUPR: 0.7861\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 24/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3336 - accuracy: 0.8509 - precision: 0.8725 - recall: 0.8840 - AUC: 0.8788 - AUPR: 0.8627 - val_loss: 0.4419 - val_accuracy: 0.8072 - val_precision: 0.8476 - val_recall: 0.8513 - val_AUC: 0.7340 - val_AUPR: 0.7872\n",
            "Epoch 25/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3277 - accuracy: 0.8534 - precision: 0.8657 - recall: 0.8982 - AUC: 0.8832 - AUPR: 0.8650 - val_loss: 0.4424 - val_accuracy: 0.8053 - val_precision: 0.8447 - val_recall: 0.8518 - val_AUC: 0.7324 - val_AUPR: 0.7880\n",
            "Epoch 26/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3323 - accuracy: 0.8534 - precision: 0.8708 - recall: 0.8912 - AUC: 0.8782 - AUPR: 0.8577 - val_loss: 0.4420 - val_accuracy: 0.8074 - val_precision: 0.8514 - val_recall: 0.8462 - val_AUC: 0.7349 - val_AUPR: 0.7887\n",
            "Epoch 27/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3247 - accuracy: 0.8531 - precision: 0.8724 - recall: 0.8883 - AUC: 0.8853 - AUPR: 0.8656 - val_loss: 0.4409 - val_accuracy: 0.8077 - val_precision: 0.8477 - val_recall: 0.8521 - val_AUC: 0.7356 - val_AUPR: 0.7899\n",
            "Epoch 28/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3256 - accuracy: 0.8540 - precision: 0.8688 - recall: 0.8951 - AUC: 0.8832 - AUPR: 0.8645 - val_loss: 0.4384 - val_accuracy: 0.8081 - val_precision: 0.8466 - val_recall: 0.8544 - val_AUC: 0.7378 - val_AUPR: 0.7907\n",
            "Epoch 29/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3212 - accuracy: 0.8567 - precision: 0.8725 - recall: 0.8952 - AUC: 0.8876 - AUPR: 0.8694 - val_loss: 0.4398 - val_accuracy: 0.8077 - val_precision: 0.8490 - val_recall: 0.8503 - val_AUC: 0.7387 - val_AUPR: 0.7900\n",
            "Epoch 30/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3212 - accuracy: 0.8574 - precision: 0.8742 - recall: 0.8940 - AUC: 0.8878 - AUPR: 0.8693 - val_loss: 0.4404 - val_accuracy: 0.8071 - val_precision: 0.8479 - val_recall: 0.8506 - val_AUC: 0.7378 - val_AUPR: 0.7895\n",
            "Epoch 31/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3221 - accuracy: 0.8548 - precision: 0.8712 - recall: 0.8933 - AUC: 0.8873 - AUPR: 0.8678 - val_loss: 0.4392 - val_accuracy: 0.8104 - val_precision: 0.8498 - val_recall: 0.8542 - val_AUC: 0.7383 - val_AUPR: 0.7903\n",
            "Epoch 32/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3182 - accuracy: 0.8571 - precision: 0.8717 - recall: 0.8970 - AUC: 0.8906 - AUPR: 0.8713 - val_loss: 0.4394 - val_accuracy: 0.8079 - val_precision: 0.8488 - val_recall: 0.8508 - val_AUC: 0.7398 - val_AUPR: 0.7904\n",
            "Epoch 33/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3187 - accuracy: 0.8582 - precision: 0.8757 - recall: 0.8936 - AUC: 0.8898 - AUPR: 0.8688 - val_loss: 0.4391 - val_accuracy: 0.8099 - val_precision: 0.8498 - val_recall: 0.8531 - val_AUC: 0.7405 - val_AUPR: 0.7907\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 34/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3173 - accuracy: 0.8590 - precision: 0.8729 - recall: 0.8990 - AUC: 0.8906 - AUPR: 0.8752 - val_loss: 0.4394 - val_accuracy: 0.8095 - val_precision: 0.8503 - val_recall: 0.8518 - val_AUC: 0.7408 - val_AUPR: 0.7907\n",
            "Epoch 35/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3175 - accuracy: 0.8580 - precision: 0.8756 - recall: 0.8934 - AUC: 0.8913 - AUPR: 0.8711 - val_loss: 0.4391 - val_accuracy: 0.8100 - val_precision: 0.8499 - val_recall: 0.8534 - val_AUC: 0.7410 - val_AUPR: 0.7909\n",
            "Epoch 36/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3167 - accuracy: 0.8592 - precision: 0.8745 - recall: 0.8971 - AUC: 0.8908 - AUPR: 0.8688 - val_loss: 0.4389 - val_accuracy: 0.8099 - val_precision: 0.8491 - val_recall: 0.8542 - val_AUC: 0.7409 - val_AUPR: 0.7911\n",
            "Epoch 37/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3151 - accuracy: 0.8595 - precision: 0.8744 - recall: 0.8979 - AUC: 0.8937 - AUPR: 0.8776 - val_loss: 0.4389 - val_accuracy: 0.8092 - val_precision: 0.8493 - val_recall: 0.8526 - val_AUC: 0.7415 - val_AUPR: 0.7908\n",
            "Epoch 38/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3127 - accuracy: 0.8616 - precision: 0.8770 - recall: 0.8983 - AUC: 0.8935 - AUPR: 0.8697 - val_loss: 0.4393 - val_accuracy: 0.8087 - val_precision: 0.8499 - val_recall: 0.8508 - val_AUC: 0.7414 - val_AUPR: 0.7910\n",
            "Epoch 39/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3180 - accuracy: 0.8585 - precision: 0.8742 - recall: 0.8962 - AUC: 0.8904 - AUPR: 0.8692 - val_loss: 0.4395 - val_accuracy: 0.8076 - val_precision: 0.8493 - val_recall: 0.8495 - val_AUC: 0.7416 - val_AUPR: 0.7912\n",
            "Epoch 40/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3113 - accuracy: 0.8607 - precision: 0.8780 - recall: 0.8954 - AUC: 0.8963 - AUPR: 0.8738 - val_loss: 0.4393 - val_accuracy: 0.8079 - val_precision: 0.8479 - val_recall: 0.8521 - val_AUC: 0.7411 - val_AUPR: 0.7909\n",
            "Epoch 41/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3140 - accuracy: 0.8605 - precision: 0.8759 - recall: 0.8976 - AUC: 0.8933 - AUPR: 0.8720 - val_loss: 0.4392 - val_accuracy: 0.8086 - val_precision: 0.8488 - val_recall: 0.8521 - val_AUC: 0.7414 - val_AUPR: 0.7911\n",
            "Epoch 42/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3147 - accuracy: 0.8599 - precision: 0.8761 - recall: 0.8962 - AUC: 0.8938 - AUPR: 0.8760 - val_loss: 0.4391 - val_accuracy: 0.8084 - val_precision: 0.8484 - val_recall: 0.8524 - val_AUC: 0.7414 - val_AUPR: 0.7911\n",
            "Epoch 43/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3103 - accuracy: 0.8623 - precision: 0.8765 - recall: 0.9004 - AUC: 0.8962 - AUPR: 0.8726 - val_loss: 0.4394 - val_accuracy: 0.8077 - val_precision: 0.8479 - val_recall: 0.8518 - val_AUC: 0.7413 - val_AUPR: 0.7907\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 44/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3176 - accuracy: 0.8587 - precision: 0.8714 - recall: 0.9005 - AUC: 0.8927 - AUPR: 0.8720 - val_loss: 0.4395 - val_accuracy: 0.8077 - val_precision: 0.8481 - val_recall: 0.8516 - val_AUC: 0.7413 - val_AUPR: 0.7907\n",
            "Epoch 45/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3110 - accuracy: 0.8602 - precision: 0.8753 - recall: 0.8980 - AUC: 0.8975 - AUPR: 0.8766 - val_loss: 0.4395 - val_accuracy: 0.8081 - val_precision: 0.8483 - val_recall: 0.8518 - val_AUC: 0.7413 - val_AUPR: 0.7908\n",
            "Epoch 46/400\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.3149 - accuracy: 0.8586 - precision: 0.8758 - recall: 0.8944 - AUC: 0.8936 - AUPR: 0.8758 - val_loss: 0.4395 - val_accuracy: 0.8082 - val_precision: 0.8484 - val_recall: 0.8521 - val_AUC: 0.7413 - val_AUPR: 0.7907\n",
            "Epoch 47/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3150 - accuracy: 0.8600 - precision: 0.8768 - recall: 0.8956 - AUC: 0.8929 - AUPR: 0.8751 - val_loss: 0.4395 - val_accuracy: 0.8082 - val_precision: 0.8484 - val_recall: 0.8521 - val_AUC: 0.7413 - val_AUPR: 0.7907\n",
            "Epoch 48/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3135 - accuracy: 0.8628 - precision: 0.8770 - recall: 0.9007 - AUC: 0.8936 - AUPR: 0.8738 - val_loss: 0.4395 - val_accuracy: 0.8079 - val_precision: 0.8483 - val_recall: 0.8516 - val_AUC: 0.7413 - val_AUPR: 0.7908\n",
            "Epoch 49/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3111 - accuracy: 0.8616 - precision: 0.8758 - recall: 0.9001 - AUC: 0.8953 - AUPR: 0.8770 - val_loss: 0.4395 - val_accuracy: 0.8081 - val_precision: 0.8485 - val_recall: 0.8516 - val_AUC: 0.7414 - val_AUPR: 0.7908\n",
            "Epoch 50/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3168 - accuracy: 0.8588 - precision: 0.8763 - recall: 0.8939 - AUC: 0.8922 - AUPR: 0.8691 - val_loss: 0.4395 - val_accuracy: 0.8081 - val_precision: 0.8485 - val_recall: 0.8516 - val_AUC: 0.7414 - val_AUPR: 0.7907\n",
            "Epoch 51/400\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3184 - accuracy: 0.8583 - precision: 0.8724 - recall: 0.8983 - AUC: 0.8910 - AUPR: 0.8755 - val_loss: 0.4395 - val_accuracy: 0.8082 - val_precision: 0.8486 - val_recall: 0.8518 - val_AUC: 0.7414 - val_AUPR: 0.7908\n",
            "Epoch 52/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3175 - accuracy: 0.8605 - precision: 0.8748 - recall: 0.8991 - AUC: 0.8913 - AUPR: 0.8742 - val_loss: 0.4395 - val_accuracy: 0.8077 - val_precision: 0.8486 - val_recall: 0.8508 - val_AUC: 0.7416 - val_AUPR: 0.7907\n",
            "Epoch 53/400\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.3162 - accuracy: 0.8596 - precision: 0.8759 - recall: 0.8960 - AUC: 0.8928 - AUPR: 0.8762 - val_loss: 0.4395 - val_accuracy: 0.8079 - val_precision: 0.8487 - val_recall: 0.8511 - val_AUC: 0.7417 - val_AUPR: 0.7907\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00053: early stopping\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8114 - precision: 0.8473 - recall: 0.8596 - AUC: 0.7400 - AUPR: 0.7888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.7400299906730652,\n",
              " 'AUPR': 0.7887771725654602,\n",
              " 'accuracy': 0.8113579750061035,\n",
              " 'loss': 0.4315369725227356,\n",
              " 'precision': 0.8473457098007202,\n",
              " 'recall': 0.8595722913742065}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ihSto4fkLg53",
        "outputId": "f52604f0-9ad3-4cfe-84fe-67af3eb842a1"
      },
      "source": [
        "fig, ax = plt.subplots(1, 6, figsize=(25, 4))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate([\"loss\",\"accuracy\",'precision','recall','AUC','AUPR']):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history[\"val_\" + met])\n",
        "    ax[i].set_title(\"mpnn {}\".format(met))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jgd4NawOoWh"
      },
      "source": [
        "# 模型融合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQIDjSFOq7m"
      },
      "source": [
        "# from keras.models import load_model\n",
        "# model2 = load_model('./model/model_FP22.h5')\n",
        "\n",
        "y_pre1 = model2.predict(c_x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbhK-TQWPDfY"
      },
      "source": [
        "**gin_edge**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKbwvlH1PMV-"
      },
      "source": [
        "X1 = np.load('./data/gin_supervised_edgepred.npy')\n",
        "x1_train,x1_test,y_train,y_test= train_test_split(X1,y,test_size=0.1,random_state=2021)\n",
        "model1 = load_model('./model/model_edgepred22.h5')\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model1.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "history  = model1.fit(x1_train,y_train,batch_size=128, epochs=400,validation_data=(x1_test,y_test),callbacks=callbacks)\n",
        "model1.evaluate(x1_test,y_test,return_dict=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJEKmIouPcf9"
      },
      "source": [
        "x1_train,x1_test,y_train,y_test= train_test_split(X1,y,test_size=0.1,random_state=2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-EORuqFPvP3",
        "outputId": "6438a7da-9ff9-4bab-e71f-c1db990d6686"
      },
      "source": [
        "model1 = load_model('./model/model_edgepred22.h5')\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model1.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "history  = model1.fit(x1_train,y_train,batch_size=128, epochs=400,validation_data=(x1_test,y_test),callbacks=callbacks)\n",
        "# history  = model2.fit(c_X_train,c_Y_train,batch_size=128, epochs=400)\n",
        "model1.evaluate(x1_test,y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "16/16 [==============================] - 3s 67ms/step - loss: 0.4080 - accuracy: 0.8151 - precision: 0.8258 - recall: 0.8819 - AUC: 0.7884 - AUPR: 0.7865 - val_loss: 0.4203 - val_accuracy: 0.8104 - val_precision: 0.8339 - val_recall: 0.8781 - val_AUC: 0.7356 - val_AUPR: 0.7748\n",
            "Epoch 2/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.8147 - precision: 0.8302 - recall: 0.8740 - AUC: 0.7913 - AUPR: 0.7916 - val_loss: 0.4197 - val_accuracy: 0.8107 - val_precision: 0.8255 - val_recall: 0.8923 - val_AUC: 0.7371 - val_AUPR: 0.7749\n",
            "Epoch 3/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4007 - accuracy: 0.8166 - precision: 0.8197 - recall: 0.8954 - AUC: 0.8028 - AUPR: 0.7968 - val_loss: 0.4228 - val_accuracy: 0.8114 - val_precision: 0.8403 - val_recall: 0.8701 - val_AUC: 0.7388 - val_AUPR: 0.7758\n",
            "Epoch 4/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3978 - accuracy: 0.8205 - precision: 0.8336 - recall: 0.8805 - AUC: 0.8056 - AUPR: 0.7977 - val_loss: 0.4185 - val_accuracy: 0.8135 - val_precision: 0.8287 - val_recall: 0.8926 - val_AUC: 0.7393 - val_AUPR: 0.7765\n",
            "Epoch 5/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3947 - accuracy: 0.8217 - precision: 0.8282 - recall: 0.8916 - AUC: 0.8103 - AUPR: 0.7946 - val_loss: 0.4225 - val_accuracy: 0.8072 - val_precision: 0.8356 - val_recall: 0.8694 - val_AUC: 0.7366 - val_AUPR: 0.7756\n",
            "Epoch 6/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3957 - accuracy: 0.8223 - precision: 0.8313 - recall: 0.8879 - AUC: 0.8074 - AUPR: 0.8011 - val_loss: 0.4193 - val_accuracy: 0.8105 - val_precision: 0.8320 - val_recall: 0.8815 - val_AUC: 0.7383 - val_AUPR: 0.7763\n",
            "Epoch 7/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8219 - precision: 0.8294 - recall: 0.8902 - AUC: 0.8133 - AUPR: 0.8026 - val_loss: 0.4190 - val_accuracy: 0.8095 - val_precision: 0.8337 - val_recall: 0.8768 - val_AUC: 0.7415 - val_AUPR: 0.7774\n",
            "Epoch 8/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3939 - accuracy: 0.8207 - precision: 0.8337 - recall: 0.8809 - AUC: 0.8098 - AUPR: 0.8026 - val_loss: 0.4190 - val_accuracy: 0.8105 - val_precision: 0.8346 - val_recall: 0.8774 - val_AUC: 0.7404 - val_AUPR: 0.7771\n",
            "Epoch 9/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3922 - accuracy: 0.8213 - precision: 0.8307 - recall: 0.8867 - AUC: 0.8132 - AUPR: 0.8049 - val_loss: 0.4206 - val_accuracy: 0.8091 - val_precision: 0.8363 - val_recall: 0.8717 - val_AUC: 0.7398 - val_AUPR: 0.7762\n",
            "Epoch 10/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8234 - precision: 0.8308 - recall: 0.8910 - AUC: 0.8145 - AUPR: 0.8069 - val_loss: 0.4193 - val_accuracy: 0.8120 - val_precision: 0.8386 - val_recall: 0.8740 - val_AUC: 0.7438 - val_AUPR: 0.7785\n",
            "Epoch 11/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8240 - precision: 0.8354 - recall: 0.8849 - AUC: 0.8216 - AUPR: 0.8073 - val_loss: 0.4188 - val_accuracy: 0.8112 - val_precision: 0.8372 - val_recall: 0.8745 - val_AUC: 0.7419 - val_AUPR: 0.7790\n",
            "Epoch 12/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.8249 - precision: 0.8367 - recall: 0.8848 - AUC: 0.8219 - AUPR: 0.8110 - val_loss: 0.4190 - val_accuracy: 0.8123 - val_precision: 0.8378 - val_recall: 0.8758 - val_AUC: 0.7434 - val_AUPR: 0.7787\n",
            "Epoch 13/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3849 - accuracy: 0.8256 - precision: 0.8319 - recall: 0.8938 - AUC: 0.8217 - AUPR: 0.8133 - val_loss: 0.4192 - val_accuracy: 0.8100 - val_precision: 0.8404 - val_recall: 0.8673 - val_AUC: 0.7450 - val_AUPR: 0.7799\n",
            "Epoch 14/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.8239 - precision: 0.8337 - recall: 0.8873 - AUC: 0.8204 - AUPR: 0.8088 - val_loss: 0.4200 - val_accuracy: 0.8095 - val_precision: 0.8398 - val_recall: 0.8673 - val_AUC: 0.7461 - val_AUPR: 0.7796\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 15/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3828 - accuracy: 0.8281 - precision: 0.8417 - recall: 0.8834 - AUC: 0.8259 - AUPR: 0.8144 - val_loss: 0.4188 - val_accuracy: 0.8084 - val_precision: 0.8363 - val_recall: 0.8704 - val_AUC: 0.7462 - val_AUPR: 0.7798\n",
            "Epoch 16/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3821 - accuracy: 0.8264 - precision: 0.8348 - recall: 0.8908 - AUC: 0.8243 - AUPR: 0.8132 - val_loss: 0.4176 - val_accuracy: 0.8094 - val_precision: 0.8349 - val_recall: 0.8745 - val_AUC: 0.7460 - val_AUPR: 0.7794\n",
            "Epoch 17/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3779 - accuracy: 0.8298 - precision: 0.8389 - recall: 0.8912 - AUC: 0.8330 - AUPR: 0.8165 - val_loss: 0.4178 - val_accuracy: 0.8099 - val_precision: 0.8357 - val_recall: 0.8743 - val_AUC: 0.7461 - val_AUPR: 0.7794\n",
            "Epoch 18/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.8281 - precision: 0.8381 - recall: 0.8891 - AUC: 0.8272 - AUPR: 0.8139 - val_loss: 0.4174 - val_accuracy: 0.8105 - val_precision: 0.8362 - val_recall: 0.8748 - val_AUC: 0.7463 - val_AUPR: 0.7795\n",
            "Epoch 19/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3805 - accuracy: 0.8268 - precision: 0.8351 - recall: 0.8911 - AUC: 0.8289 - AUPR: 0.8156 - val_loss: 0.4175 - val_accuracy: 0.8107 - val_precision: 0.8376 - val_recall: 0.8730 - val_AUC: 0.7464 - val_AUPR: 0.7797\n",
            "Epoch 20/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.8275 - precision: 0.8375 - recall: 0.8888 - AUC: 0.8305 - AUPR: 0.8158 - val_loss: 0.4174 - val_accuracy: 0.8100 - val_precision: 0.8361 - val_recall: 0.8740 - val_AUC: 0.7461 - val_AUPR: 0.7796\n",
            "Epoch 21/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3809 - accuracy: 0.8275 - precision: 0.8372 - recall: 0.8892 - AUC: 0.8275 - AUPR: 0.8150 - val_loss: 0.4178 - val_accuracy: 0.8107 - val_precision: 0.8379 - val_recall: 0.8725 - val_AUC: 0.7465 - val_AUPR: 0.7805\n",
            "Epoch 22/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.8285 - precision: 0.8383 - recall: 0.8895 - AUC: 0.8313 - AUPR: 0.8188 - val_loss: 0.4166 - val_accuracy: 0.8104 - val_precision: 0.8353 - val_recall: 0.8758 - val_AUC: 0.7459 - val_AUPR: 0.7804\n",
            "Epoch 23/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3810 - accuracy: 0.8266 - precision: 0.8360 - recall: 0.8893 - AUC: 0.8285 - AUPR: 0.8172 - val_loss: 0.4175 - val_accuracy: 0.8105 - val_precision: 0.8372 - val_recall: 0.8732 - val_AUC: 0.7461 - val_AUPR: 0.7803\n",
            "Epoch 24/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3797 - accuracy: 0.8297 - precision: 0.8383 - recall: 0.8920 - AUC: 0.8318 - AUPR: 0.8187 - val_loss: 0.4176 - val_accuracy: 0.8099 - val_precision: 0.8367 - val_recall: 0.8727 - val_AUC: 0.7458 - val_AUPR: 0.7804\n",
            "Epoch 25/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3793 - accuracy: 0.8282 - precision: 0.8374 - recall: 0.8904 - AUC: 0.8315 - AUPR: 0.8154 - val_loss: 0.4173 - val_accuracy: 0.8099 - val_precision: 0.8359 - val_recall: 0.8740 - val_AUC: 0.7455 - val_AUPR: 0.7803\n",
            "Epoch 26/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3778 - accuracy: 0.8294 - precision: 0.8406 - recall: 0.8878 - AUC: 0.8330 - AUPR: 0.8166 - val_loss: 0.4179 - val_accuracy: 0.8105 - val_precision: 0.8382 - val_recall: 0.8717 - val_AUC: 0.7461 - val_AUPR: 0.7804\n",
            "Epoch 27/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3789 - accuracy: 0.8279 - precision: 0.8397 - recall: 0.8860 - AUC: 0.8314 - AUPR: 0.8199 - val_loss: 0.4167 - val_accuracy: 0.8107 - val_precision: 0.8362 - val_recall: 0.8750 - val_AUC: 0.7466 - val_AUPR: 0.7807\n",
            "Epoch 28/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3787 - accuracy: 0.8276 - precision: 0.8367 - recall: 0.8902 - AUC: 0.8306 - AUPR: 0.8165 - val_loss: 0.4164 - val_accuracy: 0.8110 - val_precision: 0.8367 - val_recall: 0.8750 - val_AUC: 0.7474 - val_AUPR: 0.7814\n",
            "Epoch 29/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3797 - accuracy: 0.8284 - precision: 0.8381 - recall: 0.8896 - AUC: 0.8317 - AUPR: 0.8173 - val_loss: 0.4172 - val_accuracy: 0.8109 - val_precision: 0.8388 - val_recall: 0.8714 - val_AUC: 0.7476 - val_AUPR: 0.7817\n",
            "Epoch 30/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.8302 - precision: 0.8407 - recall: 0.8893 - AUC: 0.8294 - AUPR: 0.8179 - val_loss: 0.4167 - val_accuracy: 0.8109 - val_precision: 0.8371 - val_recall: 0.8740 - val_AUC: 0.7476 - val_AUPR: 0.7820\n",
            "Epoch 31/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3804 - accuracy: 0.8276 - precision: 0.8371 - recall: 0.8896 - AUC: 0.8294 - AUPR: 0.8171 - val_loss: 0.4163 - val_accuracy: 0.8115 - val_precision: 0.8369 - val_recall: 0.8755 - val_AUC: 0.7476 - val_AUPR: 0.7818\n",
            "Epoch 32/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3760 - accuracy: 0.8317 - precision: 0.8411 - recall: 0.8917 - AUC: 0.8354 - AUPR: 0.8193 - val_loss: 0.4166 - val_accuracy: 0.8110 - val_precision: 0.8385 - val_recall: 0.8722 - val_AUC: 0.7481 - val_AUPR: 0.7815\n",
            "Epoch 33/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3773 - accuracy: 0.8297 - precision: 0.8405 - recall: 0.8886 - AUC: 0.8318 - AUPR: 0.8231 - val_loss: 0.4165 - val_accuracy: 0.8122 - val_precision: 0.8386 - val_recall: 0.8743 - val_AUC: 0.7478 - val_AUPR: 0.7815\n",
            "Epoch 34/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3774 - accuracy: 0.8311 - precision: 0.8394 - recall: 0.8931 - AUC: 0.8321 - AUPR: 0.8179 - val_loss: 0.4160 - val_accuracy: 0.8112 - val_precision: 0.8370 - val_recall: 0.8748 - val_AUC: 0.7484 - val_AUPR: 0.7823\n",
            "Epoch 35/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.8302 - precision: 0.8383 - recall: 0.8930 - AUC: 0.8376 - AUPR: 0.8216 - val_loss: 0.4163 - val_accuracy: 0.8114 - val_precision: 0.8381 - val_recall: 0.8735 - val_AUC: 0.7481 - val_AUPR: 0.7821\n",
            "Epoch 36/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3787 - accuracy: 0.8269 - precision: 0.8379 - recall: 0.8870 - AUC: 0.8330 - AUPR: 0.8182 - val_loss: 0.4165 - val_accuracy: 0.8110 - val_precision: 0.8388 - val_recall: 0.8717 - val_AUC: 0.7479 - val_AUPR: 0.7823\n",
            "Epoch 37/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3751 - accuracy: 0.8304 - precision: 0.8396 - recall: 0.8913 - AUC: 0.8370 - AUPR: 0.8212 - val_loss: 0.4158 - val_accuracy: 0.8120 - val_precision: 0.8389 - val_recall: 0.8735 - val_AUC: 0.7482 - val_AUPR: 0.7821\n",
            "Epoch 38/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3740 - accuracy: 0.8311 - precision: 0.8393 - recall: 0.8932 - AUC: 0.8392 - AUPR: 0.8228 - val_loss: 0.4160 - val_accuracy: 0.8119 - val_precision: 0.8382 - val_recall: 0.8743 - val_AUC: 0.7482 - val_AUPR: 0.7812\n",
            "Epoch 39/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3740 - accuracy: 0.8318 - precision: 0.8408 - recall: 0.8924 - AUC: 0.8356 - AUPR: 0.8185 - val_loss: 0.4163 - val_accuracy: 0.8128 - val_precision: 0.8406 - val_recall: 0.8725 - val_AUC: 0.7480 - val_AUPR: 0.7814\n",
            "Epoch 40/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3762 - accuracy: 0.8313 - precision: 0.8408 - recall: 0.8912 - AUC: 0.8334 - AUPR: 0.8190 - val_loss: 0.4168 - val_accuracy: 0.8112 - val_precision: 0.8402 - val_recall: 0.8699 - val_AUC: 0.7477 - val_AUPR: 0.7814\n",
            "Epoch 41/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3762 - accuracy: 0.8310 - precision: 0.8404 - recall: 0.8914 - AUC: 0.8341 - AUPR: 0.8185 - val_loss: 0.4168 - val_accuracy: 0.8120 - val_precision: 0.8392 - val_recall: 0.8730 - val_AUC: 0.7477 - val_AUPR: 0.7813\n",
            "Epoch 42/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3760 - accuracy: 0.8294 - precision: 0.8389 - recall: 0.8905 - AUC: 0.8348 - AUPR: 0.8239 - val_loss: 0.4170 - val_accuracy: 0.8105 - val_precision: 0.8370 - val_recall: 0.8735 - val_AUC: 0.7474 - val_AUPR: 0.7812\n",
            "Epoch 43/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.8308 - precision: 0.8411 - recall: 0.8898 - AUC: 0.8373 - AUPR: 0.8210 - val_loss: 0.4169 - val_accuracy: 0.8107 - val_precision: 0.8391 - val_recall: 0.8707 - val_AUC: 0.7475 - val_AUPR: 0.7819\n",
            "Epoch 44/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3712 - accuracy: 0.8330 - precision: 0.8427 - recall: 0.8917 - AUC: 0.8417 - AUPR: 0.8230 - val_loss: 0.4165 - val_accuracy: 0.8104 - val_precision: 0.8380 - val_recall: 0.8717 - val_AUC: 0.7478 - val_AUPR: 0.7818\n",
            "Epoch 45/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3751 - accuracy: 0.8300 - precision: 0.8405 - recall: 0.8892 - AUC: 0.8383 - AUPR: 0.8227 - val_loss: 0.4166 - val_accuracy: 0.8104 - val_precision: 0.8380 - val_recall: 0.8717 - val_AUC: 0.7482 - val_AUPR: 0.7820\n",
            "Epoch 46/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8326 - precision: 0.8415 - recall: 0.8930 - AUC: 0.8395 - AUPR: 0.8242 - val_loss: 0.4160 - val_accuracy: 0.8109 - val_precision: 0.8375 - val_recall: 0.8735 - val_AUC: 0.7486 - val_AUPR: 0.7823\n",
            "Epoch 47/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3742 - accuracy: 0.8299 - precision: 0.8397 - recall: 0.8902 - AUC: 0.8387 - AUPR: 0.8207 - val_loss: 0.4165 - val_accuracy: 0.8117 - val_precision: 0.8410 - val_recall: 0.8696 - val_AUC: 0.7486 - val_AUPR: 0.7822\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 48/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.8336 - precision: 0.8445 - recall: 0.8902 - AUC: 0.8432 - AUPR: 0.8278 - val_loss: 0.4163 - val_accuracy: 0.8119 - val_precision: 0.8402 - val_recall: 0.8712 - val_AUC: 0.7487 - val_AUPR: 0.7822\n",
            "Epoch 49/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3706 - accuracy: 0.8329 - precision: 0.8426 - recall: 0.8919 - AUC: 0.8431 - AUPR: 0.8240 - val_loss: 0.4162 - val_accuracy: 0.8117 - val_precision: 0.8398 - val_recall: 0.8714 - val_AUC: 0.7488 - val_AUPR: 0.7823\n",
            "Epoch 50/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3716 - accuracy: 0.8318 - precision: 0.8431 - recall: 0.8887 - AUC: 0.8401 - AUPR: 0.8224 - val_loss: 0.4160 - val_accuracy: 0.8117 - val_precision: 0.8390 - val_recall: 0.8727 - val_AUC: 0.7489 - val_AUPR: 0.7825\n",
            "Epoch 51/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8331 - precision: 0.8426 - recall: 0.8922 - AUC: 0.8420 - AUPR: 0.8267 - val_loss: 0.4160 - val_accuracy: 0.8115 - val_precision: 0.8398 - val_recall: 0.8712 - val_AUC: 0.7489 - val_AUPR: 0.7822\n",
            "Epoch 52/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3716 - accuracy: 0.8330 - precision: 0.8428 - recall: 0.8917 - AUC: 0.8391 - AUPR: 0.8253 - val_loss: 0.4159 - val_accuracy: 0.8115 - val_precision: 0.8393 - val_recall: 0.8719 - val_AUC: 0.7488 - val_AUPR: 0.7820\n",
            "Epoch 53/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.8334 - precision: 0.8419 - recall: 0.8938 - AUC: 0.8395 - AUPR: 0.8227 - val_loss: 0.4158 - val_accuracy: 0.8112 - val_precision: 0.8389 - val_recall: 0.8719 - val_AUC: 0.7488 - val_AUPR: 0.7822\n",
            "Epoch 54/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8300 - precision: 0.8394 - recall: 0.8908 - AUC: 0.8345 - AUPR: 0.8163 - val_loss: 0.4160 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7489 - val_AUPR: 0.7824\n",
            "Epoch 55/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.8294 - precision: 0.8401 - recall: 0.8886 - AUC: 0.8361 - AUPR: 0.8247 - val_loss: 0.4161 - val_accuracy: 0.8115 - val_precision: 0.8400 - val_recall: 0.8709 - val_AUC: 0.7488 - val_AUPR: 0.7823\n",
            "Epoch 56/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3742 - accuracy: 0.8328 - precision: 0.8433 - recall: 0.8903 - AUC: 0.8364 - AUPR: 0.8236 - val_loss: 0.4161 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7488 - val_AUPR: 0.7820\n",
            "Epoch 57/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3736 - accuracy: 0.8315 - precision: 0.8423 - recall: 0.8894 - AUC: 0.8368 - AUPR: 0.8245 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 58/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3717 - accuracy: 0.8320 - precision: 0.8409 - recall: 0.8927 - AUC: 0.8418 - AUPR: 0.8246 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7487 - val_AUPR: 0.7818\n",
            "Epoch 59/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.8320 - precision: 0.8396 - recall: 0.8946 - AUC: 0.8360 - AUPR: 0.8199 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7486 - val_AUPR: 0.7819\n",
            "Epoch 60/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3717 - accuracy: 0.8328 - precision: 0.8426 - recall: 0.8916 - AUC: 0.8397 - AUPR: 0.8186 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "Epoch 61/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.8341 - precision: 0.8441 - recall: 0.8919 - AUC: 0.8420 - AUPR: 0.8235 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7488 - val_AUPR: 0.7820\n",
            "Epoch 62/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3724 - accuracy: 0.8327 - precision: 0.8417 - recall: 0.8929 - AUC: 0.8387 - AUPR: 0.8217 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "Epoch 63/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.8304 - precision: 0.8408 - recall: 0.8895 - AUC: 0.8391 - AUPR: 0.8209 - val_loss: 0.4161 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "Epoch 64/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3733 - accuracy: 0.8322 - precision: 0.8408 - recall: 0.8932 - AUC: 0.8359 - AUPR: 0.8227 - val_loss: 0.4161 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "Epoch 65/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3694 - accuracy: 0.8339 - precision: 0.8437 - recall: 0.8921 - AUC: 0.8438 - AUPR: 0.8255 - val_loss: 0.4161 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7488 - val_AUPR: 0.7820\n",
            "Epoch 66/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8318 - precision: 0.8412 - recall: 0.8918 - AUC: 0.8388 - AUPR: 0.8270 - val_loss: 0.4161 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7488 - val_AUPR: 0.7819\n",
            "Epoch 67/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3751 - accuracy: 0.8311 - precision: 0.8414 - recall: 0.8898 - AUC: 0.8374 - AUPR: 0.8229 - val_loss: 0.4161 - val_accuracy: 0.8117 - val_precision: 0.8397 - val_recall: 0.8717 - val_AUC: 0.7487 - val_AUPR: 0.7819\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 00067: early stopping\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8120 - precision: 0.8389 - recall: 0.8735 - AUC: 0.7482 - AUPR: 0.7821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.7481955885887146,\n",
              " 'AUPR': 0.7821268439292908,\n",
              " 'accuracy': 0.812016487121582,\n",
              " 'loss': 0.4158090353012085,\n",
              " 'precision': 0.8389012813568115,\n",
              " 'recall': 0.8734862208366394}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez1vzT1NQj5I"
      },
      "source": [
        "y_pre2 = model1.predict(x1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGrSdGOtRZIX"
      },
      "source": [
        "gin_infomax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia3I0v-_Rao2",
        "outputId": "97f7012b-5869-4d28-c023-ea028d7e55af"
      },
      "source": [
        "X2 = np.load('./data/gin_supervised_infomax.npy')\n",
        "x2_train,x2_test,y_train,y_test= train_test_split(X2,y,test_size=0.1,random_state=2021)\n",
        "model3 = load_model('./model/model_infomax21.h5')\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model3.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "history  = model3.fit(x2_train,y_train,batch_size=128, epochs=400,validation_data=(x2_test,y_test),callbacks=callbacks)\n",
        "model3.evaluate(x2_test,y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "16/16 [==============================] - 3s 65ms/step - loss: 0.4037 - accuracy: 0.8134 - precision: 0.8287 - recall: 0.8757 - AUC: 0.7912 - AUPR: 0.7917 - val_loss: 0.4267 - val_accuracy: 0.8081 - val_precision: 0.8313 - val_recall: 0.8776 - val_AUC: 0.7316 - val_AUPR: 0.7694\n",
            "Epoch 2/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4007 - accuracy: 0.8164 - precision: 0.8237 - recall: 0.8881 - AUC: 0.8024 - AUPR: 0.7993 - val_loss: 0.4309 - val_accuracy: 0.8015 - val_precision: 0.8343 - val_recall: 0.8601 - val_AUC: 0.7299 - val_AUPR: 0.7679\n",
            "Epoch 3/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.8217 - precision: 0.8312 - recall: 0.8869 - AUC: 0.8090 - AUPR: 0.8014 - val_loss: 0.4248 - val_accuracy: 0.8095 - val_precision: 0.8312 - val_recall: 0.8807 - val_AUC: 0.7324 - val_AUPR: 0.7686\n",
            "Epoch 4/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8212 - precision: 0.8329 - recall: 0.8832 - AUC: 0.8089 - AUPR: 0.8041 - val_loss: 0.4288 - val_accuracy: 0.8049 - val_precision: 0.8378 - val_recall: 0.8614 - val_AUC: 0.7336 - val_AUPR: 0.7682\n",
            "Epoch 5/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3920 - accuracy: 0.8227 - precision: 0.8289 - recall: 0.8925 - AUC: 0.8122 - AUPR: 0.8064 - val_loss: 0.4263 - val_accuracy: 0.8048 - val_precision: 0.8361 - val_recall: 0.8637 - val_AUC: 0.7354 - val_AUPR: 0.7715\n",
            "Epoch 6/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3904 - accuracy: 0.8235 - precision: 0.8357 - recall: 0.8834 - AUC: 0.8163 - AUPR: 0.8080 - val_loss: 0.4231 - val_accuracy: 0.8067 - val_precision: 0.8333 - val_recall: 0.8719 - val_AUC: 0.7380 - val_AUPR: 0.7730\n",
            "Epoch 7/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8241 - precision: 0.8328 - recall: 0.8891 - AUC: 0.8162 - AUPR: 0.8111 - val_loss: 0.4231 - val_accuracy: 0.8041 - val_precision: 0.8273 - val_recall: 0.8763 - val_AUC: 0.7374 - val_AUPR: 0.7717\n",
            "Epoch 8/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.8240 - precision: 0.8358 - recall: 0.8844 - AUC: 0.8214 - AUPR: 0.8144 - val_loss: 0.4243 - val_accuracy: 0.8035 - val_precision: 0.8325 - val_recall: 0.8668 - val_AUC: 0.7371 - val_AUPR: 0.7705\n",
            "Epoch 9/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3842 - accuracy: 0.8265 - precision: 0.8343 - recall: 0.8917 - AUC: 0.8246 - AUPR: 0.8120 - val_loss: 0.4254 - val_accuracy: 0.8026 - val_precision: 0.8331 - val_recall: 0.8642 - val_AUC: 0.7354 - val_AUPR: 0.7696\n",
            "Epoch 10/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3821 - accuracy: 0.8271 - precision: 0.8366 - recall: 0.8893 - AUC: 0.8280 - AUPR: 0.8184 - val_loss: 0.4236 - val_accuracy: 0.8044 - val_precision: 0.8364 - val_recall: 0.8627 - val_AUC: 0.7383 - val_AUPR: 0.7694\n",
            "Epoch 11/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3816 - accuracy: 0.8272 - precision: 0.8397 - recall: 0.8847 - AUC: 0.8285 - AUPR: 0.8194 - val_loss: 0.4229 - val_accuracy: 0.8061 - val_precision: 0.8297 - val_recall: 0.8763 - val_AUC: 0.7379 - val_AUPR: 0.7704\n",
            "Epoch 12/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3833 - accuracy: 0.8238 - precision: 0.8294 - recall: 0.8942 - AUC: 0.8272 - AUPR: 0.8191 - val_loss: 0.4244 - val_accuracy: 0.8040 - val_precision: 0.8426 - val_recall: 0.8524 - val_AUC: 0.7408 - val_AUPR: 0.7728\n",
            "Epoch 13/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3788 - accuracy: 0.8290 - precision: 0.8403 - recall: 0.8874 - AUC: 0.8330 - AUPR: 0.8227 - val_loss: 0.4207 - val_accuracy: 0.8087 - val_precision: 0.8266 - val_recall: 0.8866 - val_AUC: 0.7397 - val_AUPR: 0.7713\n",
            "Epoch 14/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3792 - accuracy: 0.8283 - precision: 0.8389 - recall: 0.8881 - AUC: 0.8300 - AUPR: 0.8194 - val_loss: 0.4217 - val_accuracy: 0.8072 - val_precision: 0.8318 - val_recall: 0.8753 - val_AUC: 0.7405 - val_AUPR: 0.7728\n",
            "Epoch 15/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3759 - accuracy: 0.8307 - precision: 0.8389 - recall: 0.8929 - AUC: 0.8359 - AUPR: 0.8223 - val_loss: 0.4241 - val_accuracy: 0.8059 - val_precision: 0.8429 - val_recall: 0.8557 - val_AUC: 0.7401 - val_AUPR: 0.7717\n",
            "Epoch 16/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3739 - accuracy: 0.8317 - precision: 0.8410 - recall: 0.8919 - AUC: 0.8382 - AUPR: 0.8248 - val_loss: 0.4235 - val_accuracy: 0.8056 - val_precision: 0.8335 - val_recall: 0.8694 - val_AUC: 0.7376 - val_AUPR: 0.7703\n",
            "Epoch 17/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.8319 - precision: 0.8401 - recall: 0.8937 - AUC: 0.8377 - AUPR: 0.8254 - val_loss: 0.4215 - val_accuracy: 0.8074 - val_precision: 0.8368 - val_recall: 0.8678 - val_AUC: 0.7428 - val_AUPR: 0.7725\n",
            "Epoch 18/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.8312 - precision: 0.8424 - recall: 0.8886 - AUC: 0.8384 - AUPR: 0.8250 - val_loss: 0.4208 - val_accuracy: 0.8077 - val_precision: 0.8340 - val_recall: 0.8727 - val_AUC: 0.7407 - val_AUPR: 0.7717\n",
            "Epoch 19/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3738 - accuracy: 0.8306 - precision: 0.8397 - recall: 0.8915 - AUC: 0.8378 - AUPR: 0.8246 - val_loss: 0.4229 - val_accuracy: 0.8084 - val_precision: 0.8399 - val_recall: 0.8650 - val_AUC: 0.7421 - val_AUPR: 0.7718\n",
            "Epoch 20/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3696 - accuracy: 0.8324 - precision: 0.8408 - recall: 0.8935 - AUC: 0.8440 - AUPR: 0.8323 - val_loss: 0.4241 - val_accuracy: 0.8061 - val_precision: 0.8358 - val_recall: 0.8668 - val_AUC: 0.7397 - val_AUPR: 0.7710\n",
            "Epoch 21/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3699 - accuracy: 0.8323 - precision: 0.8427 - recall: 0.8902 - AUC: 0.8437 - AUPR: 0.8286 - val_loss: 0.4216 - val_accuracy: 0.8077 - val_precision: 0.8392 - val_recall: 0.8647 - val_AUC: 0.7446 - val_AUPR: 0.7718\n",
            "Epoch 22/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3661 - accuracy: 0.8338 - precision: 0.8448 - recall: 0.8902 - AUC: 0.8482 - AUPR: 0.8325 - val_loss: 0.4178 - val_accuracy: 0.8104 - val_precision: 0.8363 - val_recall: 0.8743 - val_AUC: 0.7481 - val_AUPR: 0.7756\n",
            "Epoch 23/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3613 - accuracy: 0.8391 - precision: 0.8474 - recall: 0.8968 - AUC: 0.8520 - AUPR: 0.8348 - val_loss: 0.4214 - val_accuracy: 0.8084 - val_precision: 0.8402 - val_recall: 0.8645 - val_AUC: 0.7477 - val_AUPR: 0.7737\n",
            "Epoch 24/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3642 - accuracy: 0.8354 - precision: 0.8441 - recall: 0.8946 - AUC: 0.8493 - AUPR: 0.8331 - val_loss: 0.4198 - val_accuracy: 0.8091 - val_precision: 0.8392 - val_recall: 0.8673 - val_AUC: 0.7472 - val_AUPR: 0.7749\n",
            "Epoch 25/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3622 - accuracy: 0.8365 - precision: 0.8462 - recall: 0.8935 - AUC: 0.8514 - AUPR: 0.8369 - val_loss: 0.4206 - val_accuracy: 0.8092 - val_precision: 0.8428 - val_recall: 0.8621 - val_AUC: 0.7481 - val_AUPR: 0.7767\n",
            "Epoch 26/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3616 - accuracy: 0.8379 - precision: 0.8460 - recall: 0.8966 - AUC: 0.8509 - AUPR: 0.8351 - val_loss: 0.4206 - val_accuracy: 0.8087 - val_precision: 0.8444 - val_recall: 0.8588 - val_AUC: 0.7496 - val_AUPR: 0.7776\n",
            "Epoch 27/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.8375 - precision: 0.8489 - recall: 0.8914 - AUC: 0.8511 - AUPR: 0.8380 - val_loss: 0.4201 - val_accuracy: 0.8104 - val_precision: 0.8388 - val_recall: 0.8704 - val_AUC: 0.7477 - val_AUPR: 0.7768\n",
            "Epoch 28/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.8376 - precision: 0.8492 - recall: 0.8911 - AUC: 0.8537 - AUPR: 0.8375 - val_loss: 0.4213 - val_accuracy: 0.8082 - val_precision: 0.8365 - val_recall: 0.8699 - val_AUC: 0.7456 - val_AUPR: 0.7746\n",
            "Epoch 29/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3591 - accuracy: 0.8382 - precision: 0.8468 - recall: 0.8960 - AUC: 0.8541 - AUPR: 0.8396 - val_loss: 0.4214 - val_accuracy: 0.8087 - val_precision: 0.8439 - val_recall: 0.8596 - val_AUC: 0.7492 - val_AUPR: 0.7760\n",
            "Epoch 30/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3580 - accuracy: 0.8389 - precision: 0.8481 - recall: 0.8954 - AUC: 0.8547 - AUPR: 0.8381 - val_loss: 0.4213 - val_accuracy: 0.8071 - val_precision: 0.8428 - val_recall: 0.8580 - val_AUC: 0.7479 - val_AUPR: 0.7751\n",
            "Epoch 31/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3546 - accuracy: 0.8422 - precision: 0.8575 - recall: 0.8880 - AUC: 0.8606 - AUPR: 0.8433 - val_loss: 0.4175 - val_accuracy: 0.8123 - val_precision: 0.8322 - val_recall: 0.8846 - val_AUC: 0.7485 - val_AUPR: 0.7741\n",
            "Epoch 32/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3568 - accuracy: 0.8376 - precision: 0.8413 - recall: 0.9031 - AUC: 0.8575 - AUPR: 0.8381 - val_loss: 0.4212 - val_accuracy: 0.8091 - val_precision: 0.8419 - val_recall: 0.8632 - val_AUC: 0.7470 - val_AUPR: 0.7742\n",
            "Epoch 33/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3532 - accuracy: 0.8418 - precision: 0.8566 - recall: 0.8885 - AUC: 0.8613 - AUPR: 0.8416 - val_loss: 0.4185 - val_accuracy: 0.8143 - val_precision: 0.8411 - val_recall: 0.8745 - val_AUC: 0.7487 - val_AUPR: 0.7751\n",
            "Epoch 34/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3518 - accuracy: 0.8432 - precision: 0.8500 - recall: 0.9011 - AUC: 0.8616 - AUPR: 0.8413 - val_loss: 0.4207 - val_accuracy: 0.8087 - val_precision: 0.8432 - val_recall: 0.8606 - val_AUC: 0.7497 - val_AUPR: 0.7746\n",
            "Epoch 35/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3541 - accuracy: 0.8393 - precision: 0.8516 - recall: 0.8911 - AUC: 0.8595 - AUPR: 0.8440 - val_loss: 0.4183 - val_accuracy: 0.8122 - val_precision: 0.8425 - val_recall: 0.8683 - val_AUC: 0.7520 - val_AUPR: 0.7756\n",
            "Epoch 36/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3544 - accuracy: 0.8398 - precision: 0.8521 - recall: 0.8911 - AUC: 0.8597 - AUPR: 0.8410 - val_loss: 0.4211 - val_accuracy: 0.8110 - val_precision: 0.8417 - val_recall: 0.8673 - val_AUC: 0.7473 - val_AUPR: 0.7729\n",
            "Epoch 37/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3517 - accuracy: 0.8436 - precision: 0.8507 - recall: 0.9009 - AUC: 0.8610 - AUPR: 0.8449 - val_loss: 0.4217 - val_accuracy: 0.8100 - val_precision: 0.8455 - val_recall: 0.8598 - val_AUC: 0.7486 - val_AUPR: 0.7736\n",
            "Epoch 38/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.8408 - precision: 0.8538 - recall: 0.8906 - AUC: 0.8598 - AUPR: 0.8426 - val_loss: 0.4192 - val_accuracy: 0.8097 - val_precision: 0.8411 - val_recall: 0.8658 - val_AUC: 0.7480 - val_AUPR: 0.7750\n",
            "Epoch 39/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3504 - accuracy: 0.8439 - precision: 0.8558 - recall: 0.8938 - AUC: 0.8621 - AUPR: 0.8460 - val_loss: 0.4178 - val_accuracy: 0.8123 - val_precision: 0.8400 - val_recall: 0.8725 - val_AUC: 0.7495 - val_AUPR: 0.7768\n",
            "Epoch 40/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3455 - accuracy: 0.8443 - precision: 0.8518 - recall: 0.9006 - AUC: 0.8697 - AUPR: 0.8499 - val_loss: 0.4228 - val_accuracy: 0.8058 - val_precision: 0.8386 - val_recall: 0.8619 - val_AUC: 0.7476 - val_AUPR: 0.7749\n",
            "Epoch 41/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.8452 - precision: 0.8570 - recall: 0.8946 - AUC: 0.8660 - AUPR: 0.8486 - val_loss: 0.4181 - val_accuracy: 0.8112 - val_precision: 0.8426 - val_recall: 0.8663 - val_AUC: 0.7515 - val_AUPR: 0.7767\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 42/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3433 - accuracy: 0.8453 - precision: 0.8544 - recall: 0.8988 - AUC: 0.8698 - AUPR: 0.8513 - val_loss: 0.4185 - val_accuracy: 0.8109 - val_precision: 0.8436 - val_recall: 0.8642 - val_AUC: 0.7516 - val_AUPR: 0.7770\n",
            "Epoch 43/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 0.8487 - precision: 0.8596 - recall: 0.8977 - AUC: 0.8749 - AUPR: 0.8563 - val_loss: 0.4187 - val_accuracy: 0.8099 - val_precision: 0.8442 - val_recall: 0.8614 - val_AUC: 0.7516 - val_AUPR: 0.7769\n",
            "Epoch 44/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3444 - accuracy: 0.8458 - precision: 0.8549 - recall: 0.8989 - AUC: 0.8698 - AUPR: 0.8523 - val_loss: 0.4189 - val_accuracy: 0.8102 - val_precision: 0.8453 - val_recall: 0.8603 - val_AUC: 0.7517 - val_AUPR: 0.7773\n",
            "Epoch 45/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3424 - accuracy: 0.8463 - precision: 0.8578 - recall: 0.8957 - AUC: 0.8718 - AUPR: 0.8542 - val_loss: 0.4180 - val_accuracy: 0.8120 - val_precision: 0.8444 - val_recall: 0.8652 - val_AUC: 0.7520 - val_AUPR: 0.7769\n",
            "Epoch 46/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3431 - accuracy: 0.8478 - precision: 0.8580 - recall: 0.8984 - AUC: 0.8713 - AUPR: 0.8552 - val_loss: 0.4187 - val_accuracy: 0.8104 - val_precision: 0.8457 - val_recall: 0.8601 - val_AUC: 0.7518 - val_AUPR: 0.7768\n",
            "Epoch 47/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8499 - precision: 0.8602 - recall: 0.8993 - AUC: 0.8753 - AUPR: 0.8543 - val_loss: 0.4189 - val_accuracy: 0.8104 - val_precision: 0.8445 - val_recall: 0.8619 - val_AUC: 0.7517 - val_AUPR: 0.7768\n",
            "Epoch 48/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3431 - accuracy: 0.8462 - precision: 0.8582 - recall: 0.8949 - AUC: 0.8715 - AUPR: 0.8504 - val_loss: 0.4188 - val_accuracy: 0.8107 - val_precision: 0.8437 - val_recall: 0.8637 - val_AUC: 0.7513 - val_AUPR: 0.7763\n",
            "Epoch 49/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3408 - accuracy: 0.8484 - precision: 0.8584 - recall: 0.8989 - AUC: 0.8718 - AUPR: 0.8519 - val_loss: 0.4189 - val_accuracy: 0.8107 - val_precision: 0.8439 - val_recall: 0.8634 - val_AUC: 0.7514 - val_AUPR: 0.7764\n",
            "Epoch 50/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3448 - accuracy: 0.8470 - precision: 0.8571 - recall: 0.8980 - AUC: 0.8689 - AUPR: 0.8497 - val_loss: 0.4197 - val_accuracy: 0.8104 - val_precision: 0.8447 - val_recall: 0.8616 - val_AUC: 0.7509 - val_AUPR: 0.7764\n",
            "Epoch 51/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3405 - accuracy: 0.8465 - precision: 0.8567 - recall: 0.8976 - AUC: 0.8744 - AUPR: 0.8505 - val_loss: 0.4206 - val_accuracy: 0.8094 - val_precision: 0.8446 - val_recall: 0.8598 - val_AUC: 0.7508 - val_AUPR: 0.7758\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 52/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3397 - accuracy: 0.8480 - precision: 0.8594 - recall: 0.8967 - AUC: 0.8724 - AUPR: 0.8565 - val_loss: 0.4205 - val_accuracy: 0.8092 - val_precision: 0.8442 - val_recall: 0.8601 - val_AUC: 0.7508 - val_AUPR: 0.7758\n",
            "Epoch 53/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 0.8494 - precision: 0.8602 - recall: 0.8984 - AUC: 0.8748 - AUPR: 0.8541 - val_loss: 0.4203 - val_accuracy: 0.8094 - val_precision: 0.8444 - val_recall: 0.8601 - val_AUC: 0.7511 - val_AUPR: 0.7760\n",
            "Epoch 54/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3408 - accuracy: 0.8488 - precision: 0.8611 - recall: 0.8958 - AUC: 0.8730 - AUPR: 0.8528 - val_loss: 0.4202 - val_accuracy: 0.8095 - val_precision: 0.8441 - val_recall: 0.8609 - val_AUC: 0.7512 - val_AUPR: 0.7761\n",
            "Epoch 55/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3426 - accuracy: 0.8451 - precision: 0.8581 - recall: 0.8929 - AUC: 0.8727 - AUPR: 0.8563 - val_loss: 0.4199 - val_accuracy: 0.8099 - val_precision: 0.8442 - val_recall: 0.8614 - val_AUC: 0.7512 - val_AUPR: 0.7763\n",
            "Epoch 56/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3365 - accuracy: 0.8502 - precision: 0.8618 - recall: 0.8976 - AUC: 0.8761 - AUPR: 0.8550 - val_loss: 0.4197 - val_accuracy: 0.8100 - val_precision: 0.8442 - val_recall: 0.8616 - val_AUC: 0.7513 - val_AUPR: 0.7764\n",
            "Epoch 57/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3397 - accuracy: 0.8488 - precision: 0.8606 - recall: 0.8967 - AUC: 0.8742 - AUPR: 0.8554 - val_loss: 0.4194 - val_accuracy: 0.8105 - val_precision: 0.8443 - val_recall: 0.8624 - val_AUC: 0.7513 - val_AUPR: 0.7770\n",
            "Epoch 58/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3386 - accuracy: 0.8516 - precision: 0.8615 - recall: 0.9008 - AUC: 0.8747 - AUPR: 0.8567 - val_loss: 0.4195 - val_accuracy: 0.8105 - val_precision: 0.8440 - val_recall: 0.8629 - val_AUC: 0.7512 - val_AUPR: 0.7768\n",
            "Epoch 59/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3380 - accuracy: 0.8484 - precision: 0.8596 - recall: 0.8972 - AUC: 0.8766 - AUPR: 0.8525 - val_loss: 0.4196 - val_accuracy: 0.8109 - val_precision: 0.8444 - val_recall: 0.8629 - val_AUC: 0.7512 - val_AUPR: 0.7766\n",
            "Epoch 60/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.8464 - precision: 0.8572 - recall: 0.8967 - AUC: 0.8732 - AUPR: 0.8527 - val_loss: 0.4197 - val_accuracy: 0.8107 - val_precision: 0.8444 - val_recall: 0.8627 - val_AUC: 0.7511 - val_AUPR: 0.7766\n",
            "Epoch 61/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.8474 - precision: 0.8580 - recall: 0.8976 - AUC: 0.8751 - AUPR: 0.8592 - val_loss: 0.4197 - val_accuracy: 0.8109 - val_precision: 0.8444 - val_recall: 0.8629 - val_AUC: 0.7509 - val_AUPR: 0.7763\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 00061: early stopping\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8123 - precision: 0.8322 - recall: 0.8846 - AUC: 0.7485 - AUPR: 0.7741\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.748471736907959,\n",
              " 'AUPR': 0.7741188406944275,\n",
              " 'accuracy': 0.8123456239700317,\n",
              " 'loss': 0.4174900949001312,\n",
              " 'precision': 0.8322424292564392,\n",
              " 'recall': 0.8845658302307129}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xbAC9xFR5QO"
      },
      "source": [
        "y_pre3 = model3.predict(x2_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQlCVd8cSL_P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ExyVMaSOje"
      },
      "source": [
        "**gin_masking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuLxWBSTSQnc",
        "outputId": "eca77432-ea53-4dc0-c011-8bff2a0e755c"
      },
      "source": [
        "X3 = np.load('./data/gin_supervised_masking.npy')\n",
        "x3_train,x3_test,y_train,y_test= train_test_split(X3,y,test_size=0.1,random_state=2021)\n",
        "model4 = load_model('./model/model_masking22.h5')\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model4.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "history  = model4.fit(x3_train,y_train,batch_size=128, epochs=400,validation_data=(x3_test,y_test))\n",
        "model4.evaluate(x3_test,y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "16/16 [==============================] - 3s 64ms/step - loss: 0.4179 - accuracy: 0.8091 - precision: 0.8242 - recall: 0.8741 - AUC: 0.7678 - AUPR: 0.7742 - val_loss: 0.4367 - val_accuracy: 0.8046 - val_precision: 0.8265 - val_recall: 0.8786 - val_AUC: 0.7053 - val_AUPR: 0.7560\n",
            "Epoch 2/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8136 - precision: 0.8231 - recall: 0.8834 - AUC: 0.7831 - AUPR: 0.7855 - val_loss: 0.4354 - val_accuracy: 0.8067 - val_precision: 0.8317 - val_recall: 0.8745 - val_AUC: 0.7081 - val_AUPR: 0.7568\n",
            "Epoch 3/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4053 - accuracy: 0.8172 - precision: 0.8235 - recall: 0.8901 - AUC: 0.7934 - AUPR: 0.7853 - val_loss: 0.4361 - val_accuracy: 0.8061 - val_precision: 0.8386 - val_recall: 0.8624 - val_AUC: 0.7108 - val_AUPR: 0.7588\n",
            "Epoch 4/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4057 - accuracy: 0.8163 - precision: 0.8306 - recall: 0.8768 - AUC: 0.7939 - AUPR: 0.7911 - val_loss: 0.4326 - val_accuracy: 0.8053 - val_precision: 0.8258 - val_recall: 0.8810 - val_AUC: 0.7115 - val_AUPR: 0.7595\n",
            "Epoch 5/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4046 - accuracy: 0.8164 - precision: 0.8250 - recall: 0.8859 - AUC: 0.7949 - AUPR: 0.7933 - val_loss: 0.4351 - val_accuracy: 0.8058 - val_precision: 0.8362 - val_recall: 0.8655 - val_AUC: 0.7136 - val_AUPR: 0.7589\n",
            "Epoch 6/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4027 - accuracy: 0.8174 - precision: 0.8276 - recall: 0.8837 - AUC: 0.7976 - AUPR: 0.7927 - val_loss: 0.4329 - val_accuracy: 0.8051 - val_precision: 0.8303 - val_recall: 0.8735 - val_AUC: 0.7106 - val_AUPR: 0.7579\n",
            "Epoch 7/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4011 - accuracy: 0.8192 - precision: 0.8345 - recall: 0.8765 - AUC: 0.7991 - AUPR: 0.7927 - val_loss: 0.4328 - val_accuracy: 0.8079 - val_precision: 0.8347 - val_recall: 0.8719 - val_AUC: 0.7158 - val_AUPR: 0.7600\n",
            "Epoch 8/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.8183 - precision: 0.8207 - recall: 0.8972 - AUC: 0.8035 - AUPR: 0.7980 - val_loss: 0.4349 - val_accuracy: 0.8059 - val_precision: 0.8378 - val_recall: 0.8634 - val_AUC: 0.7138 - val_AUPR: 0.7600\n",
            "Epoch 9/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.8202 - precision: 0.8329 - recall: 0.8811 - AUC: 0.8081 - AUPR: 0.7982 - val_loss: 0.4297 - val_accuracy: 0.8097 - val_precision: 0.8360 - val_recall: 0.8735 - val_AUC: 0.7189 - val_AUPR: 0.7624\n",
            "Epoch 10/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3958 - accuracy: 0.8202 - precision: 0.8290 - recall: 0.8873 - AUC: 0.8092 - AUPR: 0.8009 - val_loss: 0.4313 - val_accuracy: 0.8095 - val_precision: 0.8378 - val_recall: 0.8704 - val_AUC: 0.7189 - val_AUPR: 0.7623\n",
            "Epoch 11/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3937 - accuracy: 0.8225 - precision: 0.8329 - recall: 0.8858 - AUC: 0.8110 - AUPR: 0.8048 - val_loss: 0.4321 - val_accuracy: 0.8095 - val_precision: 0.8370 - val_recall: 0.8717 - val_AUC: 0.7150 - val_AUPR: 0.7616\n",
            "Epoch 12/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3956 - accuracy: 0.8201 - precision: 0.8337 - recall: 0.8796 - AUC: 0.8098 - AUPR: 0.7969 - val_loss: 0.4296 - val_accuracy: 0.8072 - val_precision: 0.8319 - val_recall: 0.8750 - val_AUC: 0.7178 - val_AUPR: 0.7621\n",
            "Epoch 13/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8228 - precision: 0.8309 - recall: 0.8897 - AUC: 0.8135 - AUPR: 0.8049 - val_loss: 0.4302 - val_accuracy: 0.8069 - val_precision: 0.8356 - val_recall: 0.8686 - val_AUC: 0.7205 - val_AUPR: 0.7629\n",
            "Epoch 14/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8235 - precision: 0.8328 - recall: 0.8880 - AUC: 0.8178 - AUPR: 0.8066 - val_loss: 0.4270 - val_accuracy: 0.8092 - val_precision: 0.8349 - val_recall: 0.8743 - val_AUC: 0.7235 - val_AUPR: 0.7657\n",
            "Epoch 15/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3869 - accuracy: 0.8257 - precision: 0.8348 - recall: 0.8893 - AUC: 0.8190 - AUPR: 0.8108 - val_loss: 0.4286 - val_accuracy: 0.8112 - val_precision: 0.8404 - val_recall: 0.8696 - val_AUC: 0.7241 - val_AUPR: 0.7671\n",
            "Epoch 16/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3897 - accuracy: 0.8233 - precision: 0.8364 - recall: 0.8818 - AUC: 0.8164 - AUPR: 0.8073 - val_loss: 0.4261 - val_accuracy: 0.8109 - val_precision: 0.8350 - val_recall: 0.8774 - val_AUC: 0.7282 - val_AUPR: 0.7673\n",
            "Epoch 17/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3849 - accuracy: 0.8276 - precision: 0.8345 - recall: 0.8938 - AUC: 0.8242 - AUPR: 0.8114 - val_loss: 0.4281 - val_accuracy: 0.8091 - val_precision: 0.8443 - val_recall: 0.8596 - val_AUC: 0.7284 - val_AUPR: 0.7686\n",
            "Epoch 18/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.8259 - precision: 0.8385 - recall: 0.8839 - AUC: 0.8249 - AUPR: 0.8123 - val_loss: 0.4253 - val_accuracy: 0.8110 - val_precision: 0.8375 - val_recall: 0.8737 - val_AUC: 0.7282 - val_AUPR: 0.7672\n",
            "Epoch 19/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3865 - accuracy: 0.8252 - precision: 0.8328 - recall: 0.8914 - AUC: 0.8192 - AUPR: 0.8083 - val_loss: 0.4263 - val_accuracy: 0.8132 - val_precision: 0.8404 - val_recall: 0.8735 - val_AUC: 0.7277 - val_AUPR: 0.7675\n",
            "Epoch 20/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3799 - accuracy: 0.8270 - precision: 0.8373 - recall: 0.8880 - AUC: 0.8296 - AUPR: 0.8171 - val_loss: 0.4259 - val_accuracy: 0.8104 - val_precision: 0.8372 - val_recall: 0.8730 - val_AUC: 0.7281 - val_AUPR: 0.7682\n",
            "Epoch 21/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3835 - accuracy: 0.8275 - precision: 0.8414 - recall: 0.8826 - AUC: 0.8253 - AUPR: 0.8095 - val_loss: 0.4246 - val_accuracy: 0.8114 - val_precision: 0.8348 - val_recall: 0.8786 - val_AUC: 0.7292 - val_AUPR: 0.7687\n",
            "Epoch 22/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3817 - accuracy: 0.8287 - precision: 0.8345 - recall: 0.8961 - AUC: 0.8280 - AUPR: 0.8128 - val_loss: 0.4280 - val_accuracy: 0.8110 - val_precision: 0.8445 - val_recall: 0.8632 - val_AUC: 0.7296 - val_AUPR: 0.7689\n",
            "Epoch 23/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3786 - accuracy: 0.8302 - precision: 0.8450 - recall: 0.8825 - AUC: 0.8328 - AUPR: 0.8180 - val_loss: 0.4230 - val_accuracy: 0.8120 - val_precision: 0.8353 - val_recall: 0.8792 - val_AUC: 0.7330 - val_AUPR: 0.7695\n",
            "Epoch 24/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8301 - precision: 0.8375 - recall: 0.8941 - AUC: 0.8330 - AUPR: 0.8157 - val_loss: 0.4233 - val_accuracy: 0.8143 - val_precision: 0.8440 - val_recall: 0.8701 - val_AUC: 0.7348 - val_AUPR: 0.7715\n",
            "Epoch 25/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3762 - accuracy: 0.8312 - precision: 0.8427 - recall: 0.8881 - AUC: 0.8335 - AUPR: 0.8172 - val_loss: 0.4258 - val_accuracy: 0.8119 - val_precision: 0.8397 - val_recall: 0.8719 - val_AUC: 0.7327 - val_AUPR: 0.7697\n",
            "Epoch 26/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3774 - accuracy: 0.8295 - precision: 0.8405 - recall: 0.8882 - AUC: 0.8340 - AUPR: 0.8204 - val_loss: 0.4266 - val_accuracy: 0.8112 - val_precision: 0.8436 - val_recall: 0.8647 - val_AUC: 0.7333 - val_AUPR: 0.7699\n",
            "Epoch 27/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3724 - accuracy: 0.8320 - precision: 0.8408 - recall: 0.8928 - AUC: 0.8400 - AUPR: 0.8195 - val_loss: 0.4259 - val_accuracy: 0.8114 - val_precision: 0.8447 - val_recall: 0.8634 - val_AUC: 0.7338 - val_AUPR: 0.7709\n",
            "Epoch 28/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3708 - accuracy: 0.8327 - precision: 0.8439 - recall: 0.8893 - AUC: 0.8409 - AUPR: 0.8239 - val_loss: 0.4242 - val_accuracy: 0.8120 - val_precision: 0.8411 - val_recall: 0.8701 - val_AUC: 0.7355 - val_AUPR: 0.7711\n",
            "Epoch 29/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3719 - accuracy: 0.8337 - precision: 0.8423 - recall: 0.8939 - AUC: 0.8394 - AUPR: 0.8228 - val_loss: 0.4263 - val_accuracy: 0.8115 - val_precision: 0.8477 - val_recall: 0.8593 - val_AUC: 0.7361 - val_AUPR: 0.7727\n",
            "Epoch 30/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3717 - accuracy: 0.8340 - precision: 0.8442 - recall: 0.8915 - AUC: 0.8395 - AUPR: 0.8217 - val_loss: 0.4257 - val_accuracy: 0.8089 - val_precision: 0.8385 - val_recall: 0.8681 - val_AUC: 0.7332 - val_AUPR: 0.7714\n",
            "Epoch 31/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3737 - accuracy: 0.8322 - precision: 0.8470 - recall: 0.8837 - AUC: 0.8365 - AUPR: 0.8226 - val_loss: 0.4223 - val_accuracy: 0.8142 - val_precision: 0.8359 - val_recall: 0.8822 - val_AUC: 0.7347 - val_AUPR: 0.7727\n",
            "Epoch 32/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3689 - accuracy: 0.8338 - precision: 0.8385 - recall: 0.9000 - AUC: 0.8440 - AUPR: 0.8230 - val_loss: 0.4268 - val_accuracy: 0.8120 - val_precision: 0.8502 - val_recall: 0.8567 - val_AUC: 0.7369 - val_AUPR: 0.7735\n",
            "Epoch 33/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3680 - accuracy: 0.8364 - precision: 0.8500 - recall: 0.8877 - AUC: 0.8444 - AUPR: 0.8275 - val_loss: 0.4228 - val_accuracy: 0.8130 - val_precision: 0.8371 - val_recall: 0.8781 - val_AUC: 0.7349 - val_AUPR: 0.7711\n",
            "Epoch 34/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3656 - accuracy: 0.8341 - precision: 0.8427 - recall: 0.8940 - AUC: 0.8478 - AUPR: 0.8294 - val_loss: 0.4240 - val_accuracy: 0.8145 - val_precision: 0.8511 - val_recall: 0.8601 - val_AUC: 0.7389 - val_AUPR: 0.7732\n",
            "Epoch 35/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3680 - accuracy: 0.8335 - precision: 0.8445 - recall: 0.8900 - AUC: 0.8453 - AUPR: 0.8261 - val_loss: 0.4246 - val_accuracy: 0.8128 - val_precision: 0.8393 - val_recall: 0.8745 - val_AUC: 0.7351 - val_AUPR: 0.7714\n",
            "Epoch 36/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3656 - accuracy: 0.8355 - precision: 0.8498 - recall: 0.8862 - AUC: 0.8467 - AUPR: 0.8328 - val_loss: 0.4232 - val_accuracy: 0.8153 - val_precision: 0.8431 - val_recall: 0.8735 - val_AUC: 0.7382 - val_AUPR: 0.7729\n",
            "Epoch 37/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3656 - accuracy: 0.8339 - precision: 0.8400 - recall: 0.8978 - AUC: 0.8457 - AUPR: 0.8300 - val_loss: 0.4249 - val_accuracy: 0.8122 - val_precision: 0.8495 - val_recall: 0.8580 - val_AUC: 0.7382 - val_AUPR: 0.7749\n",
            "Epoch 38/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.8380 - precision: 0.8522 - recall: 0.8874 - AUC: 0.8493 - AUPR: 0.8337 - val_loss: 0.4228 - val_accuracy: 0.8127 - val_precision: 0.8407 - val_recall: 0.8719 - val_AUC: 0.7362 - val_AUPR: 0.7733\n",
            "Epoch 39/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.8361 - precision: 0.8466 - recall: 0.8920 - AUC: 0.8518 - AUPR: 0.8317 - val_loss: 0.4235 - val_accuracy: 0.8123 - val_precision: 0.8453 - val_recall: 0.8645 - val_AUC: 0.7375 - val_AUPR: 0.7755\n",
            "Epoch 40/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.8391 - precision: 0.8502 - recall: 0.8927 - AUC: 0.8532 - AUPR: 0.8348 - val_loss: 0.4219 - val_accuracy: 0.8135 - val_precision: 0.8461 - val_recall: 0.8655 - val_AUC: 0.7400 - val_AUPR: 0.7767\n",
            "Epoch 41/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3588 - accuracy: 0.8400 - precision: 0.8515 - recall: 0.8925 - AUC: 0.8525 - AUPR: 0.8357 - val_loss: 0.4229 - val_accuracy: 0.8135 - val_precision: 0.8461 - val_recall: 0.8655 - val_AUC: 0.7388 - val_AUPR: 0.7787\n",
            "Epoch 42/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.8382 - precision: 0.8505 - recall: 0.8903 - AUC: 0.8544 - AUPR: 0.8378 - val_loss: 0.4233 - val_accuracy: 0.8132 - val_precision: 0.8438 - val_recall: 0.8683 - val_AUC: 0.7385 - val_AUPR: 0.7780\n",
            "Epoch 43/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3556 - accuracy: 0.8387 - precision: 0.8469 - recall: 0.8968 - AUC: 0.8582 - AUPR: 0.8388 - val_loss: 0.4245 - val_accuracy: 0.8125 - val_precision: 0.8467 - val_recall: 0.8627 - val_AUC: 0.7360 - val_AUPR: 0.7760\n",
            "Epoch 44/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3583 - accuracy: 0.8403 - precision: 0.8527 - recall: 0.8912 - AUC: 0.8546 - AUPR: 0.8328 - val_loss: 0.4242 - val_accuracy: 0.8117 - val_precision: 0.8395 - val_recall: 0.8719 - val_AUC: 0.7348 - val_AUPR: 0.7751\n",
            "Epoch 45/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8384 - precision: 0.8489 - recall: 0.8932 - AUC: 0.8549 - AUPR: 0.8358 - val_loss: 0.4244 - val_accuracy: 0.8132 - val_precision: 0.8479 - val_recall: 0.8621 - val_AUC: 0.7363 - val_AUPR: 0.7776\n",
            "Epoch 46/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3555 - accuracy: 0.8411 - precision: 0.8518 - recall: 0.8942 - AUC: 0.8565 - AUPR: 0.8369 - val_loss: 0.4242 - val_accuracy: 0.8115 - val_precision: 0.8441 - val_recall: 0.8647 - val_AUC: 0.7357 - val_AUPR: 0.7785\n",
            "Epoch 47/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.8402 - precision: 0.8502 - recall: 0.8948 - AUC: 0.8577 - AUPR: 0.8371 - val_loss: 0.4259 - val_accuracy: 0.8120 - val_precision: 0.8479 - val_recall: 0.8601 - val_AUC: 0.7350 - val_AUPR: 0.7774\n",
            "Epoch 48/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3550 - accuracy: 0.8417 - precision: 0.8550 - recall: 0.8906 - AUC: 0.8572 - AUPR: 0.8367 - val_loss: 0.4226 - val_accuracy: 0.8137 - val_precision: 0.8454 - val_recall: 0.8668 - val_AUC: 0.7404 - val_AUPR: 0.7781\n",
            "Epoch 49/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3527 - accuracy: 0.8430 - precision: 0.8528 - recall: 0.8966 - AUC: 0.8585 - AUPR: 0.8412 - val_loss: 0.4245 - val_accuracy: 0.8142 - val_precision: 0.8468 - val_recall: 0.8658 - val_AUC: 0.7386 - val_AUPR: 0.7780\n",
            "Epoch 50/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3527 - accuracy: 0.8421 - precision: 0.8537 - recall: 0.8935 - AUC: 0.8587 - AUPR: 0.8367 - val_loss: 0.4234 - val_accuracy: 0.8147 - val_precision: 0.8494 - val_recall: 0.8629 - val_AUC: 0.7389 - val_AUPR: 0.7794\n",
            "Epoch 51/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8424 - precision: 0.8517 - recall: 0.8970 - AUC: 0.8620 - AUPR: 0.8418 - val_loss: 0.4199 - val_accuracy: 0.8170 - val_precision: 0.8506 - val_recall: 0.8655 - val_AUC: 0.7435 - val_AUPR: 0.7819\n",
            "Epoch 52/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3499 - accuracy: 0.8418 - precision: 0.8553 - recall: 0.8904 - AUC: 0.8619 - AUPR: 0.8415 - val_loss: 0.4191 - val_accuracy: 0.8156 - val_precision: 0.8469 - val_recall: 0.8683 - val_AUC: 0.7433 - val_AUPR: 0.7794\n",
            "Epoch 53/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3486 - accuracy: 0.8434 - precision: 0.8553 - recall: 0.8937 - AUC: 0.8653 - AUPR: 0.8447 - val_loss: 0.4228 - val_accuracy: 0.8117 - val_precision: 0.8485 - val_recall: 0.8585 - val_AUC: 0.7452 - val_AUPR: 0.7806\n",
            "Epoch 54/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3475 - accuracy: 0.8443 - precision: 0.8546 - recall: 0.8965 - AUC: 0.8661 - AUPR: 0.8461 - val_loss: 0.4223 - val_accuracy: 0.8140 - val_precision: 0.8460 - val_recall: 0.8665 - val_AUC: 0.7418 - val_AUPR: 0.7777\n",
            "Epoch 55/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3496 - accuracy: 0.8442 - precision: 0.8555 - recall: 0.8949 - AUC: 0.8632 - AUPR: 0.8437 - val_loss: 0.4221 - val_accuracy: 0.8143 - val_precision: 0.8456 - val_recall: 0.8678 - val_AUC: 0.7409 - val_AUPR: 0.7799\n",
            "Epoch 56/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3472 - accuracy: 0.8444 - precision: 0.8575 - recall: 0.8924 - AUC: 0.8667 - AUPR: 0.8451 - val_loss: 0.4243 - val_accuracy: 0.8156 - val_precision: 0.8498 - val_recall: 0.8642 - val_AUC: 0.7400 - val_AUPR: 0.7803\n",
            "Epoch 57/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3483 - accuracy: 0.8427 - precision: 0.8531 - recall: 0.8954 - AUC: 0.8651 - AUPR: 0.8464 - val_loss: 0.4222 - val_accuracy: 0.8132 - val_precision: 0.8503 - val_recall: 0.8588 - val_AUC: 0.7445 - val_AUPR: 0.7830\n",
            "Epoch 58/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3453 - accuracy: 0.8450 - precision: 0.8581 - recall: 0.8927 - AUC: 0.8688 - AUPR: 0.8446 - val_loss: 0.4193 - val_accuracy: 0.8176 - val_precision: 0.8478 - val_recall: 0.8709 - val_AUC: 0.7459 - val_AUPR: 0.7840\n",
            "Epoch 59/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3478 - accuracy: 0.8432 - precision: 0.8532 - recall: 0.8964 - AUC: 0.8647 - AUPR: 0.8443 - val_loss: 0.4218 - val_accuracy: 0.8153 - val_precision: 0.8493 - val_recall: 0.8642 - val_AUC: 0.7443 - val_AUPR: 0.7837\n",
            "Epoch 60/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3401 - accuracy: 0.8484 - precision: 0.8585 - recall: 0.8988 - AUC: 0.8737 - AUPR: 0.8554 - val_loss: 0.4244 - val_accuracy: 0.8142 - val_precision: 0.8489 - val_recall: 0.8627 - val_AUC: 0.7412 - val_AUPR: 0.7819\n",
            "Epoch 61/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3477 - accuracy: 0.8440 - precision: 0.8587 - recall: 0.8899 - AUC: 0.8639 - AUPR: 0.8419 - val_loss: 0.4212 - val_accuracy: 0.8150 - val_precision: 0.8423 - val_recall: 0.8740 - val_AUC: 0.7437 - val_AUPR: 0.7822\n",
            "Epoch 62/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3455 - accuracy: 0.8446 - precision: 0.8565 - recall: 0.8943 - AUC: 0.8663 - AUPR: 0.8427 - val_loss: 0.4213 - val_accuracy: 0.8160 - val_precision: 0.8520 - val_recall: 0.8616 - val_AUC: 0.7470 - val_AUPR: 0.7840\n",
            "Epoch 63/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.8483 - precision: 0.8584 - recall: 0.8987 - AUC: 0.8708 - AUPR: 0.8478 - val_loss: 0.4227 - val_accuracy: 0.8170 - val_precision: 0.8467 - val_recall: 0.8712 - val_AUC: 0.7426 - val_AUPR: 0.7809\n",
            "Epoch 64/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3430 - accuracy: 0.8464 - precision: 0.8611 - recall: 0.8911 - AUC: 0.8706 - AUPR: 0.8480 - val_loss: 0.4236 - val_accuracy: 0.8142 - val_precision: 0.8469 - val_recall: 0.8655 - val_AUC: 0.7422 - val_AUPR: 0.7817\n",
            "Epoch 65/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3435 - accuracy: 0.8479 - precision: 0.8588 - recall: 0.8973 - AUC: 0.8692 - AUPR: 0.8540 - val_loss: 0.4258 - val_accuracy: 0.8145 - val_precision: 0.8486 - val_recall: 0.8637 - val_AUC: 0.7404 - val_AUPR: 0.7809\n",
            "Epoch 66/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3414 - accuracy: 0.8464 - precision: 0.8559 - recall: 0.8987 - AUC: 0.8698 - AUPR: 0.8480 - val_loss: 0.4244 - val_accuracy: 0.8133 - val_precision: 0.8492 - val_recall: 0.8606 - val_AUC: 0.7430 - val_AUPR: 0.7817\n",
            "Epoch 67/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.8496 - precision: 0.8650 - recall: 0.8918 - AUC: 0.8762 - AUPR: 0.8513 - val_loss: 0.4224 - val_accuracy: 0.8160 - val_precision: 0.8453 - val_recall: 0.8714 - val_AUC: 0.7430 - val_AUPR: 0.7826\n",
            "Epoch 68/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.8495 - precision: 0.8592 - recall: 0.8999 - AUC: 0.8764 - AUPR: 0.8521 - val_loss: 0.4241 - val_accuracy: 0.8150 - val_precision: 0.8516 - val_recall: 0.8603 - val_AUC: 0.7443 - val_AUPR: 0.7820\n",
            "Epoch 69/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3363 - accuracy: 0.8491 - precision: 0.8621 - recall: 0.8950 - AUC: 0.8777 - AUPR: 0.8561 - val_loss: 0.4241 - val_accuracy: 0.8160 - val_precision: 0.8497 - val_recall: 0.8650 - val_AUC: 0.7440 - val_AUPR: 0.7813\n",
            "Epoch 70/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3426 - accuracy: 0.8467 - precision: 0.8591 - recall: 0.8946 - AUC: 0.8708 - AUPR: 0.8498 - val_loss: 0.4235 - val_accuracy: 0.8147 - val_precision: 0.8494 - val_recall: 0.8629 - val_AUC: 0.7442 - val_AUPR: 0.7833\n",
            "Epoch 71/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3373 - accuracy: 0.8496 - precision: 0.8596 - recall: 0.8996 - AUC: 0.8750 - AUPR: 0.8538 - val_loss: 0.4230 - val_accuracy: 0.8155 - val_precision: 0.8485 - val_recall: 0.8658 - val_AUC: 0.7447 - val_AUPR: 0.7828\n",
            "Epoch 72/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3375 - accuracy: 0.8490 - precision: 0.8597 - recall: 0.8983 - AUC: 0.8759 - AUPR: 0.8519 - val_loss: 0.4252 - val_accuracy: 0.8155 - val_precision: 0.8467 - val_recall: 0.8683 - val_AUC: 0.7418 - val_AUPR: 0.7820\n",
            "Epoch 73/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3347 - accuracy: 0.8505 - precision: 0.8626 - recall: 0.8971 - AUC: 0.8764 - AUPR: 0.8542 - val_loss: 0.4244 - val_accuracy: 0.8151 - val_precision: 0.8475 - val_recall: 0.8665 - val_AUC: 0.7428 - val_AUPR: 0.7821\n",
            "Epoch 74/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3370 - accuracy: 0.8508 - precision: 0.8658 - recall: 0.8930 - AUC: 0.8772 - AUPR: 0.8571 - val_loss: 0.4269 - val_accuracy: 0.8135 - val_precision: 0.8452 - val_recall: 0.8668 - val_AUC: 0.7397 - val_AUPR: 0.7785\n",
            "Epoch 75/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.8507 - precision: 0.8589 - recall: 0.9028 - AUC: 0.8778 - AUPR: 0.8584 - val_loss: 0.4260 - val_accuracy: 0.8138 - val_precision: 0.8492 - val_recall: 0.8616 - val_AUC: 0.7405 - val_AUPR: 0.7787\n",
            "Epoch 76/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.8494 - precision: 0.8634 - recall: 0.8937 - AUC: 0.8760 - AUPR: 0.8561 - val_loss: 0.4281 - val_accuracy: 0.8128 - val_precision: 0.8468 - val_recall: 0.8632 - val_AUC: 0.7386 - val_AUPR: 0.7771\n",
            "Epoch 77/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3330 - accuracy: 0.8520 - precision: 0.8617 - recall: 0.9011 - AUC: 0.8776 - AUPR: 0.8551 - val_loss: 0.4269 - val_accuracy: 0.8128 - val_precision: 0.8440 - val_recall: 0.8673 - val_AUC: 0.7394 - val_AUPR: 0.7770\n",
            "Epoch 78/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3297 - accuracy: 0.8519 - precision: 0.8660 - recall: 0.8948 - AUC: 0.8823 - AUPR: 0.8599 - val_loss: 0.4269 - val_accuracy: 0.8140 - val_precision: 0.8501 - val_recall: 0.8606 - val_AUC: 0.7406 - val_AUPR: 0.7766\n",
            "Epoch 79/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3312 - accuracy: 0.8535 - precision: 0.8647 - recall: 0.8999 - AUC: 0.8791 - AUPR: 0.8583 - val_loss: 0.4237 - val_accuracy: 0.8150 - val_precision: 0.8482 - val_recall: 0.8652 - val_AUC: 0.7465 - val_AUPR: 0.7810\n",
            "Epoch 80/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3294 - accuracy: 0.8537 - precision: 0.8662 - recall: 0.8982 - AUC: 0.8833 - AUPR: 0.8568 - val_loss: 0.4230 - val_accuracy: 0.8142 - val_precision: 0.8435 - val_recall: 0.8707 - val_AUC: 0.7476 - val_AUPR: 0.7824\n",
            "Epoch 81/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3316 - accuracy: 0.8505 - precision: 0.8632 - recall: 0.8961 - AUC: 0.8793 - AUPR: 0.8582 - val_loss: 0.4278 - val_accuracy: 0.8122 - val_precision: 0.8509 - val_recall: 0.8560 - val_AUC: 0.7452 - val_AUPR: 0.7820\n",
            "Epoch 82/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3279 - accuracy: 0.8553 - precision: 0.8673 - recall: 0.8996 - AUC: 0.8841 - AUPR: 0.8658 - val_loss: 0.4250 - val_accuracy: 0.8168 - val_precision: 0.8507 - val_recall: 0.8650 - val_AUC: 0.7465 - val_AUPR: 0.7831\n",
            "Epoch 83/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.8530 - precision: 0.8644 - recall: 0.8993 - AUC: 0.8822 - AUPR: 0.8604 - val_loss: 0.4290 - val_accuracy: 0.8112 - val_precision: 0.8471 - val_recall: 0.8596 - val_AUC: 0.7437 - val_AUPR: 0.7817\n",
            "Epoch 84/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3301 - accuracy: 0.8530 - precision: 0.8653 - recall: 0.8980 - AUC: 0.8827 - AUPR: 0.8571 - val_loss: 0.4266 - val_accuracy: 0.8151 - val_precision: 0.8488 - val_recall: 0.8647 - val_AUC: 0.7450 - val_AUPR: 0.7839\n",
            "Epoch 85/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3267 - accuracy: 0.8566 - precision: 0.8683 - recall: 0.9008 - AUC: 0.8841 - AUPR: 0.8641 - val_loss: 0.4257 - val_accuracy: 0.8151 - val_precision: 0.8530 - val_recall: 0.8585 - val_AUC: 0.7491 - val_AUPR: 0.7838\n",
            "Epoch 86/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3244 - accuracy: 0.8554 - precision: 0.8685 - recall: 0.8981 - AUC: 0.8875 - AUPR: 0.8635 - val_loss: 0.4245 - val_accuracy: 0.8142 - val_precision: 0.8438 - val_recall: 0.8701 - val_AUC: 0.7470 - val_AUPR: 0.7813\n",
            "Epoch 87/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3270 - accuracy: 0.8547 - precision: 0.8687 - recall: 0.8966 - AUC: 0.8842 - AUPR: 0.8597 - val_loss: 0.4245 - val_accuracy: 0.8151 - val_precision: 0.8486 - val_recall: 0.8650 - val_AUC: 0.7489 - val_AUPR: 0.7810\n",
            "Epoch 88/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 0.8537 - precision: 0.8618 - recall: 0.9045 - AUC: 0.8828 - AUPR: 0.8620 - val_loss: 0.4235 - val_accuracy: 0.8132 - val_precision: 0.8521 - val_recall: 0.8562 - val_AUC: 0.7509 - val_AUPR: 0.7838\n",
            "Epoch 89/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3249 - accuracy: 0.8560 - precision: 0.8707 - recall: 0.8962 - AUC: 0.8856 - AUPR: 0.8630 - val_loss: 0.4230 - val_accuracy: 0.8147 - val_precision: 0.8495 - val_recall: 0.8627 - val_AUC: 0.7506 - val_AUPR: 0.7858\n",
            "Epoch 90/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 0.8564 - precision: 0.8676 - recall: 0.9013 - AUC: 0.8866 - AUPR: 0.8648 - val_loss: 0.4213 - val_accuracy: 0.8158 - val_precision: 0.8493 - val_recall: 0.8652 - val_AUC: 0.7520 - val_AUPR: 0.7855\n",
            "Epoch 91/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3238 - accuracy: 0.8567 - precision: 0.8701 - recall: 0.8985 - AUC: 0.8872 - AUPR: 0.8684 - val_loss: 0.4239 - val_accuracy: 0.8178 - val_precision: 0.8535 - val_recall: 0.8629 - val_AUC: 0.7506 - val_AUPR: 0.7859\n",
            "Epoch 92/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3249 - accuracy: 0.8554 - precision: 0.8671 - recall: 0.9002 - AUC: 0.8866 - AUPR: 0.8642 - val_loss: 0.4266 - val_accuracy: 0.8160 - val_precision: 0.8498 - val_recall: 0.8647 - val_AUC: 0.7468 - val_AUPR: 0.7831\n",
            "Epoch 93/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3239 - accuracy: 0.8549 - precision: 0.8667 - recall: 0.8997 - AUC: 0.8872 - AUPR: 0.8648 - val_loss: 0.4264 - val_accuracy: 0.8155 - val_precision: 0.8503 - val_recall: 0.8632 - val_AUC: 0.7450 - val_AUPR: 0.7808\n",
            "Epoch 94/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3210 - accuracy: 0.8581 - precision: 0.8744 - recall: 0.8953 - AUC: 0.8901 - AUPR: 0.8696 - val_loss: 0.4235 - val_accuracy: 0.8166 - val_precision: 0.8511 - val_recall: 0.8642 - val_AUC: 0.7483 - val_AUPR: 0.7849\n",
            "Epoch 95/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3224 - accuracy: 0.8567 - precision: 0.8638 - recall: 0.9075 - AUC: 0.8894 - AUPR: 0.8649 - val_loss: 0.4227 - val_accuracy: 0.8171 - val_precision: 0.8524 - val_recall: 0.8632 - val_AUC: 0.7494 - val_AUPR: 0.7843\n",
            "Epoch 96/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3249 - accuracy: 0.8555 - precision: 0.8726 - recall: 0.8927 - AUC: 0.8875 - AUPR: 0.8593 - val_loss: 0.4237 - val_accuracy: 0.8168 - val_precision: 0.8479 - val_recall: 0.8691 - val_AUC: 0.7455 - val_AUPR: 0.7808\n",
            "Epoch 97/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3197 - accuracy: 0.8586 - precision: 0.8666 - recall: 0.9070 - AUC: 0.8911 - AUPR: 0.8698 - val_loss: 0.4273 - val_accuracy: 0.8132 - val_precision: 0.8524 - val_recall: 0.8557 - val_AUC: 0.7473 - val_AUPR: 0.7828\n",
            "Epoch 98/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3210 - accuracy: 0.8592 - precision: 0.8742 - recall: 0.8976 - AUC: 0.8885 - AUPR: 0.8650 - val_loss: 0.4263 - val_accuracy: 0.8170 - val_precision: 0.8464 - val_recall: 0.8717 - val_AUC: 0.7440 - val_AUPR: 0.7823\n",
            "Epoch 99/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3207 - accuracy: 0.8567 - precision: 0.8708 - recall: 0.8976 - AUC: 0.8909 - AUPR: 0.8665 - val_loss: 0.4257 - val_accuracy: 0.8158 - val_precision: 0.8510 - val_recall: 0.8627 - val_AUC: 0.7478 - val_AUPR: 0.7838\n",
            "Epoch 100/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3217 - accuracy: 0.8566 - precision: 0.8663 - recall: 0.9035 - AUC: 0.8886 - AUPR: 0.8628 - val_loss: 0.4269 - val_accuracy: 0.8160 - val_precision: 0.8522 - val_recall: 0.8614 - val_AUC: 0.7465 - val_AUPR: 0.7815\n",
            "Epoch 101/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3207 - accuracy: 0.8573 - precision: 0.8726 - recall: 0.8962 - AUC: 0.8909 - AUPR: 0.8659 - val_loss: 0.4271 - val_accuracy: 0.8137 - val_precision: 0.8456 - val_recall: 0.8665 - val_AUC: 0.7447 - val_AUPR: 0.7814\n",
            "Epoch 102/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3215 - accuracy: 0.8565 - precision: 0.8714 - recall: 0.8961 - AUC: 0.8896 - AUPR: 0.8697 - val_loss: 0.4263 - val_accuracy: 0.8151 - val_precision: 0.8474 - val_recall: 0.8668 - val_AUC: 0.7458 - val_AUPR: 0.7820\n",
            "Epoch 103/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3180 - accuracy: 0.8585 - precision: 0.8694 - recall: 0.9029 - AUC: 0.8917 - AUPR: 0.8648 - val_loss: 0.4260 - val_accuracy: 0.8148 - val_precision: 0.8508 - val_recall: 0.8611 - val_AUC: 0.7464 - val_AUPR: 0.7846\n",
            "Epoch 104/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3185 - accuracy: 0.8583 - precision: 0.8702 - recall: 0.9015 - AUC: 0.8921 - AUPR: 0.8667 - val_loss: 0.4285 - val_accuracy: 0.8138 - val_precision: 0.8517 - val_recall: 0.8580 - val_AUC: 0.7443 - val_AUPR: 0.7822\n",
            "Epoch 105/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3144 - accuracy: 0.8613 - precision: 0.8744 - recall: 0.9014 - AUC: 0.8938 - AUPR: 0.8717 - val_loss: 0.4263 - val_accuracy: 0.8171 - val_precision: 0.8473 - val_recall: 0.8707 - val_AUC: 0.7449 - val_AUPR: 0.7841\n",
            "Epoch 106/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3197 - accuracy: 0.8590 - precision: 0.8723 - recall: 0.8999 - AUC: 0.8897 - AUPR: 0.8679 - val_loss: 0.4256 - val_accuracy: 0.8171 - val_precision: 0.8480 - val_recall: 0.8696 - val_AUC: 0.7467 - val_AUPR: 0.7822\n",
            "Epoch 107/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3193 - accuracy: 0.8579 - precision: 0.8713 - recall: 0.8991 - AUC: 0.8903 - AUPR: 0.8690 - val_loss: 0.4268 - val_accuracy: 0.8137 - val_precision: 0.8472 - val_recall: 0.8642 - val_AUC: 0.7464 - val_AUPR: 0.7810\n",
            "Epoch 108/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3188 - accuracy: 0.8582 - precision: 0.8708 - recall: 0.9002 - AUC: 0.8908 - AUPR: 0.8692 - val_loss: 0.4275 - val_accuracy: 0.8138 - val_precision: 0.8455 - val_recall: 0.8670 - val_AUC: 0.7483 - val_AUPR: 0.7829\n",
            "Epoch 109/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3160 - accuracy: 0.8593 - precision: 0.8732 - recall: 0.8991 - AUC: 0.8940 - AUPR: 0.8679 - val_loss: 0.4265 - val_accuracy: 0.8171 - val_precision: 0.8452 - val_recall: 0.8737 - val_AUC: 0.7464 - val_AUPR: 0.7809\n",
            "Epoch 110/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3176 - accuracy: 0.8604 - precision: 0.8720 - recall: 0.9030 - AUC: 0.8920 - AUPR: 0.8722 - val_loss: 0.4318 - val_accuracy: 0.8140 - val_precision: 0.8508 - val_recall: 0.8596 - val_AUC: 0.7445 - val_AUPR: 0.7790\n",
            "Epoch 111/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.8596 - precision: 0.8726 - recall: 0.9005 - AUC: 0.8940 - AUPR: 0.8735 - val_loss: 0.4298 - val_accuracy: 0.8148 - val_precision: 0.8475 - val_recall: 0.8660 - val_AUC: 0.7435 - val_AUPR: 0.7788\n",
            "Epoch 112/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3152 - accuracy: 0.8596 - precision: 0.8736 - recall: 0.8992 - AUC: 0.8957 - AUPR: 0.8675 - val_loss: 0.4284 - val_accuracy: 0.8145 - val_precision: 0.8507 - val_recall: 0.8606 - val_AUC: 0.7472 - val_AUPR: 0.7824\n",
            "Epoch 113/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3197 - accuracy: 0.8576 - precision: 0.8699 - recall: 0.9005 - AUC: 0.8899 - AUPR: 0.8692 - val_loss: 0.4300 - val_accuracy: 0.8147 - val_precision: 0.8502 - val_recall: 0.8616 - val_AUC: 0.7456 - val_AUPR: 0.7795\n",
            "Epoch 114/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3210 - accuracy: 0.8580 - precision: 0.8714 - recall: 0.8992 - AUC: 0.8896 - AUPR: 0.8688 - val_loss: 0.4273 - val_accuracy: 0.8174 - val_precision: 0.8481 - val_recall: 0.8701 - val_AUC: 0.7492 - val_AUPR: 0.7811\n",
            "Epoch 115/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3141 - accuracy: 0.8616 - precision: 0.8746 - recall: 0.9018 - AUC: 0.8946 - AUPR: 0.8729 - val_loss: 0.4276 - val_accuracy: 0.8156 - val_precision: 0.8483 - val_recall: 0.8663 - val_AUC: 0.7487 - val_AUPR: 0.7825\n",
            "Epoch 116/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3126 - accuracy: 0.8621 - precision: 0.8755 - recall: 0.9014 - AUC: 0.8951 - AUPR: 0.8715 - val_loss: 0.4291 - val_accuracy: 0.8145 - val_precision: 0.8481 - val_recall: 0.8645 - val_AUC: 0.7455 - val_AUPR: 0.7779\n",
            "Epoch 117/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3154 - accuracy: 0.8598 - precision: 0.8699 - recall: 0.9047 - AUC: 0.8935 - AUPR: 0.8713 - val_loss: 0.4256 - val_accuracy: 0.8174 - val_precision: 0.8541 - val_recall: 0.8614 - val_AUC: 0.7505 - val_AUPR: 0.7823\n",
            "Epoch 118/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3141 - accuracy: 0.8615 - precision: 0.8768 - recall: 0.8986 - AUC: 0.8943 - AUPR: 0.8716 - val_loss: 0.4244 - val_accuracy: 0.8165 - val_precision: 0.8505 - val_recall: 0.8647 - val_AUC: 0.7512 - val_AUPR: 0.7823\n",
            "Epoch 119/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.8607 - precision: 0.8721 - recall: 0.9033 - AUC: 0.8948 - AUPR: 0.8752 - val_loss: 0.4240 - val_accuracy: 0.8161 - val_precision: 0.8488 - val_recall: 0.8665 - val_AUC: 0.7529 - val_AUPR: 0.7835\n",
            "Epoch 120/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.8610 - precision: 0.8748 - recall: 0.9002 - AUC: 0.8939 - AUPR: 0.8688 - val_loss: 0.4234 - val_accuracy: 0.8166 - val_precision: 0.8518 - val_recall: 0.8632 - val_AUC: 0.7539 - val_AUPR: 0.7861\n",
            "Epoch 121/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3079 - accuracy: 0.8643 - precision: 0.8802 - recall: 0.8992 - AUC: 0.9006 - AUPR: 0.8766 - val_loss: 0.4234 - val_accuracy: 0.8211 - val_precision: 0.8494 - val_recall: 0.8750 - val_AUC: 0.7535 - val_AUPR: 0.7840\n",
            "Epoch 122/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 0.8600 - precision: 0.8693 - recall: 0.9060 - AUC: 0.8967 - AUPR: 0.8757 - val_loss: 0.4267 - val_accuracy: 0.8147 - val_precision: 0.8506 - val_recall: 0.8611 - val_AUC: 0.7528 - val_AUPR: 0.7849\n",
            "Epoch 123/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3121 - accuracy: 0.8626 - precision: 0.8771 - recall: 0.9001 - AUC: 0.8950 - AUPR: 0.8741 - val_loss: 0.4259 - val_accuracy: 0.8171 - val_precision: 0.8501 - val_recall: 0.8665 - val_AUC: 0.7534 - val_AUPR: 0.7844\n",
            "Epoch 124/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3132 - accuracy: 0.8607 - precision: 0.8739 - recall: 0.9011 - AUC: 0.8959 - AUPR: 0.8728 - val_loss: 0.4267 - val_accuracy: 0.8151 - val_precision: 0.8496 - val_recall: 0.8634 - val_AUC: 0.7534 - val_AUPR: 0.7822\n",
            "Epoch 125/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3150 - accuracy: 0.8615 - precision: 0.8750 - recall: 0.9010 - AUC: 0.8946 - AUPR: 0.8754 - val_loss: 0.4258 - val_accuracy: 0.8155 - val_precision: 0.8517 - val_recall: 0.8611 - val_AUC: 0.7549 - val_AUPR: 0.7784\n",
            "Epoch 126/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3124 - accuracy: 0.8626 - precision: 0.8744 - recall: 0.9038 - AUC: 0.8974 - AUPR: 0.8733 - val_loss: 0.4216 - val_accuracy: 0.8193 - val_precision: 0.8488 - val_recall: 0.8725 - val_AUC: 0.7566 - val_AUPR: 0.7801\n",
            "Epoch 127/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3090 - accuracy: 0.8644 - precision: 0.8777 - recall: 0.9027 - AUC: 0.8994 - AUPR: 0.8804 - val_loss: 0.4235 - val_accuracy: 0.8171 - val_precision: 0.8490 - val_recall: 0.8681 - val_AUC: 0.7545 - val_AUPR: 0.7785\n",
            "Epoch 128/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3091 - accuracy: 0.8622 - precision: 0.8726 - recall: 0.9055 - AUC: 0.8997 - AUPR: 0.8757 - val_loss: 0.4234 - val_accuracy: 0.8166 - val_precision: 0.8530 - val_recall: 0.8614 - val_AUC: 0.7576 - val_AUPR: 0.7806\n",
            "Epoch 129/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3099 - accuracy: 0.8641 - precision: 0.8779 - recall: 0.9020 - AUC: 0.8967 - AUPR: 0.8774 - val_loss: 0.4239 - val_accuracy: 0.8174 - val_precision: 0.8534 - val_recall: 0.8624 - val_AUC: 0.7565 - val_AUPR: 0.7818\n",
            "Epoch 130/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3122 - accuracy: 0.8621 - precision: 0.8772 - recall: 0.8991 - AUC: 0.8956 - AUPR: 0.8720 - val_loss: 0.4257 - val_accuracy: 0.8160 - val_precision: 0.8532 - val_recall: 0.8598 - val_AUC: 0.7530 - val_AUPR: 0.7853\n",
            "Epoch 131/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3122 - accuracy: 0.8621 - precision: 0.8730 - recall: 0.9049 - AUC: 0.8952 - AUPR: 0.8762 - val_loss: 0.4250 - val_accuracy: 0.8151 - val_precision: 0.8484 - val_recall: 0.8652 - val_AUC: 0.7530 - val_AUPR: 0.7847\n",
            "Epoch 132/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3117 - accuracy: 0.8621 - precision: 0.8769 - recall: 0.8995 - AUC: 0.8966 - AUPR: 0.8744 - val_loss: 0.4255 - val_accuracy: 0.8186 - val_precision: 0.8517 - val_recall: 0.8670 - val_AUC: 0.7525 - val_AUPR: 0.7851\n",
            "Epoch 133/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3058 - accuracy: 0.8646 - precision: 0.8747 - recall: 0.9073 - AUC: 0.9011 - AUPR: 0.8743 - val_loss: 0.4270 - val_accuracy: 0.8155 - val_precision: 0.8575 - val_recall: 0.8529 - val_AUC: 0.7535 - val_AUPR: 0.7859\n",
            "Epoch 134/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3108 - accuracy: 0.8629 - precision: 0.8793 - recall: 0.8977 - AUC: 0.8977 - AUPR: 0.8741 - val_loss: 0.4269 - val_accuracy: 0.8174 - val_precision: 0.8453 - val_recall: 0.8743 - val_AUC: 0.7499 - val_AUPR: 0.7841\n",
            "Epoch 135/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3098 - accuracy: 0.8643 - precision: 0.8764 - recall: 0.9043 - AUC: 0.8984 - AUPR: 0.8787 - val_loss: 0.4292 - val_accuracy: 0.8160 - val_precision: 0.8554 - val_recall: 0.8567 - val_AUC: 0.7508 - val_AUPR: 0.7857\n",
            "Epoch 136/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3053 - accuracy: 0.8655 - precision: 0.8764 - recall: 0.9066 - AUC: 0.9008 - AUPR: 0.8811 - val_loss: 0.4255 - val_accuracy: 0.8198 - val_precision: 0.8523 - val_recall: 0.8683 - val_AUC: 0.7529 - val_AUPR: 0.7851\n",
            "Epoch 137/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3073 - accuracy: 0.8649 - precision: 0.8799 - recall: 0.9007 - AUC: 0.8991 - AUPR: 0.8752 - val_loss: 0.4263 - val_accuracy: 0.8168 - val_precision: 0.8493 - val_recall: 0.8670 - val_AUC: 0.7540 - val_AUPR: 0.7775\n",
            "Epoch 138/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3075 - accuracy: 0.8639 - precision: 0.8744 - recall: 0.9063 - AUC: 0.9010 - AUPR: 0.8774 - val_loss: 0.4233 - val_accuracy: 0.8176 - val_precision: 0.8515 - val_recall: 0.8655 - val_AUC: 0.7581 - val_AUPR: 0.7879\n",
            "Epoch 139/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3058 - accuracy: 0.8658 - precision: 0.8815 - recall: 0.9003 - AUC: 0.9002 - AUPR: 0.8766 - val_loss: 0.4261 - val_accuracy: 0.8165 - val_precision: 0.8447 - val_recall: 0.8732 - val_AUC: 0.7545 - val_AUPR: 0.7853\n",
            "Epoch 140/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3073 - accuracy: 0.8635 - precision: 0.8766 - recall: 0.9026 - AUC: 0.9010 - AUPR: 0.8805 - val_loss: 0.4270 - val_accuracy: 0.8160 - val_precision: 0.8549 - val_recall: 0.8575 - val_AUC: 0.7570 - val_AUPR: 0.7872\n",
            "Epoch 141/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3050 - accuracy: 0.8668 - precision: 0.8775 - recall: 0.9077 - AUC: 0.9026 - AUPR: 0.8788 - val_loss: 0.4255 - val_accuracy: 0.8160 - val_precision: 0.8470 - val_recall: 0.8688 - val_AUC: 0.7550 - val_AUPR: 0.7854\n",
            "Epoch 142/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3088 - accuracy: 0.8636 - precision: 0.8802 - recall: 0.8978 - AUC: 0.8997 - AUPR: 0.8796 - val_loss: 0.4285 - val_accuracy: 0.8158 - val_precision: 0.8470 - val_recall: 0.8686 - val_AUC: 0.7522 - val_AUPR: 0.7842\n",
            "Epoch 143/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2999 - accuracy: 0.8686 - precision: 0.8799 - recall: 0.9078 - AUC: 0.9061 - AUPR: 0.8770 - val_loss: 0.4295 - val_accuracy: 0.8155 - val_precision: 0.8510 - val_recall: 0.8621 - val_AUC: 0.7521 - val_AUPR: 0.7842\n",
            "Epoch 144/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3011 - accuracy: 0.8665 - precision: 0.8772 - recall: 0.9075 - AUC: 0.9047 - AUPR: 0.8803 - val_loss: 0.4296 - val_accuracy: 0.8150 - val_precision: 0.8494 - val_recall: 0.8634 - val_AUC: 0.7525 - val_AUPR: 0.7838\n",
            "Epoch 145/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3031 - accuracy: 0.8657 - precision: 0.8790 - recall: 0.9034 - AUC: 0.9026 - AUPR: 0.8783 - val_loss: 0.4306 - val_accuracy: 0.8160 - val_precision: 0.8551 - val_recall: 0.8573 - val_AUC: 0.7522 - val_AUPR: 0.7845\n",
            "Epoch 146/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3016 - accuracy: 0.8667 - precision: 0.8797 - recall: 0.9045 - AUC: 0.9052 - AUPR: 0.8830 - val_loss: 0.4305 - val_accuracy: 0.8153 - val_precision: 0.8484 - val_recall: 0.8655 - val_AUC: 0.7504 - val_AUPR: 0.7851\n",
            "Epoch 147/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3077 - accuracy: 0.8631 - precision: 0.8776 - recall: 0.9005 - AUC: 0.9004 - AUPR: 0.8800 - val_loss: 0.4295 - val_accuracy: 0.8155 - val_precision: 0.8517 - val_recall: 0.8611 - val_AUC: 0.7528 - val_AUPR: 0.7858\n",
            "Epoch 148/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3052 - accuracy: 0.8652 - precision: 0.8778 - recall: 0.9042 - AUC: 0.9007 - AUPR: 0.8826 - val_loss: 0.4281 - val_accuracy: 0.8181 - val_precision: 0.8507 - val_recall: 0.8676 - val_AUC: 0.7540 - val_AUPR: 0.7865\n",
            "Epoch 149/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3019 - accuracy: 0.8675 - precision: 0.8804 - recall: 0.9050 - AUC: 0.9025 - AUPR: 0.8840 - val_loss: 0.4297 - val_accuracy: 0.8188 - val_precision: 0.8560 - val_recall: 0.8611 - val_AUC: 0.7521 - val_AUPR: 0.7851\n",
            "Epoch 150/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8662 - precision: 0.8802 - recall: 0.9028 - AUC: 0.9030 - AUPR: 0.8799 - val_loss: 0.4298 - val_accuracy: 0.8193 - val_precision: 0.8531 - val_recall: 0.8663 - val_AUC: 0.7515 - val_AUPR: 0.7851\n",
            "Epoch 151/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3009 - accuracy: 0.8668 - precision: 0.8771 - recall: 0.9080 - AUC: 0.9061 - AUPR: 0.8815 - val_loss: 0.4320 - val_accuracy: 0.8161 - val_precision: 0.8553 - val_recall: 0.8573 - val_AUC: 0.7530 - val_AUPR: 0.7862\n",
            "Epoch 152/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3001 - accuracy: 0.8685 - precision: 0.8826 - recall: 0.9039 - AUC: 0.9050 - AUPR: 0.8819 - val_loss: 0.4295 - val_accuracy: 0.8179 - val_precision: 0.8503 - val_recall: 0.8678 - val_AUC: 0.7538 - val_AUPR: 0.7858\n",
            "Epoch 153/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3044 - accuracy: 0.8650 - precision: 0.8782 - recall: 0.9032 - AUC: 0.9012 - AUPR: 0.8755 - val_loss: 0.4272 - val_accuracy: 0.8194 - val_precision: 0.8522 - val_recall: 0.8678 - val_AUC: 0.7553 - val_AUPR: 0.7879\n",
            "Epoch 154/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3008 - accuracy: 0.8672 - precision: 0.8783 - recall: 0.9072 - AUC: 0.9051 - AUPR: 0.8851 - val_loss: 0.4273 - val_accuracy: 0.8181 - val_precision: 0.8521 - val_recall: 0.8655 - val_AUC: 0.7521 - val_AUPR: 0.7871\n",
            "Epoch 155/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2993 - accuracy: 0.8686 - precision: 0.8834 - recall: 0.9031 - AUC: 0.9074 - AUPR: 0.8790 - val_loss: 0.4294 - val_accuracy: 0.8153 - val_precision: 0.8515 - val_recall: 0.8611 - val_AUC: 0.7535 - val_AUPR: 0.7805\n",
            "Epoch 156/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3023 - accuracy: 0.8672 - precision: 0.8796 - recall: 0.9055 - AUC: 0.9038 - AUPR: 0.8831 - val_loss: 0.4285 - val_accuracy: 0.8171 - val_precision: 0.8499 - val_recall: 0.8668 - val_AUC: 0.7536 - val_AUPR: 0.7809\n",
            "Epoch 157/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2989 - accuracy: 0.8696 - precision: 0.8821 - recall: 0.9067 - AUC: 0.9069 - AUPR: 0.8870 - val_loss: 0.4288 - val_accuracy: 0.8176 - val_precision: 0.8542 - val_recall: 0.8616 - val_AUC: 0.7543 - val_AUPR: 0.7805\n",
            "Epoch 158/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.8679 - precision: 0.8821 - recall: 0.9035 - AUC: 0.9061 - AUPR: 0.8854 - val_loss: 0.4272 - val_accuracy: 0.8196 - val_precision: 0.8566 - val_recall: 0.8619 - val_AUC: 0.7547 - val_AUPR: 0.7875\n",
            "Epoch 159/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2979 - accuracy: 0.8689 - precision: 0.8821 - recall: 0.9053 - AUC: 0.9069 - AUPR: 0.8855 - val_loss: 0.4285 - val_accuracy: 0.8178 - val_precision: 0.8515 - val_recall: 0.8658 - val_AUC: 0.7539 - val_AUPR: 0.7864\n",
            "Epoch 160/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3009 - accuracy: 0.8690 - precision: 0.8809 - recall: 0.9073 - AUC: 0.9042 - AUPR: 0.8782 - val_loss: 0.4300 - val_accuracy: 0.8168 - val_precision: 0.8527 - val_recall: 0.8621 - val_AUC: 0.7532 - val_AUPR: 0.7853\n",
            "Epoch 161/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3006 - accuracy: 0.8676 - precision: 0.8800 - recall: 0.9058 - AUC: 0.9045 - AUPR: 0.8804 - val_loss: 0.4319 - val_accuracy: 0.8161 - val_precision: 0.8564 - val_recall: 0.8557 - val_AUC: 0.7551 - val_AUPR: 0.7859\n",
            "Epoch 162/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2966 - accuracy: 0.8692 - precision: 0.8858 - recall: 0.9010 - AUC: 0.9079 - AUPR: 0.8851 - val_loss: 0.4290 - val_accuracy: 0.8191 - val_precision: 0.8520 - val_recall: 0.8676 - val_AUC: 0.7537 - val_AUPR: 0.7857\n",
            "Epoch 163/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2992 - accuracy: 0.8671 - precision: 0.8774 - recall: 0.9083 - AUC: 0.9062 - AUPR: 0.8834 - val_loss: 0.4336 - val_accuracy: 0.8166 - val_precision: 0.8583 - val_recall: 0.8539 - val_AUC: 0.7549 - val_AUPR: 0.7862\n",
            "Epoch 164/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2981 - accuracy: 0.8683 - precision: 0.8843 - recall: 0.9015 - AUC: 0.9067 - AUPR: 0.8813 - val_loss: 0.4295 - val_accuracy: 0.8178 - val_precision: 0.8483 - val_recall: 0.8704 - val_AUC: 0.7549 - val_AUPR: 0.7854\n",
            "Epoch 165/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2955 - accuracy: 0.8715 - precision: 0.8827 - recall: 0.9095 - AUC: 0.9099 - AUPR: 0.8890 - val_loss: 0.4285 - val_accuracy: 0.8207 - val_precision: 0.8540 - val_recall: 0.8678 - val_AUC: 0.7560 - val_AUPR: 0.7862\n",
            "Epoch 166/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2975 - accuracy: 0.8692 - precision: 0.8822 - recall: 0.9058 - AUC: 0.9070 - AUPR: 0.8845 - val_loss: 0.4288 - val_accuracy: 0.8179 - val_precision: 0.8535 - val_recall: 0.8632 - val_AUC: 0.7548 - val_AUPR: 0.7858\n",
            "Epoch 167/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.8677 - precision: 0.8813 - recall: 0.9043 - AUC: 0.9048 - AUPR: 0.8788 - val_loss: 0.4292 - val_accuracy: 0.8176 - val_precision: 0.8560 - val_recall: 0.8591 - val_AUC: 0.7572 - val_AUPR: 0.7870\n",
            "Epoch 168/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3002 - accuracy: 0.8702 - precision: 0.8833 - recall: 0.9063 - AUC: 0.9057 - AUPR: 0.8817 - val_loss: 0.4314 - val_accuracy: 0.8170 - val_precision: 0.8531 - val_recall: 0.8619 - val_AUC: 0.7529 - val_AUPR: 0.7843\n",
            "Epoch 169/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2975 - accuracy: 0.8696 - precision: 0.8789 - recall: 0.9111 - AUC: 0.9076 - AUPR: 0.8859 - val_loss: 0.4316 - val_accuracy: 0.8151 - val_precision: 0.8556 - val_recall: 0.8549 - val_AUC: 0.7547 - val_AUPR: 0.7850\n",
            "Epoch 170/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2988 - accuracy: 0.8680 - precision: 0.8852 - recall: 0.8995 - AUC: 0.9067 - AUPR: 0.8848 - val_loss: 0.4288 - val_accuracy: 0.8207 - val_precision: 0.8534 - val_recall: 0.8686 - val_AUC: 0.7546 - val_AUPR: 0.7861\n",
            "Epoch 171/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2936 - accuracy: 0.8707 - precision: 0.8820 - recall: 0.9089 - AUC: 0.9102 - AUPR: 0.8850 - val_loss: 0.4291 - val_accuracy: 0.8194 - val_precision: 0.8537 - val_recall: 0.8658 - val_AUC: 0.7554 - val_AUPR: 0.7811\n",
            "Epoch 172/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2940 - accuracy: 0.8701 - precision: 0.8845 - recall: 0.9045 - AUC: 0.9107 - AUPR: 0.8917 - val_loss: 0.4310 - val_accuracy: 0.8173 - val_precision: 0.8550 - val_recall: 0.8598 - val_AUC: 0.7562 - val_AUPR: 0.7804\n",
            "Epoch 173/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2983 - accuracy: 0.8681 - precision: 0.8801 - recall: 0.9066 - AUC: 0.9075 - AUPR: 0.8871 - val_loss: 0.4318 - val_accuracy: 0.8166 - val_precision: 0.8554 - val_recall: 0.8580 - val_AUC: 0.7561 - val_AUPR: 0.7863\n",
            "Epoch 174/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2991 - accuracy: 0.8688 - precision: 0.8832 - recall: 0.9036 - AUC: 0.9045 - AUPR: 0.8863 - val_loss: 0.4266 - val_accuracy: 0.8199 - val_precision: 0.8536 - val_recall: 0.8668 - val_AUC: 0.7597 - val_AUPR: 0.7882\n",
            "Epoch 175/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2911 - accuracy: 0.8729 - precision: 0.8842 - recall: 0.9102 - AUC: 0.9120 - AUPR: 0.8929 - val_loss: 0.4296 - val_accuracy: 0.8179 - val_precision: 0.8553 - val_recall: 0.8606 - val_AUC: 0.7561 - val_AUPR: 0.7859\n",
            "Epoch 176/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2926 - accuracy: 0.8705 - precision: 0.8848 - recall: 0.9048 - AUC: 0.9111 - AUPR: 0.8877 - val_loss: 0.4312 - val_accuracy: 0.8161 - val_precision: 0.8533 - val_recall: 0.8601 - val_AUC: 0.7567 - val_AUPR: 0.7872\n",
            "Epoch 177/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.8707 - precision: 0.8826 - recall: 0.9083 - AUC: 0.9113 - AUPR: 0.8874 - val_loss: 0.4293 - val_accuracy: 0.8191 - val_precision: 0.8534 - val_recall: 0.8655 - val_AUC: 0.7580 - val_AUPR: 0.7884\n",
            "Epoch 178/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2964 - accuracy: 0.8688 - precision: 0.8868 - recall: 0.8990 - AUC: 0.9089 - AUPR: 0.8885 - val_loss: 0.4300 - val_accuracy: 0.8181 - val_precision: 0.8523 - val_recall: 0.8652 - val_AUC: 0.7580 - val_AUPR: 0.7871\n",
            "Epoch 179/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2925 - accuracy: 0.8728 - precision: 0.8819 - recall: 0.9130 - AUC: 0.9096 - AUPR: 0.8852 - val_loss: 0.4319 - val_accuracy: 0.8158 - val_precision: 0.8534 - val_recall: 0.8593 - val_AUC: 0.7564 - val_AUPR: 0.7905\n",
            "Epoch 180/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2939 - accuracy: 0.8699 - precision: 0.8829 - recall: 0.9062 - AUC: 0.9090 - AUPR: 0.8842 - val_loss: 0.4304 - val_accuracy: 0.8212 - val_precision: 0.8581 - val_recall: 0.8629 - val_AUC: 0.7598 - val_AUPR: 0.7920\n",
            "Epoch 181/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 0.8700 - precision: 0.8869 - recall: 0.9011 - AUC: 0.9109 - AUPR: 0.8896 - val_loss: 0.4287 - val_accuracy: 0.8198 - val_precision: 0.8546 - val_recall: 0.8650 - val_AUC: 0.7590 - val_AUPR: 0.7888\n",
            "Epoch 182/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2942 - accuracy: 0.8694 - precision: 0.8822 - recall: 0.9063 - AUC: 0.9099 - AUPR: 0.8885 - val_loss: 0.4300 - val_accuracy: 0.8202 - val_precision: 0.8496 - val_recall: 0.8732 - val_AUC: 0.7565 - val_AUPR: 0.7884\n",
            "Epoch 183/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2925 - accuracy: 0.8698 - precision: 0.8813 - recall: 0.9083 - AUC: 0.9106 - AUPR: 0.8899 - val_loss: 0.4312 - val_accuracy: 0.8173 - val_precision: 0.8535 - val_recall: 0.8619 - val_AUC: 0.7570 - val_AUPR: 0.7885\n",
            "Epoch 184/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2922 - accuracy: 0.8723 - precision: 0.8868 - recall: 0.9055 - AUC: 0.9107 - AUPR: 0.8845 - val_loss: 0.4277 - val_accuracy: 0.8191 - val_precision: 0.8534 - val_recall: 0.8655 - val_AUC: 0.7580 - val_AUPR: 0.7884\n",
            "Epoch 185/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2979 - accuracy: 0.8694 - precision: 0.8785 - recall: 0.9113 - AUC: 0.9078 - AUPR: 0.8844 - val_loss: 0.4310 - val_accuracy: 0.8179 - val_precision: 0.8584 - val_recall: 0.8562 - val_AUC: 0.7591 - val_AUPR: 0.7879\n",
            "Epoch 186/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2929 - accuracy: 0.8734 - precision: 0.8916 - recall: 0.9014 - AUC: 0.9110 - AUPR: 0.8872 - val_loss: 0.4311 - val_accuracy: 0.8166 - val_precision: 0.8509 - val_recall: 0.8645 - val_AUC: 0.7567 - val_AUPR: 0.7794\n",
            "Epoch 187/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2952 - accuracy: 0.8699 - precision: 0.8832 - recall: 0.9058 - AUC: 0.9094 - AUPR: 0.8885 - val_loss: 0.4316 - val_accuracy: 0.8163 - val_precision: 0.8537 - val_recall: 0.8598 - val_AUC: 0.7576 - val_AUPR: 0.7860\n",
            "Epoch 188/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.8719 - precision: 0.8855 - recall: 0.9065 - AUC: 0.9114 - AUPR: 0.8903 - val_loss: 0.4314 - val_accuracy: 0.8181 - val_precision: 0.8550 - val_recall: 0.8614 - val_AUC: 0.7570 - val_AUPR: 0.7866\n",
            "Epoch 189/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2953 - accuracy: 0.8706 - precision: 0.8828 - recall: 0.9077 - AUC: 0.9092 - AUPR: 0.8900 - val_loss: 0.4331 - val_accuracy: 0.8174 - val_precision: 0.8543 - val_recall: 0.8611 - val_AUC: 0.7570 - val_AUPR: 0.7876\n",
            "Epoch 190/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2896 - accuracy: 0.8738 - precision: 0.8860 - recall: 0.9093 - AUC: 0.9115 - AUPR: 0.8894 - val_loss: 0.4302 - val_accuracy: 0.8184 - val_precision: 0.8556 - val_recall: 0.8611 - val_AUC: 0.7589 - val_AUPR: 0.7881\n",
            "Epoch 191/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2953 - accuracy: 0.8707 - precision: 0.8837 - recall: 0.9067 - AUC: 0.9085 - AUPR: 0.8837 - val_loss: 0.4336 - val_accuracy: 0.8161 - val_precision: 0.8513 - val_recall: 0.8629 - val_AUC: 0.7555 - val_AUPR: 0.7859\n",
            "Epoch 192/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2907 - accuracy: 0.8730 - precision: 0.8855 - recall: 0.9086 - AUC: 0.9127 - AUPR: 0.8921 - val_loss: 0.4342 - val_accuracy: 0.8158 - val_precision: 0.8510 - val_recall: 0.8627 - val_AUC: 0.7570 - val_AUPR: 0.7856\n",
            "Epoch 193/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2862 - accuracy: 0.8760 - precision: 0.8896 - recall: 0.9089 - AUC: 0.9153 - AUPR: 0.8866 - val_loss: 0.4335 - val_accuracy: 0.8171 - val_precision: 0.8553 - val_recall: 0.8591 - val_AUC: 0.7586 - val_AUPR: 0.7864\n",
            "Epoch 194/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2889 - accuracy: 0.8739 - precision: 0.8867 - recall: 0.9087 - AUC: 0.9124 - AUPR: 0.8906 - val_loss: 0.4330 - val_accuracy: 0.8153 - val_precision: 0.8520 - val_recall: 0.8603 - val_AUC: 0.7596 - val_AUPR: 0.7861\n",
            "Epoch 195/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2877 - accuracy: 0.8734 - precision: 0.8872 - recall: 0.9071 - AUC: 0.9141 - AUPR: 0.8920 - val_loss: 0.4349 - val_accuracy: 0.8186 - val_precision: 0.8535 - val_recall: 0.8645 - val_AUC: 0.7576 - val_AUPR: 0.7852\n",
            "Epoch 196/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.8739 - precision: 0.8875 - recall: 0.9077 - AUC: 0.9157 - AUPR: 0.8924 - val_loss: 0.4336 - val_accuracy: 0.8178 - val_precision: 0.8556 - val_recall: 0.8598 - val_AUC: 0.7584 - val_AUPR: 0.7852\n",
            "Epoch 197/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2903 - accuracy: 0.8717 - precision: 0.8848 - recall: 0.9071 - AUC: 0.9126 - AUPR: 0.8960 - val_loss: 0.4329 - val_accuracy: 0.8161 - val_precision: 0.8531 - val_recall: 0.8603 - val_AUC: 0.7583 - val_AUPR: 0.7858\n",
            "Epoch 198/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2891 - accuracy: 0.8735 - precision: 0.8871 - recall: 0.9074 - AUC: 0.9131 - AUPR: 0.8934 - val_loss: 0.4338 - val_accuracy: 0.8174 - val_precision: 0.8596 - val_recall: 0.8536 - val_AUC: 0.7592 - val_AUPR: 0.7879\n",
            "Epoch 199/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2868 - accuracy: 0.8746 - precision: 0.8893 - recall: 0.9065 - AUC: 0.9151 - AUPR: 0.8931 - val_loss: 0.4355 - val_accuracy: 0.8145 - val_precision: 0.8509 - val_recall: 0.8603 - val_AUC: 0.7543 - val_AUPR: 0.7839\n",
            "Epoch 200/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.8735 - precision: 0.8853 - recall: 0.9099 - AUC: 0.9155 - AUPR: 0.8921 - val_loss: 0.4366 - val_accuracy: 0.8140 - val_precision: 0.8497 - val_recall: 0.8611 - val_AUC: 0.7536 - val_AUPR: 0.7838\n",
            "Epoch 201/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2864 - accuracy: 0.8740 - precision: 0.8856 - recall: 0.9105 - AUC: 0.9160 - AUPR: 0.8978 - val_loss: 0.4346 - val_accuracy: 0.8161 - val_precision: 0.8527 - val_recall: 0.8609 - val_AUC: 0.7534 - val_AUPR: 0.7839\n",
            "Epoch 202/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2912 - accuracy: 0.8731 - precision: 0.8856 - recall: 0.9087 - AUC: 0.9125 - AUPR: 0.8982 - val_loss: 0.4368 - val_accuracy: 0.8174 - val_precision: 0.8532 - val_recall: 0.8627 - val_AUC: 0.7525 - val_AUPR: 0.7835\n",
            "Epoch 203/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.8739 - precision: 0.8901 - recall: 0.9042 - AUC: 0.9129 - AUPR: 0.8970 - val_loss: 0.4362 - val_accuracy: 0.8160 - val_precision: 0.8511 - val_recall: 0.8629 - val_AUC: 0.7545 - val_AUPR: 0.7840\n",
            "Epoch 204/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2902 - accuracy: 0.8735 - precision: 0.8842 - recall: 0.9114 - AUC: 0.9131 - AUPR: 0.8968 - val_loss: 0.4348 - val_accuracy: 0.8183 - val_precision: 0.8520 - val_recall: 0.8660 - val_AUC: 0.7545 - val_AUPR: 0.7829\n",
            "Epoch 205/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2890 - accuracy: 0.8735 - precision: 0.8855 - recall: 0.9095 - AUC: 0.9130 - AUPR: 0.8917 - val_loss: 0.4346 - val_accuracy: 0.8176 - val_precision: 0.8556 - val_recall: 0.8596 - val_AUC: 0.7556 - val_AUPR: 0.7853\n",
            "Epoch 206/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2894 - accuracy: 0.8741 - precision: 0.8885 - recall: 0.9067 - AUC: 0.9131 - AUPR: 0.8969 - val_loss: 0.4339 - val_accuracy: 0.8166 - val_precision: 0.8527 - val_recall: 0.8619 - val_AUC: 0.7565 - val_AUPR: 0.7791\n",
            "Epoch 207/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2852 - accuracy: 0.8761 - precision: 0.8895 - recall: 0.9092 - AUC: 0.9153 - AUPR: 0.8933 - val_loss: 0.4354 - val_accuracy: 0.8171 - val_precision: 0.8546 - val_recall: 0.8601 - val_AUC: 0.7548 - val_AUPR: 0.7780\n",
            "Epoch 208/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2898 - accuracy: 0.8741 - precision: 0.8871 - recall: 0.9086 - AUC: 0.9121 - AUPR: 0.8920 - val_loss: 0.4340 - val_accuracy: 0.8188 - val_precision: 0.8535 - val_recall: 0.8647 - val_AUC: 0.7542 - val_AUPR: 0.7780\n",
            "Epoch 209/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2825 - accuracy: 0.8758 - precision: 0.8880 - recall: 0.9106 - AUC: 0.9179 - AUPR: 0.8973 - val_loss: 0.4346 - val_accuracy: 0.8189 - val_precision: 0.8521 - val_recall: 0.8670 - val_AUC: 0.7547 - val_AUPR: 0.7851\n",
            "Epoch 210/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2875 - accuracy: 0.8754 - precision: 0.8880 - recall: 0.9098 - AUC: 0.9138 - AUPR: 0.8936 - val_loss: 0.4346 - val_accuracy: 0.8199 - val_precision: 0.8572 - val_recall: 0.8616 - val_AUC: 0.7567 - val_AUPR: 0.7858\n",
            "Epoch 211/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2807 - accuracy: 0.8781 - precision: 0.8929 - recall: 0.9085 - AUC: 0.9193 - AUPR: 0.8997 - val_loss: 0.4354 - val_accuracy: 0.8165 - val_precision: 0.8557 - val_recall: 0.8573 - val_AUC: 0.7564 - val_AUPR: 0.7881\n",
            "Epoch 212/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2874 - accuracy: 0.8736 - precision: 0.8874 - recall: 0.9072 - AUC: 0.9145 - AUPR: 0.8930 - val_loss: 0.4350 - val_accuracy: 0.8171 - val_precision: 0.8528 - val_recall: 0.8627 - val_AUC: 0.7558 - val_AUPR: 0.7795\n",
            "Epoch 213/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2869 - accuracy: 0.8732 - precision: 0.8835 - recall: 0.9117 - AUC: 0.9154 - AUPR: 0.8973 - val_loss: 0.4349 - val_accuracy: 0.8181 - val_precision: 0.8530 - val_recall: 0.8642 - val_AUC: 0.7560 - val_AUPR: 0.7803\n",
            "Epoch 214/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.8740 - precision: 0.8869 - recall: 0.9087 - AUC: 0.9139 - AUPR: 0.8908 - val_loss: 0.4347 - val_accuracy: 0.8170 - val_precision: 0.8501 - val_recall: 0.8663 - val_AUC: 0.7558 - val_AUPR: 0.7788\n",
            "Epoch 215/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2850 - accuracy: 0.8748 - precision: 0.8876 - recall: 0.9093 - AUC: 0.9152 - AUPR: 0.8934 - val_loss: 0.4395 - val_accuracy: 0.8174 - val_precision: 0.8565 - val_recall: 0.8580 - val_AUC: 0.7520 - val_AUPR: 0.7761\n",
            "Epoch 216/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 0.8742 - precision: 0.8909 - recall: 0.9037 - AUC: 0.9167 - AUPR: 0.8932 - val_loss: 0.4380 - val_accuracy: 0.8191 - val_precision: 0.8563 - val_recall: 0.8614 - val_AUC: 0.7542 - val_AUPR: 0.7780\n",
            "Epoch 217/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2865 - accuracy: 0.8746 - precision: 0.8836 - recall: 0.9143 - AUC: 0.9141 - AUPR: 0.8938 - val_loss: 0.4361 - val_accuracy: 0.8166 - val_precision: 0.8550 - val_recall: 0.8585 - val_AUC: 0.7574 - val_AUPR: 0.7804\n",
            "Epoch 218/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2858 - accuracy: 0.8748 - precision: 0.8912 - recall: 0.9045 - AUC: 0.9153 - AUPR: 0.8922 - val_loss: 0.4352 - val_accuracy: 0.8191 - val_precision: 0.8548 - val_recall: 0.8634 - val_AUC: 0.7556 - val_AUPR: 0.7805\n",
            "Epoch 219/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 0.8737 - precision: 0.8839 - recall: 0.9121 - AUC: 0.9175 - AUPR: 0.8959 - val_loss: 0.4386 - val_accuracy: 0.8179 - val_precision: 0.8559 - val_recall: 0.8598 - val_AUC: 0.7537 - val_AUPR: 0.7799\n",
            "Epoch 220/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2852 - accuracy: 0.8777 - precision: 0.8936 - recall: 0.9069 - AUC: 0.9162 - AUPR: 0.8958 - val_loss: 0.4357 - val_accuracy: 0.8174 - val_precision: 0.8491 - val_recall: 0.8686 - val_AUC: 0.7557 - val_AUPR: 0.7801\n",
            "Epoch 221/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2835 - accuracy: 0.8772 - precision: 0.8885 - recall: 0.9127 - AUC: 0.9166 - AUPR: 0.8937 - val_loss: 0.4338 - val_accuracy: 0.8193 - val_precision: 0.8536 - val_recall: 0.8655 - val_AUC: 0.7583 - val_AUPR: 0.7812\n",
            "Epoch 222/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2848 - accuracy: 0.8738 - precision: 0.8844 - recall: 0.9115 - AUC: 0.9167 - AUPR: 0.8971 - val_loss: 0.4355 - val_accuracy: 0.8191 - val_precision: 0.8565 - val_recall: 0.8611 - val_AUC: 0.7585 - val_AUPR: 0.7822\n",
            "Epoch 223/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2853 - accuracy: 0.8749 - precision: 0.8910 - recall: 0.9050 - AUC: 0.9151 - AUPR: 0.8946 - val_loss: 0.4354 - val_accuracy: 0.8188 - val_precision: 0.8559 - val_recall: 0.8614 - val_AUC: 0.7571 - val_AUPR: 0.7811\n",
            "Epoch 224/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2819 - accuracy: 0.8769 - precision: 0.8904 - recall: 0.9095 - AUC: 0.9181 - AUPR: 0.8975 - val_loss: 0.4345 - val_accuracy: 0.8196 - val_precision: 0.8559 - val_recall: 0.8629 - val_AUC: 0.7582 - val_AUPR: 0.7808\n",
            "Epoch 225/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2799 - accuracy: 0.8763 - precision: 0.8861 - recall: 0.9140 - AUC: 0.9192 - AUPR: 0.9002 - val_loss: 0.4387 - val_accuracy: 0.8173 - val_precision: 0.8598 - val_recall: 0.8531 - val_AUC: 0.7558 - val_AUPR: 0.7796\n",
            "Epoch 226/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2862 - accuracy: 0.8771 - precision: 0.8924 - recall: 0.9073 - AUC: 0.9155 - AUPR: 0.8925 - val_loss: 0.4330 - val_accuracy: 0.8212 - val_precision: 0.8550 - val_recall: 0.8673 - val_AUC: 0.7598 - val_AUPR: 0.7812\n",
            "Epoch 227/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2793 - accuracy: 0.8771 - precision: 0.8907 - recall: 0.9095 - AUC: 0.9201 - AUPR: 0.8985 - val_loss: 0.4359 - val_accuracy: 0.8191 - val_precision: 0.8585 - val_recall: 0.8583 - val_AUC: 0.7596 - val_AUPR: 0.7824\n",
            "Epoch 228/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2812 - accuracy: 0.8774 - precision: 0.8897 - recall: 0.9113 - AUC: 0.9189 - AUPR: 0.8963 - val_loss: 0.4329 - val_accuracy: 0.8214 - val_precision: 0.8529 - val_recall: 0.8707 - val_AUC: 0.7607 - val_AUPR: 0.7844\n",
            "Epoch 229/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2822 - accuracy: 0.8759 - precision: 0.8884 - recall: 0.9104 - AUC: 0.9171 - AUPR: 0.8939 - val_loss: 0.4339 - val_accuracy: 0.8207 - val_precision: 0.8607 - val_recall: 0.8583 - val_AUC: 0.7613 - val_AUPR: 0.7847\n",
            "Epoch 230/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2822 - accuracy: 0.8767 - precision: 0.8915 - recall: 0.9077 - AUC: 0.9176 - AUPR: 0.8954 - val_loss: 0.4329 - val_accuracy: 0.8199 - val_precision: 0.8561 - val_recall: 0.8632 - val_AUC: 0.7607 - val_AUPR: 0.7837\n",
            "Epoch 231/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2796 - accuracy: 0.8772 - precision: 0.8892 - recall: 0.9117 - AUC: 0.9192 - AUPR: 0.8977 - val_loss: 0.4340 - val_accuracy: 0.8217 - val_precision: 0.8630 - val_recall: 0.8570 - val_AUC: 0.7612 - val_AUPR: 0.7951\n",
            "Epoch 232/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2845 - accuracy: 0.8750 - precision: 0.8893 - recall: 0.9075 - AUC: 0.9170 - AUPR: 0.8986 - val_loss: 0.4336 - val_accuracy: 0.8217 - val_precision: 0.8584 - val_recall: 0.8634 - val_AUC: 0.7602 - val_AUPR: 0.7928\n",
            "Epoch 233/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2854 - accuracy: 0.8757 - precision: 0.8917 - recall: 0.9056 - AUC: 0.9158 - AUPR: 0.8938 - val_loss: 0.4329 - val_accuracy: 0.8191 - val_precision: 0.8529 - val_recall: 0.8663 - val_AUC: 0.7617 - val_AUPR: 0.7941\n",
            "Epoch 234/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2849 - accuracy: 0.8744 - precision: 0.8865 - recall: 0.9098 - AUC: 0.9171 - AUPR: 0.8970 - val_loss: 0.4361 - val_accuracy: 0.8202 - val_precision: 0.8569 - val_recall: 0.8627 - val_AUC: 0.7586 - val_AUPR: 0.7921\n",
            "Epoch 235/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2822 - accuracy: 0.8771 - precision: 0.8893 - recall: 0.9114 - AUC: 0.9192 - AUPR: 0.9004 - val_loss: 0.4404 - val_accuracy: 0.8181 - val_precision: 0.8563 - val_recall: 0.8596 - val_AUC: 0.7563 - val_AUPR: 0.7885\n",
            "Epoch 236/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2831 - accuracy: 0.8761 - precision: 0.8895 - recall: 0.9091 - AUC: 0.9173 - AUPR: 0.8980 - val_loss: 0.4370 - val_accuracy: 0.8186 - val_precision: 0.8546 - val_recall: 0.8629 - val_AUC: 0.7589 - val_AUPR: 0.7889\n",
            "Epoch 237/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2799 - accuracy: 0.8773 - precision: 0.8936 - recall: 0.9061 - AUC: 0.9184 - AUPR: 0.8989 - val_loss: 0.4395 - val_accuracy: 0.8186 - val_precision: 0.8549 - val_recall: 0.8624 - val_AUC: 0.7576 - val_AUPR: 0.7871\n",
            "Epoch 238/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.8779 - precision: 0.8896 - recall: 0.9124 - AUC: 0.9174 - AUPR: 0.8963 - val_loss: 0.4391 - val_accuracy: 0.8181 - val_precision: 0.8555 - val_recall: 0.8606 - val_AUC: 0.7586 - val_AUPR: 0.7913\n",
            "Epoch 239/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2794 - accuracy: 0.8786 - precision: 0.8927 - recall: 0.9096 - AUC: 0.9198 - AUPR: 0.9005 - val_loss: 0.4394 - val_accuracy: 0.8189 - val_precision: 0.8555 - val_recall: 0.8621 - val_AUC: 0.7567 - val_AUPR: 0.7865\n",
            "Epoch 240/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2800 - accuracy: 0.8777 - precision: 0.8908 - recall: 0.9105 - AUC: 0.9192 - AUPR: 0.8982 - val_loss: 0.4397 - val_accuracy: 0.8179 - val_precision: 0.8553 - val_recall: 0.8606 - val_AUC: 0.7588 - val_AUPR: 0.7817\n",
            "Epoch 241/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2791 - accuracy: 0.8776 - precision: 0.8909 - recall: 0.9102 - AUC: 0.9207 - AUPR: 0.8972 - val_loss: 0.4385 - val_accuracy: 0.8181 - val_precision: 0.8543 - val_recall: 0.8624 - val_AUC: 0.7570 - val_AUPR: 0.7815\n",
            "Epoch 242/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2816 - accuracy: 0.8757 - precision: 0.8906 - recall: 0.9069 - AUC: 0.9176 - AUPR: 0.8974 - val_loss: 0.4391 - val_accuracy: 0.8191 - val_precision: 0.8574 - val_recall: 0.8598 - val_AUC: 0.7561 - val_AUPR: 0.7810\n",
            "Epoch 243/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2794 - accuracy: 0.8778 - precision: 0.8915 - recall: 0.9097 - AUC: 0.9195 - AUPR: 0.9015 - val_loss: 0.4380 - val_accuracy: 0.8201 - val_precision: 0.8565 - val_recall: 0.8629 - val_AUC: 0.7573 - val_AUPR: 0.7818\n",
            "Epoch 244/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2834 - accuracy: 0.8768 - precision: 0.8907 - recall: 0.9089 - AUC: 0.9174 - AUPR: 0.8933 - val_loss: 0.4377 - val_accuracy: 0.8198 - val_precision: 0.8566 - val_recall: 0.8621 - val_AUC: 0.7582 - val_AUPR: 0.7892\n",
            "Epoch 245/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2755 - accuracy: 0.8796 - precision: 0.8923 - recall: 0.9120 - AUC: 0.9223 - AUPR: 0.9005 - val_loss: 0.4379 - val_accuracy: 0.8209 - val_precision: 0.8549 - val_recall: 0.8668 - val_AUC: 0.7561 - val_AUPR: 0.7812\n",
            "Epoch 246/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 0.8791 - precision: 0.8909 - recall: 0.9129 - AUC: 0.9240 - AUPR: 0.9011 - val_loss: 0.4391 - val_accuracy: 0.8198 - val_precision: 0.8559 - val_recall: 0.8632 - val_AUC: 0.7568 - val_AUPR: 0.7889\n",
            "Epoch 247/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2763 - accuracy: 0.8803 - precision: 0.8914 - recall: 0.9145 - AUC: 0.9224 - AUPR: 0.9038 - val_loss: 0.4398 - val_accuracy: 0.8183 - val_precision: 0.8561 - val_recall: 0.8601 - val_AUC: 0.7568 - val_AUPR: 0.7921\n",
            "Epoch 248/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2797 - accuracy: 0.8776 - precision: 0.8952 - recall: 0.9047 - AUC: 0.9196 - AUPR: 0.8964 - val_loss: 0.4389 - val_accuracy: 0.8199 - val_precision: 0.8539 - val_recall: 0.8663 - val_AUC: 0.7580 - val_AUPR: 0.7887\n",
            "Epoch 249/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2771 - accuracy: 0.8773 - precision: 0.8880 - recall: 0.9133 - AUC: 0.9208 - AUPR: 0.8985 - val_loss: 0.4394 - val_accuracy: 0.8193 - val_precision: 0.8587 - val_recall: 0.8583 - val_AUC: 0.7589 - val_AUPR: 0.7915\n",
            "Epoch 250/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2821 - accuracy: 0.8767 - precision: 0.8914 - recall: 0.9078 - AUC: 0.9175 - AUPR: 0.8986 - val_loss: 0.4384 - val_accuracy: 0.8183 - val_precision: 0.8554 - val_recall: 0.8611 - val_AUC: 0.7570 - val_AUPR: 0.7910\n",
            "Epoch 251/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2800 - accuracy: 0.8791 - precision: 0.8934 - recall: 0.9097 - AUC: 0.9199 - AUPR: 0.8983 - val_loss: 0.4375 - val_accuracy: 0.8194 - val_precision: 0.8546 - val_recall: 0.8645 - val_AUC: 0.7583 - val_AUPR: 0.7919\n",
            "Epoch 252/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2751 - accuracy: 0.8804 - precision: 0.8920 - recall: 0.9140 - AUC: 0.9225 - AUPR: 0.9008 - val_loss: 0.4401 - val_accuracy: 0.8181 - val_precision: 0.8575 - val_recall: 0.8578 - val_AUC: 0.7574 - val_AUPR: 0.7872\n",
            "Epoch 253/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2768 - accuracy: 0.8794 - precision: 0.8932 - recall: 0.9105 - AUC: 0.9224 - AUPR: 0.9031 - val_loss: 0.4417 - val_accuracy: 0.8194 - val_precision: 0.8566 - val_recall: 0.8616 - val_AUC: 0.7565 - val_AUPR: 0.7909\n",
            "Epoch 254/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.8820 - precision: 0.8939 - recall: 0.9144 - AUC: 0.9248 - AUPR: 0.9016 - val_loss: 0.4394 - val_accuracy: 0.8188 - val_precision: 0.8553 - val_recall: 0.8621 - val_AUC: 0.7584 - val_AUPR: 0.7913\n",
            "Epoch 255/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2799 - accuracy: 0.8768 - precision: 0.8886 - recall: 0.9117 - AUC: 0.9198 - AUPR: 0.9032 - val_loss: 0.4383 - val_accuracy: 0.8212 - val_precision: 0.8605 - val_recall: 0.8596 - val_AUC: 0.7598 - val_AUPR: 0.7928\n",
            "Epoch 256/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2740 - accuracy: 0.8816 - precision: 0.8946 - recall: 0.9128 - AUC: 0.9232 - AUPR: 0.8991 - val_loss: 0.4396 - val_accuracy: 0.8201 - val_precision: 0.8623 - val_recall: 0.8549 - val_AUC: 0.7602 - val_AUPR: 0.7935\n",
            "Epoch 257/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2739 - accuracy: 0.8816 - precision: 0.8968 - recall: 0.9100 - AUC: 0.9226 - AUPR: 0.9026 - val_loss: 0.4409 - val_accuracy: 0.8198 - val_precision: 0.8561 - val_recall: 0.8629 - val_AUC: 0.7572 - val_AUPR: 0.7918\n",
            "Epoch 258/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2769 - accuracy: 0.8787 - precision: 0.8895 - recall: 0.9140 - AUC: 0.9213 - AUPR: 0.9049 - val_loss: 0.4437 - val_accuracy: 0.8171 - val_precision: 0.8568 - val_recall: 0.8570 - val_AUC: 0.7584 - val_AUPR: 0.7870\n",
            "Epoch 259/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2741 - accuracy: 0.8810 - precision: 0.8953 - recall: 0.9107 - AUC: 0.9231 - AUPR: 0.9007 - val_loss: 0.4417 - val_accuracy: 0.8196 - val_precision: 0.8524 - val_recall: 0.8678 - val_AUC: 0.7569 - val_AUPR: 0.7807\n",
            "Epoch 260/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2774 - accuracy: 0.8788 - precision: 0.8918 - recall: 0.9112 - AUC: 0.9208 - AUPR: 0.8989 - val_loss: 0.4426 - val_accuracy: 0.8189 - val_precision: 0.8568 - val_recall: 0.8603 - val_AUC: 0.7587 - val_AUPR: 0.7822\n",
            "Epoch 261/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2742 - accuracy: 0.8803 - precision: 0.8907 - recall: 0.9156 - AUC: 0.9225 - AUPR: 0.8989 - val_loss: 0.4414 - val_accuracy: 0.8196 - val_precision: 0.8590 - val_recall: 0.8585 - val_AUC: 0.7590 - val_AUPR: 0.7823\n",
            "Epoch 262/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2785 - accuracy: 0.8783 - precision: 0.8932 - recall: 0.9085 - AUC: 0.9184 - AUPR: 0.8970 - val_loss: 0.4408 - val_accuracy: 0.8161 - val_precision: 0.8562 - val_recall: 0.8560 - val_AUC: 0.7598 - val_AUPR: 0.7818\n",
            "Epoch 263/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2760 - accuracy: 0.8786 - precision: 0.8921 - recall: 0.9104 - AUC: 0.9214 - AUPR: 0.9025 - val_loss: 0.4393 - val_accuracy: 0.8188 - val_precision: 0.8501 - val_recall: 0.8696 - val_AUC: 0.7583 - val_AUPR: 0.7808\n",
            "Epoch 264/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2778 - accuracy: 0.8784 - precision: 0.8899 - recall: 0.9130 - AUC: 0.9204 - AUPR: 0.8977 - val_loss: 0.4399 - val_accuracy: 0.8153 - val_precision: 0.8529 - val_recall: 0.8591 - val_AUC: 0.7586 - val_AUPR: 0.7815\n",
            "Epoch 265/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2750 - accuracy: 0.8799 - precision: 0.8944 - recall: 0.9098 - AUC: 0.9222 - AUPR: 0.9031 - val_loss: 0.4399 - val_accuracy: 0.8171 - val_precision: 0.8581 - val_recall: 0.8552 - val_AUC: 0.7607 - val_AUPR: 0.7828\n",
            "Epoch 266/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2766 - accuracy: 0.8794 - precision: 0.8932 - recall: 0.9105 - AUC: 0.9219 - AUPR: 0.8987 - val_loss: 0.4422 - val_accuracy: 0.8170 - val_precision: 0.8526 - val_recall: 0.8627 - val_AUC: 0.7583 - val_AUPR: 0.7803\n",
            "Epoch 267/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2716 - accuracy: 0.8815 - precision: 0.8930 - recall: 0.9147 - AUC: 0.9252 - AUPR: 0.9015 - val_loss: 0.4395 - val_accuracy: 0.8186 - val_precision: 0.8538 - val_recall: 0.8640 - val_AUC: 0.7602 - val_AUPR: 0.7809\n",
            "Epoch 268/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2767 - accuracy: 0.8808 - precision: 0.8979 - recall: 0.9072 - AUC: 0.9208 - AUPR: 0.9027 - val_loss: 0.4418 - val_accuracy: 0.8156 - val_precision: 0.8553 - val_recall: 0.8562 - val_AUC: 0.7600 - val_AUPR: 0.7880\n",
            "Epoch 269/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2817 - accuracy: 0.8758 - precision: 0.8853 - recall: 0.9141 - AUC: 0.9187 - AUPR: 0.9008 - val_loss: 0.4431 - val_accuracy: 0.8165 - val_precision: 0.8517 - val_recall: 0.8629 - val_AUC: 0.7584 - val_AUPR: 0.7812\n",
            "Epoch 270/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2761 - accuracy: 0.8815 - precision: 0.8959 - recall: 0.9110 - AUC: 0.9233 - AUPR: 0.9028 - val_loss: 0.4429 - val_accuracy: 0.8156 - val_precision: 0.8512 - val_recall: 0.8621 - val_AUC: 0.7569 - val_AUPR: 0.7806\n",
            "Epoch 271/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2713 - accuracy: 0.8832 - precision: 0.8946 - recall: 0.9157 - AUC: 0.9239 - AUPR: 0.9016 - val_loss: 0.4433 - val_accuracy: 0.8179 - val_precision: 0.8586 - val_recall: 0.8560 - val_AUC: 0.7592 - val_AUPR: 0.7809\n",
            "Epoch 272/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 0.8784 - precision: 0.8950 - recall: 0.9063 - AUC: 0.9209 - AUPR: 0.8972 - val_loss: 0.4436 - val_accuracy: 0.8161 - val_precision: 0.8522 - val_recall: 0.8616 - val_AUC: 0.7571 - val_AUPR: 0.7793\n",
            "Epoch 273/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2733 - accuracy: 0.8804 - precision: 0.8927 - recall: 0.9130 - AUC: 0.9236 - AUPR: 0.9002 - val_loss: 0.4425 - val_accuracy: 0.8178 - val_precision: 0.8544 - val_recall: 0.8616 - val_AUC: 0.7578 - val_AUPR: 0.7800\n",
            "Epoch 274/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2716 - accuracy: 0.8823 - precision: 0.8953 - recall: 0.9133 - AUC: 0.9245 - AUPR: 0.9025 - val_loss: 0.4439 - val_accuracy: 0.8176 - val_precision: 0.8554 - val_recall: 0.8598 - val_AUC: 0.7581 - val_AUPR: 0.7802\n",
            "Epoch 275/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2767 - accuracy: 0.8783 - precision: 0.8908 - recall: 0.9117 - AUC: 0.9220 - AUPR: 0.9007 - val_loss: 0.4421 - val_accuracy: 0.8179 - val_precision: 0.8551 - val_recall: 0.8609 - val_AUC: 0.7592 - val_AUPR: 0.7813\n",
            "Epoch 276/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2746 - accuracy: 0.8805 - precision: 0.8951 - recall: 0.9101 - AUC: 0.9234 - AUPR: 0.9056 - val_loss: 0.4424 - val_accuracy: 0.8165 - val_precision: 0.8552 - val_recall: 0.8580 - val_AUC: 0.7604 - val_AUPR: 0.7825\n",
            "Epoch 277/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2764 - accuracy: 0.8809 - precision: 0.8914 - recall: 0.9155 - AUC: 0.9215 - AUPR: 0.9054 - val_loss: 0.4431 - val_accuracy: 0.8168 - val_precision: 0.8563 - val_recall: 0.8570 - val_AUC: 0.7586 - val_AUPR: 0.7812\n",
            "Epoch 278/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2719 - accuracy: 0.8817 - precision: 0.8970 - recall: 0.9099 - AUC: 0.9245 - AUPR: 0.9065 - val_loss: 0.4411 - val_accuracy: 0.8186 - val_precision: 0.8571 - val_recall: 0.8593 - val_AUC: 0.7601 - val_AUPR: 0.7833\n",
            "Epoch 279/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2705 - accuracy: 0.8814 - precision: 0.8940 - recall: 0.9132 - AUC: 0.9250 - AUPR: 0.9058 - val_loss: 0.4417 - val_accuracy: 0.8173 - val_precision: 0.8561 - val_recall: 0.8583 - val_AUC: 0.7611 - val_AUPR: 0.7837\n",
            "Epoch 280/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2788 - accuracy: 0.8771 - precision: 0.8888 - recall: 0.9120 - AUC: 0.9194 - AUPR: 0.9016 - val_loss: 0.4450 - val_accuracy: 0.8153 - val_precision: 0.8567 - val_recall: 0.8536 - val_AUC: 0.7588 - val_AUPR: 0.7815\n",
            "Epoch 281/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2705 - accuracy: 0.8817 - precision: 0.8951 - recall: 0.9124 - AUC: 0.9255 - AUPR: 0.9052 - val_loss: 0.4434 - val_accuracy: 0.8189 - val_precision: 0.8590 - val_recall: 0.8573 - val_AUC: 0.7603 - val_AUPR: 0.7819\n",
            "Epoch 282/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2785 - accuracy: 0.8788 - precision: 0.8962 - recall: 0.9055 - AUC: 0.9200 - AUPR: 0.9047 - val_loss: 0.4417 - val_accuracy: 0.8196 - val_precision: 0.8510 - val_recall: 0.8699 - val_AUC: 0.7585 - val_AUPR: 0.7804\n",
            "Epoch 283/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2733 - accuracy: 0.8796 - precision: 0.8887 - recall: 0.9168 - AUC: 0.9223 - AUPR: 0.9042 - val_loss: 0.4423 - val_accuracy: 0.8189 - val_precision: 0.8577 - val_recall: 0.8591 - val_AUC: 0.7614 - val_AUPR: 0.7835\n",
            "Epoch 284/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2706 - accuracy: 0.8819 - precision: 0.8978 - recall: 0.9092 - AUC: 0.9252 - AUPR: 0.8996 - val_loss: 0.4408 - val_accuracy: 0.8191 - val_precision: 0.8548 - val_recall: 0.8634 - val_AUC: 0.7601 - val_AUPR: 0.7834\n",
            "Epoch 285/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2707 - accuracy: 0.8821 - precision: 0.8911 - recall: 0.9184 - AUC: 0.9246 - AUPR: 0.9003 - val_loss: 0.4425 - val_accuracy: 0.8186 - val_precision: 0.8540 - val_recall: 0.8637 - val_AUC: 0.7595 - val_AUPR: 0.7825\n",
            "Epoch 286/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2696 - accuracy: 0.8829 - precision: 0.8994 - recall: 0.9091 - AUC: 0.9261 - AUPR: 0.9022 - val_loss: 0.4413 - val_accuracy: 0.8178 - val_precision: 0.8542 - val_recall: 0.8619 - val_AUC: 0.7594 - val_AUPR: 0.7816\n",
            "Epoch 287/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2695 - accuracy: 0.8830 - precision: 0.8914 - recall: 0.9195 - AUC: 0.9269 - AUPR: 0.9073 - val_loss: 0.4433 - val_accuracy: 0.8160 - val_precision: 0.8569 - val_recall: 0.8547 - val_AUC: 0.7595 - val_AUPR: 0.7831\n",
            "Epoch 288/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2724 - accuracy: 0.8814 - precision: 0.8963 - recall: 0.9104 - AUC: 0.9241 - AUPR: 0.8997 - val_loss: 0.4438 - val_accuracy: 0.8150 - val_precision: 0.8526 - val_recall: 0.8588 - val_AUC: 0.7585 - val_AUPR: 0.7821\n",
            "Epoch 289/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 0.8826 - precision: 0.8948 - recall: 0.9144 - AUC: 0.9261 - AUPR: 0.9048 - val_loss: 0.4445 - val_accuracy: 0.8155 - val_precision: 0.8538 - val_recall: 0.8580 - val_AUC: 0.7592 - val_AUPR: 0.7826\n",
            "Epoch 290/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2721 - accuracy: 0.8826 - precision: 0.8955 - recall: 0.9135 - AUC: 0.9227 - AUPR: 0.9045 - val_loss: 0.4439 - val_accuracy: 0.8161 - val_precision: 0.8553 - val_recall: 0.8573 - val_AUC: 0.7602 - val_AUPR: 0.7830\n",
            "Epoch 291/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2669 - accuracy: 0.8849 - precision: 0.8999 - recall: 0.9122 - AUC: 0.9273 - AUPR: 0.9081 - val_loss: 0.4431 - val_accuracy: 0.8160 - val_precision: 0.8532 - val_recall: 0.8598 - val_AUC: 0.7604 - val_AUPR: 0.7885\n",
            "Epoch 292/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2681 - accuracy: 0.8824 - precision: 0.8947 - recall: 0.9141 - AUC: 0.9267 - AUPR: 0.9083 - val_loss: 0.4442 - val_accuracy: 0.8156 - val_precision: 0.8517 - val_recall: 0.8614 - val_AUC: 0.7598 - val_AUPR: 0.7818\n",
            "Epoch 293/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2702 - accuracy: 0.8819 - precision: 0.8930 - recall: 0.9155 - AUC: 0.9262 - AUPR: 0.9047 - val_loss: 0.4465 - val_accuracy: 0.8150 - val_precision: 0.8554 - val_recall: 0.8549 - val_AUC: 0.7590 - val_AUPR: 0.7817\n",
            "Epoch 294/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2690 - accuracy: 0.8829 - precision: 0.8968 - recall: 0.9123 - AUC: 0.9255 - AUPR: 0.9047 - val_loss: 0.4462 - val_accuracy: 0.8151 - val_precision: 0.8565 - val_recall: 0.8536 - val_AUC: 0.7608 - val_AUPR: 0.7836\n",
            "Epoch 295/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2733 - accuracy: 0.8811 - precision: 0.8968 - recall: 0.9091 - AUC: 0.9227 - AUPR: 0.9042 - val_loss: 0.4443 - val_accuracy: 0.8170 - val_precision: 0.8531 - val_recall: 0.8619 - val_AUC: 0.7608 - val_AUPR: 0.7821\n",
            "Epoch 296/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2708 - accuracy: 0.8832 - precision: 0.8951 - recall: 0.9151 - AUC: 0.9243 - AUPR: 0.9027 - val_loss: 0.4433 - val_accuracy: 0.8196 - val_precision: 0.8537 - val_recall: 0.8660 - val_AUC: 0.7603 - val_AUPR: 0.7812\n",
            "Epoch 297/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2727 - accuracy: 0.8830 - precision: 0.8959 - recall: 0.9136 - AUC: 0.9230 - AUPR: 0.8999 - val_loss: 0.4429 - val_accuracy: 0.8147 - val_precision: 0.8537 - val_recall: 0.8567 - val_AUC: 0.7620 - val_AUPR: 0.7844\n",
            "Epoch 298/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2715 - accuracy: 0.8817 - precision: 0.8958 - recall: 0.9115 - AUC: 0.9249 - AUPR: 0.9023 - val_loss: 0.4406 - val_accuracy: 0.8184 - val_precision: 0.8529 - val_recall: 0.8650 - val_AUC: 0.7617 - val_AUPR: 0.7836\n",
            "Epoch 299/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2665 - accuracy: 0.8829 - precision: 0.8945 - recall: 0.9154 - AUC: 0.9278 - AUPR: 0.9076 - val_loss: 0.4421 - val_accuracy: 0.8176 - val_precision: 0.8558 - val_recall: 0.8593 - val_AUC: 0.7616 - val_AUPR: 0.7845\n",
            "Epoch 300/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.8814 - precision: 0.8949 - recall: 0.9121 - AUC: 0.9234 - AUPR: 0.9038 - val_loss: 0.4440 - val_accuracy: 0.8173 - val_precision: 0.8548 - val_recall: 0.8601 - val_AUC: 0.7597 - val_AUPR: 0.7823\n",
            "Epoch 301/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2740 - accuracy: 0.8795 - precision: 0.8917 - recall: 0.9127 - AUC: 0.9229 - AUPR: 0.9033 - val_loss: 0.4444 - val_accuracy: 0.8176 - val_precision: 0.8556 - val_recall: 0.8596 - val_AUC: 0.7596 - val_AUPR: 0.7828\n",
            "Epoch 302/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2692 - accuracy: 0.8815 - precision: 0.8976 - recall: 0.9086 - AUC: 0.9267 - AUPR: 0.9075 - val_loss: 0.4443 - val_accuracy: 0.8184 - val_precision: 0.8551 - val_recall: 0.8619 - val_AUC: 0.7591 - val_AUPR: 0.7822\n",
            "Epoch 303/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2681 - accuracy: 0.8820 - precision: 0.8915 - recall: 0.9175 - AUC: 0.9257 - AUPR: 0.9074 - val_loss: 0.4450 - val_accuracy: 0.8170 - val_precision: 0.8556 - val_recall: 0.8583 - val_AUC: 0.7595 - val_AUPR: 0.7822\n",
            "Epoch 304/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2697 - accuracy: 0.8811 - precision: 0.8970 - recall: 0.9089 - AUC: 0.9252 - AUPR: 0.9041 - val_loss: 0.4447 - val_accuracy: 0.8158 - val_precision: 0.8536 - val_recall: 0.8591 - val_AUC: 0.7601 - val_AUPR: 0.7815\n",
            "Epoch 305/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2679 - accuracy: 0.8836 - precision: 0.8951 - recall: 0.9158 - AUC: 0.9271 - AUPR: 0.9076 - val_loss: 0.4445 - val_accuracy: 0.8174 - val_precision: 0.8538 - val_recall: 0.8619 - val_AUC: 0.7599 - val_AUPR: 0.7816\n",
            "Epoch 306/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2700 - accuracy: 0.8822 - precision: 0.8957 - recall: 0.9124 - AUC: 0.9265 - AUPR: 0.9089 - val_loss: 0.4443 - val_accuracy: 0.8171 - val_precision: 0.8586 - val_recall: 0.8544 - val_AUC: 0.7617 - val_AUPR: 0.7838\n",
            "Epoch 307/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2690 - accuracy: 0.8814 - precision: 0.8939 - recall: 0.9134 - AUC: 0.9261 - AUPR: 0.9076 - val_loss: 0.4401 - val_accuracy: 0.8196 - val_precision: 0.8528 - val_recall: 0.8673 - val_AUC: 0.7621 - val_AUPR: 0.7838\n",
            "Epoch 308/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2656 - accuracy: 0.8847 - precision: 0.8992 - recall: 0.9128 - AUC: 0.9290 - AUPR: 0.9099 - val_loss: 0.4426 - val_accuracy: 0.8173 - val_precision: 0.8572 - val_recall: 0.8567 - val_AUC: 0.7618 - val_AUPR: 0.7839\n",
            "Epoch 309/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2660 - accuracy: 0.8830 - precision: 0.8960 - recall: 0.9137 - AUC: 0.9280 - AUPR: 0.9088 - val_loss: 0.4402 - val_accuracy: 0.8206 - val_precision: 0.8561 - val_recall: 0.8645 - val_AUC: 0.7648 - val_AUPR: 0.7853\n",
            "Epoch 310/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2671 - accuracy: 0.8839 - precision: 0.8964 - recall: 0.9147 - AUC: 0.9281 - AUPR: 0.9068 - val_loss: 0.4437 - val_accuracy: 0.8193 - val_precision: 0.8602 - val_recall: 0.8562 - val_AUC: 0.7627 - val_AUPR: 0.7838\n",
            "Epoch 311/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2690 - accuracy: 0.8848 - precision: 0.8988 - recall: 0.9133 - AUC: 0.9256 - AUPR: 0.9055 - val_loss: 0.4428 - val_accuracy: 0.8202 - val_precision: 0.8533 - val_recall: 0.8678 - val_AUC: 0.7602 - val_AUPR: 0.7820\n",
            "Epoch 312/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2669 - accuracy: 0.8838 - precision: 0.8942 - recall: 0.9174 - AUC: 0.9279 - AUPR: 0.9105 - val_loss: 0.4457 - val_accuracy: 0.8196 - val_precision: 0.8590 - val_recall: 0.8585 - val_AUC: 0.7603 - val_AUPR: 0.7823\n",
            "Epoch 313/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2687 - accuracy: 0.8828 - precision: 0.8963 - recall: 0.9128 - AUC: 0.9263 - AUPR: 0.9020 - val_loss: 0.4467 - val_accuracy: 0.8174 - val_precision: 0.8596 - val_recall: 0.8536 - val_AUC: 0.7596 - val_AUPR: 0.7832\n",
            "Epoch 314/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2652 - accuracy: 0.8867 - precision: 0.8999 - recall: 0.9156 - AUC: 0.9284 - AUPR: 0.9108 - val_loss: 0.4449 - val_accuracy: 0.8178 - val_precision: 0.8560 - val_recall: 0.8593 - val_AUC: 0.7605 - val_AUPR: 0.7840\n",
            "Epoch 315/400\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.2695 - accuracy: 0.8833 - precision: 0.8977 - recall: 0.9120 - AUC: 0.9260 - AUPR: 0.9067 - val_loss: 0.4446 - val_accuracy: 0.8178 - val_precision: 0.8562 - val_recall: 0.8591 - val_AUC: 0.7623 - val_AUPR: 0.7846\n",
            "Epoch 316/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.8816 - precision: 0.8945 - recall: 0.9131 - AUC: 0.9236 - AUPR: 0.9044 - val_loss: 0.4467 - val_accuracy: 0.8168 - val_precision: 0.8593 - val_recall: 0.8529 - val_AUC: 0.7599 - val_AUPR: 0.7832\n",
            "Epoch 317/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 0.8830 - precision: 0.8983 - recall: 0.9105 - AUC: 0.9263 - AUPR: 0.9063 - val_loss: 0.4447 - val_accuracy: 0.8174 - val_precision: 0.8570 - val_recall: 0.8573 - val_AUC: 0.7611 - val_AUPR: 0.7828\n",
            "Epoch 318/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2676 - accuracy: 0.8827 - precision: 0.8942 - recall: 0.9153 - AUC: 0.9273 - AUPR: 0.9054 - val_loss: 0.4463 - val_accuracy: 0.8168 - val_precision: 0.8595 - val_recall: 0.8526 - val_AUC: 0.7603 - val_AUPR: 0.7835\n",
            "Epoch 319/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2665 - accuracy: 0.8836 - precision: 0.8991 - recall: 0.9107 - AUC: 0.9289 - AUPR: 0.9064 - val_loss: 0.4478 - val_accuracy: 0.8184 - val_precision: 0.8556 - val_recall: 0.8611 - val_AUC: 0.7558 - val_AUPR: 0.7807\n",
            "Epoch 320/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2665 - accuracy: 0.8848 - precision: 0.8979 - recall: 0.9145 - AUC: 0.9271 - AUPR: 0.9083 - val_loss: 0.4470 - val_accuracy: 0.8179 - val_precision: 0.8573 - val_recall: 0.8578 - val_AUC: 0.7580 - val_AUPR: 0.7819\n",
            "Epoch 321/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2667 - accuracy: 0.8846 - precision: 0.8971 - recall: 0.9152 - AUC: 0.9271 - AUPR: 0.9079 - val_loss: 0.4446 - val_accuracy: 0.8194 - val_precision: 0.8558 - val_recall: 0.8627 - val_AUC: 0.7591 - val_AUPR: 0.7825\n",
            "Epoch 322/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2680 - accuracy: 0.8844 - precision: 0.8982 - recall: 0.9133 - AUC: 0.9260 - AUPR: 0.9053 - val_loss: 0.4486 - val_accuracy: 0.8184 - val_precision: 0.8573 - val_recall: 0.8588 - val_AUC: 0.7570 - val_AUPR: 0.7804\n",
            "Epoch 323/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2652 - accuracy: 0.8835 - precision: 0.8945 - recall: 0.9165 - AUC: 0.9284 - AUPR: 0.9082 - val_loss: 0.4477 - val_accuracy: 0.8179 - val_precision: 0.8551 - val_recall: 0.8609 - val_AUC: 0.7562 - val_AUPR: 0.7854\n",
            "Epoch 324/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2717 - accuracy: 0.8826 - precision: 0.8966 - recall: 0.9120 - AUC: 0.9235 - AUPR: 0.9071 - val_loss: 0.4511 - val_accuracy: 0.8161 - val_precision: 0.8564 - val_recall: 0.8557 - val_AUC: 0.7565 - val_AUPR: 0.7899\n",
            "Epoch 325/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2689 - accuracy: 0.8826 - precision: 0.8961 - recall: 0.9127 - AUC: 0.9257 - AUPR: 0.9061 - val_loss: 0.4492 - val_accuracy: 0.8173 - val_precision: 0.8574 - val_recall: 0.8565 - val_AUC: 0.7581 - val_AUPR: 0.7908\n",
            "Epoch 326/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2642 - accuracy: 0.8864 - precision: 0.8987 - recall: 0.9165 - AUC: 0.9289 - AUPR: 0.9093 - val_loss: 0.4505 - val_accuracy: 0.8171 - val_precision: 0.8560 - val_recall: 0.8580 - val_AUC: 0.7557 - val_AUPR: 0.7856\n",
            "Epoch 327/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2704 - accuracy: 0.8810 - precision: 0.8963 - recall: 0.9095 - AUC: 0.9255 - AUPR: 0.9082 - val_loss: 0.4470 - val_accuracy: 0.8179 - val_precision: 0.8562 - val_recall: 0.8593 - val_AUC: 0.7577 - val_AUPR: 0.7804\n",
            "Epoch 328/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2647 - accuracy: 0.8851 - precision: 0.8986 - recall: 0.9142 - AUC: 0.9288 - AUPR: 0.9137 - val_loss: 0.4488 - val_accuracy: 0.8168 - val_precision: 0.8551 - val_recall: 0.8588 - val_AUC: 0.7588 - val_AUPR: 0.7818\n",
            "Epoch 329/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2682 - accuracy: 0.8846 - precision: 0.8961 - recall: 0.9164 - AUC: 0.9257 - AUPR: 0.9040 - val_loss: 0.4503 - val_accuracy: 0.8145 - val_precision: 0.8543 - val_recall: 0.8554 - val_AUC: 0.7571 - val_AUPR: 0.7817\n",
            "Epoch 330/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2667 - accuracy: 0.8854 - precision: 0.8988 - recall: 0.9146 - AUC: 0.9281 - AUPR: 0.9071 - val_loss: 0.4525 - val_accuracy: 0.8132 - val_precision: 0.8540 - val_recall: 0.8534 - val_AUC: 0.7555 - val_AUPR: 0.7801\n",
            "Epoch 331/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2686 - accuracy: 0.8829 - precision: 0.8962 - recall: 0.9133 - AUC: 0.9265 - AUPR: 0.9073 - val_loss: 0.4520 - val_accuracy: 0.8137 - val_precision: 0.8540 - val_recall: 0.8544 - val_AUC: 0.7551 - val_AUPR: 0.7793\n",
            "Epoch 332/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2685 - accuracy: 0.8845 - precision: 0.8980 - recall: 0.9139 - AUC: 0.9265 - AUPR: 0.9078 - val_loss: 0.4501 - val_accuracy: 0.8183 - val_precision: 0.8552 - val_recall: 0.8614 - val_AUC: 0.7562 - val_AUPR: 0.7797\n",
            "Epoch 333/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2684 - accuracy: 0.8837 - precision: 0.8971 - recall: 0.9136 - AUC: 0.9261 - AUPR: 0.9057 - val_loss: 0.4502 - val_accuracy: 0.8165 - val_precision: 0.8546 - val_recall: 0.8588 - val_AUC: 0.7565 - val_AUPR: 0.7795\n",
            "Epoch 334/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2696 - accuracy: 0.8842 - precision: 0.8953 - recall: 0.9167 - AUC: 0.9266 - AUPR: 0.9096 - val_loss: 0.4515 - val_accuracy: 0.8150 - val_precision: 0.8565 - val_recall: 0.8534 - val_AUC: 0.7573 - val_AUPR: 0.7805\n",
            "Epoch 335/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2656 - accuracy: 0.8849 - precision: 0.8996 - recall: 0.9125 - AUC: 0.9278 - AUPR: 0.9052 - val_loss: 0.4496 - val_accuracy: 0.8163 - val_precision: 0.8529 - val_recall: 0.8609 - val_AUC: 0.7572 - val_AUPR: 0.7861\n",
            "Epoch 336/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2670 - accuracy: 0.8846 - precision: 0.8958 - recall: 0.9168 - AUC: 0.9269 - AUPR: 0.9112 - val_loss: 0.4493 - val_accuracy: 0.8163 - val_precision: 0.8546 - val_recall: 0.8585 - val_AUC: 0.7567 - val_AUPR: 0.7801\n",
            "Epoch 337/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2651 - accuracy: 0.8860 - precision: 0.8997 - recall: 0.9145 - AUC: 0.9295 - AUPR: 0.9099 - val_loss: 0.4485 - val_accuracy: 0.8137 - val_precision: 0.8549 - val_recall: 0.8531 - val_AUC: 0.7578 - val_AUPR: 0.7822\n",
            "Epoch 338/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.8874 - precision: 0.9000 - recall: 0.9166 - AUC: 0.9311 - AUPR: 0.9130 - val_loss: 0.4483 - val_accuracy: 0.8174 - val_precision: 0.8548 - val_recall: 0.8603 - val_AUC: 0.7576 - val_AUPR: 0.7810\n",
            "Epoch 339/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2627 - accuracy: 0.8871 - precision: 0.8994 - recall: 0.9170 - AUC: 0.9299 - AUPR: 0.9134 - val_loss: 0.4515 - val_accuracy: 0.8171 - val_precision: 0.8611 - val_recall: 0.8511 - val_AUC: 0.7568 - val_AUPR: 0.7816\n",
            "Epoch 340/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2680 - accuracy: 0.8827 - precision: 0.8953 - recall: 0.9139 - AUC: 0.9263 - AUPR: 0.9102 - val_loss: 0.4505 - val_accuracy: 0.8181 - val_precision: 0.8548 - val_recall: 0.8616 - val_AUC: 0.7570 - val_AUPR: 0.7814\n",
            "Epoch 341/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2632 - accuracy: 0.8864 - precision: 0.8989 - recall: 0.9162 - AUC: 0.9288 - AUPR: 0.9059 - val_loss: 0.4521 - val_accuracy: 0.8174 - val_precision: 0.8568 - val_recall: 0.8575 - val_AUC: 0.7564 - val_AUPR: 0.7816\n",
            "Epoch 342/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2640 - accuracy: 0.8868 - precision: 0.8998 - recall: 0.9158 - AUC: 0.9300 - AUPR: 0.9093 - val_loss: 0.4504 - val_accuracy: 0.8198 - val_precision: 0.8581 - val_recall: 0.8601 - val_AUC: 0.7592 - val_AUPR: 0.7891\n",
            "Epoch 343/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.8877 - precision: 0.9017 - recall: 0.9151 - AUC: 0.9307 - AUPR: 0.9104 - val_loss: 0.4500 - val_accuracy: 0.8188 - val_precision: 0.8590 - val_recall: 0.8570 - val_AUC: 0.7589 - val_AUPR: 0.7893\n",
            "Epoch 344/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2682 - accuracy: 0.8824 - precision: 0.8948 - recall: 0.9140 - AUC: 0.9272 - AUPR: 0.8998 - val_loss: 0.4508 - val_accuracy: 0.8178 - val_precision: 0.8569 - val_recall: 0.8580 - val_AUC: 0.7585 - val_AUPR: 0.7826\n",
            "Epoch 345/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2636 - accuracy: 0.8852 - precision: 0.9002 - recall: 0.9123 - AUC: 0.9288 - AUPR: 0.9103 - val_loss: 0.4491 - val_accuracy: 0.8168 - val_precision: 0.8551 - val_recall: 0.8588 - val_AUC: 0.7585 - val_AUPR: 0.7825\n",
            "Epoch 346/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2655 - accuracy: 0.8843 - precision: 0.8970 - recall: 0.9147 - AUC: 0.9276 - AUPR: 0.9065 - val_loss: 0.4467 - val_accuracy: 0.8179 - val_precision: 0.8537 - val_recall: 0.8629 - val_AUC: 0.7590 - val_AUPR: 0.7835\n",
            "Epoch 347/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2647 - accuracy: 0.8847 - precision: 0.8986 - recall: 0.9135 - AUC: 0.9290 - AUPR: 0.9085 - val_loss: 0.4512 - val_accuracy: 0.8147 - val_precision: 0.8557 - val_recall: 0.8539 - val_AUC: 0.7580 - val_AUPR: 0.7890\n",
            "Epoch 348/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2614 - accuracy: 0.8859 - precision: 0.8977 - recall: 0.9169 - AUC: 0.9308 - AUPR: 0.9112 - val_loss: 0.4495 - val_accuracy: 0.8156 - val_precision: 0.8517 - val_recall: 0.8614 - val_AUC: 0.7576 - val_AUPR: 0.7877\n",
            "Epoch 349/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2681 - accuracy: 0.8830 - precision: 0.8934 - recall: 0.9171 - AUC: 0.9266 - AUPR: 0.9056 - val_loss: 0.4520 - val_accuracy: 0.8170 - val_precision: 0.8567 - val_recall: 0.8567 - val_AUC: 0.7573 - val_AUPR: 0.7923\n",
            "Epoch 350/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2625 - accuracy: 0.8846 - precision: 0.8999 - recall: 0.9117 - AUC: 0.9293 - AUPR: 0.9075 - val_loss: 0.4518 - val_accuracy: 0.8171 - val_precision: 0.8564 - val_recall: 0.8575 - val_AUC: 0.7577 - val_AUPR: 0.7878\n",
            "Epoch 351/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.8852 - precision: 0.8968 - recall: 0.9166 - AUC: 0.9295 - AUPR: 0.9077 - val_loss: 0.4508 - val_accuracy: 0.8158 - val_precision: 0.8561 - val_recall: 0.8554 - val_AUC: 0.7586 - val_AUPR: 0.7893\n",
            "Epoch 352/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2632 - accuracy: 0.8865 - precision: 0.8982 - recall: 0.9173 - AUC: 0.9292 - AUPR: 0.9050 - val_loss: 0.4532 - val_accuracy: 0.8138 - val_precision: 0.8533 - val_recall: 0.8557 - val_AUC: 0.7567 - val_AUPR: 0.7822\n",
            "Epoch 353/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2589 - accuracy: 0.8872 - precision: 0.9011 - recall: 0.9150 - AUC: 0.9320 - AUPR: 0.9108 - val_loss: 0.4538 - val_accuracy: 0.8140 - val_precision: 0.8561 - val_recall: 0.8521 - val_AUC: 0.7570 - val_AUPR: 0.7833\n",
            "Epoch 354/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2630 - accuracy: 0.8866 - precision: 0.8988 - recall: 0.9168 - AUC: 0.9294 - AUPR: 0.9143 - val_loss: 0.4521 - val_accuracy: 0.8151 - val_precision: 0.8534 - val_recall: 0.8580 - val_AUC: 0.7565 - val_AUPR: 0.7816\n",
            "Epoch 355/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2664 - accuracy: 0.8835 - precision: 0.8954 - recall: 0.9154 - AUC: 0.9275 - AUPR: 0.9121 - val_loss: 0.4527 - val_accuracy: 0.8142 - val_precision: 0.8546 - val_recall: 0.8544 - val_AUC: 0.7565 - val_AUPR: 0.7887\n",
            "Epoch 356/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2657 - accuracy: 0.8847 - precision: 0.9008 - recall: 0.9107 - AUC: 0.9278 - AUPR: 0.9150 - val_loss: 0.4511 - val_accuracy: 0.8160 - val_precision: 0.8531 - val_recall: 0.8601 - val_AUC: 0.7570 - val_AUPR: 0.7921\n",
            "Epoch 357/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2597 - accuracy: 0.8856 - precision: 0.8981 - recall: 0.9156 - AUC: 0.9308 - AUPR: 0.9094 - val_loss: 0.4540 - val_accuracy: 0.8161 - val_precision: 0.8571 - val_recall: 0.8547 - val_AUC: 0.7561 - val_AUPR: 0.7880\n",
            "Epoch 358/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2628 - accuracy: 0.8844 - precision: 0.8999 - recall: 0.9114 - AUC: 0.9292 - AUPR: 0.9106 - val_loss: 0.4529 - val_accuracy: 0.8138 - val_precision: 0.8524 - val_recall: 0.8570 - val_AUC: 0.7565 - val_AUPR: 0.7818\n",
            "Epoch 359/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2617 - accuracy: 0.8870 - precision: 0.9003 - recall: 0.9156 - AUC: 0.9303 - AUPR: 0.9122 - val_loss: 0.4535 - val_accuracy: 0.8133 - val_precision: 0.8512 - val_recall: 0.8578 - val_AUC: 0.7564 - val_AUPR: 0.7909\n",
            "Epoch 360/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2635 - accuracy: 0.8852 - precision: 0.8977 - recall: 0.9156 - AUC: 0.9296 - AUPR: 0.9130 - val_loss: 0.4533 - val_accuracy: 0.8160 - val_precision: 0.8549 - val_recall: 0.8575 - val_AUC: 0.7566 - val_AUPR: 0.7921\n",
            "Epoch 361/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2608 - accuracy: 0.8881 - precision: 0.9011 - recall: 0.9165 - AUC: 0.9317 - AUPR: 0.9122 - val_loss: 0.4539 - val_accuracy: 0.8142 - val_precision: 0.8541 - val_recall: 0.8552 - val_AUC: 0.7554 - val_AUPR: 0.7814\n",
            "Epoch 362/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2619 - accuracy: 0.8875 - precision: 0.9047 - recall: 0.9110 - AUC: 0.9307 - AUPR: 0.9115 - val_loss: 0.4550 - val_accuracy: 0.8145 - val_precision: 0.8538 - val_recall: 0.8562 - val_AUC: 0.7559 - val_AUPR: 0.7826\n",
            "Epoch 363/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2611 - accuracy: 0.8868 - precision: 0.8963 - recall: 0.9203 - AUC: 0.9313 - AUPR: 0.9094 - val_loss: 0.4548 - val_accuracy: 0.8143 - val_precision: 0.8503 - val_recall: 0.8609 - val_AUC: 0.7562 - val_AUPR: 0.7820\n",
            "Epoch 364/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2617 - accuracy: 0.8861 - precision: 0.9006 - recall: 0.9134 - AUC: 0.9300 - AUPR: 0.9099 - val_loss: 0.4549 - val_accuracy: 0.8147 - val_precision: 0.8559 - val_recall: 0.8536 - val_AUC: 0.7573 - val_AUPR: 0.7820\n",
            "Epoch 365/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2650 - accuracy: 0.8838 - precision: 0.8956 - recall: 0.9156 - AUC: 0.9284 - AUPR: 0.9096 - val_loss: 0.4532 - val_accuracy: 0.8163 - val_precision: 0.8513 - val_recall: 0.8632 - val_AUC: 0.7582 - val_AUPR: 0.7820\n",
            "Epoch 366/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2621 - accuracy: 0.8861 - precision: 0.9008 - recall: 0.9132 - AUC: 0.9299 - AUPR: 0.9095 - val_loss: 0.4554 - val_accuracy: 0.8150 - val_precision: 0.8578 - val_recall: 0.8516 - val_AUC: 0.7564 - val_AUPR: 0.7818\n",
            "Epoch 367/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2634 - accuracy: 0.8871 - precision: 0.9003 - recall: 0.9157 - AUC: 0.9293 - AUPR: 0.9104 - val_loss: 0.4540 - val_accuracy: 0.8166 - val_precision: 0.8518 - val_recall: 0.8632 - val_AUC: 0.7553 - val_AUPR: 0.7812\n",
            "Epoch 368/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2604 - accuracy: 0.8873 - precision: 0.9006 - recall: 0.9156 - AUC: 0.9312 - AUPR: 0.9119 - val_loss: 0.4553 - val_accuracy: 0.8153 - val_precision: 0.8549 - val_recall: 0.8562 - val_AUC: 0.7567 - val_AUPR: 0.7820\n",
            "Epoch 369/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.8863 - precision: 0.8991 - recall: 0.9157 - AUC: 0.9299 - AUPR: 0.9001 - val_loss: 0.4526 - val_accuracy: 0.8156 - val_precision: 0.8552 - val_recall: 0.8565 - val_AUC: 0.7593 - val_AUPR: 0.7831\n",
            "Epoch 370/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2620 - accuracy: 0.8893 - precision: 0.9027 - recall: 0.9167 - AUC: 0.9301 - AUPR: 0.9058 - val_loss: 0.4524 - val_accuracy: 0.8143 - val_precision: 0.8538 - val_recall: 0.8560 - val_AUC: 0.7578 - val_AUPR: 0.7811\n",
            "Epoch 371/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2618 - accuracy: 0.8862 - precision: 0.8975 - recall: 0.9176 - AUC: 0.9298 - AUPR: 0.9072 - val_loss: 0.4539 - val_accuracy: 0.8156 - val_precision: 0.8552 - val_recall: 0.8565 - val_AUC: 0.7582 - val_AUPR: 0.7814\n",
            "Epoch 372/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2626 - accuracy: 0.8873 - precision: 0.9036 - recall: 0.9118 - AUC: 0.9302 - AUPR: 0.9152 - val_loss: 0.4540 - val_accuracy: 0.8156 - val_precision: 0.8570 - val_recall: 0.8539 - val_AUC: 0.7584 - val_AUPR: 0.7817\n",
            "Epoch 373/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2629 - accuracy: 0.8852 - precision: 0.8965 - recall: 0.9171 - AUC: 0.9299 - AUPR: 0.9096 - val_loss: 0.4556 - val_accuracy: 0.8155 - val_precision: 0.8499 - val_recall: 0.8637 - val_AUC: 0.7560 - val_AUPR: 0.7800\n",
            "Epoch 374/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2617 - accuracy: 0.8866 - precision: 0.9013 - recall: 0.9134 - AUC: 0.9298 - AUPR: 0.9140 - val_loss: 0.4569 - val_accuracy: 0.8151 - val_precision: 0.8534 - val_recall: 0.8580 - val_AUC: 0.7547 - val_AUPR: 0.7789\n",
            "Epoch 375/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2626 - accuracy: 0.8857 - precision: 0.8962 - recall: 0.9184 - AUC: 0.9312 - AUPR: 0.9129 - val_loss: 0.4573 - val_accuracy: 0.8143 - val_precision: 0.8565 - val_recall: 0.8521 - val_AUC: 0.7557 - val_AUPR: 0.7796\n",
            "Epoch 376/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2660 - accuracy: 0.8841 - precision: 0.8997 - recall: 0.9109 - AUC: 0.9283 - AUPR: 0.9105 - val_loss: 0.4551 - val_accuracy: 0.8155 - val_precision: 0.8549 - val_recall: 0.8565 - val_AUC: 0.7554 - val_AUPR: 0.7797\n",
            "Epoch 377/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2566 - accuracy: 0.8877 - precision: 0.9010 - recall: 0.9160 - AUC: 0.9323 - AUPR: 0.9146 - val_loss: 0.4562 - val_accuracy: 0.8148 - val_precision: 0.8542 - val_recall: 0.8562 - val_AUC: 0.7564 - val_AUPR: 0.7802\n",
            "Epoch 378/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2608 - accuracy: 0.8881 - precision: 0.9032 - recall: 0.9140 - AUC: 0.9319 - AUPR: 0.9130 - val_loss: 0.4565 - val_accuracy: 0.8163 - val_precision: 0.8526 - val_recall: 0.8614 - val_AUC: 0.7554 - val_AUPR: 0.7796\n",
            "Epoch 379/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.8846 - precision: 0.8948 - recall: 0.9182 - AUC: 0.9293 - AUPR: 0.9121 - val_loss: 0.4559 - val_accuracy: 0.8170 - val_precision: 0.8536 - val_recall: 0.8611 - val_AUC: 0.7560 - val_AUPR: 0.7806\n",
            "Epoch 380/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2641 - accuracy: 0.8871 - precision: 0.9035 - recall: 0.9118 - AUC: 0.9292 - AUPR: 0.9090 - val_loss: 0.4545 - val_accuracy: 0.8173 - val_precision: 0.8535 - val_recall: 0.8619 - val_AUC: 0.7571 - val_AUPR: 0.7809\n",
            "Epoch 381/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2605 - accuracy: 0.8880 - precision: 0.8997 - recall: 0.9182 - AUC: 0.9311 - AUPR: 0.9164 - val_loss: 0.4553 - val_accuracy: 0.8166 - val_precision: 0.8541 - val_recall: 0.8598 - val_AUC: 0.7570 - val_AUPR: 0.7806\n",
            "Epoch 382/400\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2606 - accuracy: 0.8888 - precision: 0.9021 - recall: 0.9165 - AUC: 0.9306 - AUPR: 0.9153 - val_loss: 0.4546 - val_accuracy: 0.8170 - val_precision: 0.8542 - val_recall: 0.8603 - val_AUC: 0.7562 - val_AUPR: 0.7788\n",
            "Epoch 383/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2568 - accuracy: 0.8904 - precision: 0.9024 - recall: 0.9191 - AUC: 0.9335 - AUPR: 0.9141 - val_loss: 0.4586 - val_accuracy: 0.8130 - val_precision: 0.8535 - val_recall: 0.8539 - val_AUC: 0.7532 - val_AUPR: 0.7772\n",
            "Epoch 384/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2551 - accuracy: 0.8910 - precision: 0.9071 - recall: 0.9144 - AUC: 0.9342 - AUPR: 0.9122 - val_loss: 0.4569 - val_accuracy: 0.8165 - val_precision: 0.8524 - val_recall: 0.8619 - val_AUC: 0.7560 - val_AUPR: 0.7792\n",
            "Epoch 385/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2600 - accuracy: 0.8877 - precision: 0.8975 - recall: 0.9205 - AUC: 0.9304 - AUPR: 0.9108 - val_loss: 0.4611 - val_accuracy: 0.8133 - val_precision: 0.8521 - val_recall: 0.8565 - val_AUC: 0.7531 - val_AUPR: 0.7778\n",
            "Epoch 386/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2593 - accuracy: 0.8867 - precision: 0.9013 - recall: 0.9138 - AUC: 0.9326 - AUPR: 0.9143 - val_loss: 0.4590 - val_accuracy: 0.8148 - val_precision: 0.8541 - val_recall: 0.8565 - val_AUC: 0.7531 - val_AUPR: 0.7785\n",
            "Epoch 387/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2586 - accuracy: 0.8881 - precision: 0.9010 - recall: 0.9167 - AUC: 0.9320 - AUPR: 0.9090 - val_loss: 0.4579 - val_accuracy: 0.8151 - val_precision: 0.8550 - val_recall: 0.8557 - val_AUC: 0.7558 - val_AUPR: 0.7802\n",
            "Epoch 388/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2573 - accuracy: 0.8876 - precision: 0.9003 - recall: 0.9167 - AUC: 0.9337 - AUPR: 0.9117 - val_loss: 0.4596 - val_accuracy: 0.8160 - val_precision: 0.8547 - val_recall: 0.8578 - val_AUC: 0.7533 - val_AUPR: 0.7889\n",
            "Epoch 389/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2606 - accuracy: 0.8866 - precision: 0.9024 - recall: 0.9121 - AUC: 0.9308 - AUPR: 0.9133 - val_loss: 0.4573 - val_accuracy: 0.8179 - val_precision: 0.8539 - val_recall: 0.8627 - val_AUC: 0.7549 - val_AUPR: 0.7893\n",
            "Epoch 390/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2577 - accuracy: 0.8877 - precision: 0.8990 - recall: 0.9184 - AUC: 0.9320 - AUPR: 0.9127 - val_loss: 0.4602 - val_accuracy: 0.8140 - val_precision: 0.8566 - val_recall: 0.8513 - val_AUC: 0.7532 - val_AUPR: 0.7895\n",
            "Epoch 391/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2594 - accuracy: 0.8896 - precision: 0.9035 - recall: 0.9163 - AUC: 0.9315 - AUPR: 0.9153 - val_loss: 0.4563 - val_accuracy: 0.8137 - val_precision: 0.8516 - val_recall: 0.8578 - val_AUC: 0.7546 - val_AUPR: 0.7798\n",
            "Epoch 392/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2614 - accuracy: 0.8859 - precision: 0.9002 - recall: 0.9136 - AUC: 0.9301 - AUPR: 0.9141 - val_loss: 0.4564 - val_accuracy: 0.8143 - val_precision: 0.8558 - val_recall: 0.8531 - val_AUC: 0.7561 - val_AUPR: 0.7804\n",
            "Epoch 393/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2595 - accuracy: 0.8887 - precision: 0.8998 - recall: 0.9193 - AUC: 0.9314 - AUPR: 0.9091 - val_loss: 0.4566 - val_accuracy: 0.8163 - val_precision: 0.8548 - val_recall: 0.8583 - val_AUC: 0.7555 - val_AUPR: 0.7788\n",
            "Epoch 394/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2582 - accuracy: 0.8875 - precision: 0.9003 - recall: 0.9165 - AUC: 0.9324 - AUPR: 0.9105 - val_loss: 0.4579 - val_accuracy: 0.8143 - val_precision: 0.8563 - val_recall: 0.8524 - val_AUC: 0.7553 - val_AUPR: 0.7797\n",
            "Epoch 395/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2608 - accuracy: 0.8871 - precision: 0.8990 - recall: 0.9175 - AUC: 0.9315 - AUPR: 0.9155 - val_loss: 0.4547 - val_accuracy: 0.8155 - val_precision: 0.8542 - val_recall: 0.8575 - val_AUC: 0.7571 - val_AUPR: 0.7806\n",
            "Epoch 396/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2604 - accuracy: 0.8870 - precision: 0.9030 - recall: 0.9123 - AUC: 0.9308 - AUPR: 0.9092 - val_loss: 0.4564 - val_accuracy: 0.8137 - val_precision: 0.8543 - val_recall: 0.8539 - val_AUC: 0.7581 - val_AUPR: 0.7815\n",
            "Epoch 397/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2582 - accuracy: 0.8873 - precision: 0.9012 - recall: 0.9150 - AUC: 0.9322 - AUPR: 0.9149 - val_loss: 0.4583 - val_accuracy: 0.8166 - val_precision: 0.8548 - val_recall: 0.8588 - val_AUC: 0.7557 - val_AUPR: 0.7806\n",
            "Epoch 398/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2578 - accuracy: 0.8886 - precision: 0.9008 - recall: 0.9179 - AUC: 0.9323 - AUPR: 0.9104 - val_loss: 0.4594 - val_accuracy: 0.8150 - val_precision: 0.8525 - val_recall: 0.8591 - val_AUC: 0.7535 - val_AUPR: 0.7795\n",
            "Epoch 399/400\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2594 - accuracy: 0.8878 - precision: 0.9018 - recall: 0.9151 - AUC: 0.9312 - AUPR: 0.9119 - val_loss: 0.4591 - val_accuracy: 0.8140 - val_precision: 0.8552 - val_recall: 0.8534 - val_AUC: 0.7552 - val_AUPR: 0.7810\n",
            "Epoch 400/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 0.8900 - precision: 0.9009 - recall: 0.9203 - AUC: 0.9343 - AUPR: 0.9143 - val_loss: 0.4557 - val_accuracy: 0.8160 - val_precision: 0.8532 - val_recall: 0.8598 - val_AUC: 0.7568 - val_AUPR: 0.7816\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8160 - precision: 0.8532 - recall: 0.8598 - AUC: 0.7568 - AUPR: 0.7817\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.7567673325538635,\n",
              " 'AUPR': 0.7816628813743591,\n",
              " 'accuracy': 0.8159670829772949,\n",
              " 'loss': 0.45568355917930603,\n",
              " 'precision': 0.8532344698905945,\n",
              " 'recall': 0.8598299622535706}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuvRgpMeStl7"
      },
      "source": [
        "y_pre4 = model4.predict(x3_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn6tmq0-T8n_"
      },
      "source": [
        "gin_context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bNf8E6tT-eU",
        "outputId": "cda1e234-5aa9-4998-df3b-424c677879a0"
      },
      "source": [
        "X4 = np.load('./data/gin_supervised_contextpred.npy')\n",
        "x4_train,x4_test,y_train,y_test= train_test_split(X4,y,test_size=0.1,random_state=2021)\n",
        "model5 = load_model('./model/model_context21.h5')\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model3.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)\n",
        "\n",
        "history  = model5.fit(x4_train,y_train,batch_size=128, epochs=400)\n",
        "model5.evaluate(x4_test,y_test,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "16/16 [==============================] - 2s 10ms/step - loss: 0.3990 - accuracy: 0.8201 - precision: 0.8255 - recall: 0.8927 - AUC: 0.7986 - AUPR: 0.7959\n",
            "Epoch 2/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4010 - accuracy: 0.8161 - precision: 0.8219 - recall: 0.8906 - AUC: 0.7990 - AUPR: 0.7951\n",
            "Epoch 3/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3994 - accuracy: 0.8171 - precision: 0.8222 - recall: 0.8921 - AUC: 0.8019 - AUPR: 0.7961\n",
            "Epoch 4/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8213 - precision: 0.8272 - recall: 0.8925 - AUC: 0.8076 - AUPR: 0.8007\n",
            "Epoch 5/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3931 - accuracy: 0.8224 - precision: 0.8279 - recall: 0.8936 - AUC: 0.8092 - AUPR: 0.8002\n",
            "Epoch 6/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3959 - accuracy: 0.8200 - precision: 0.8260 - recall: 0.8918 - AUC: 0.8055 - AUPR: 0.7974\n",
            "Epoch 7/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8201 - precision: 0.8284 - recall: 0.8882 - AUC: 0.8075 - AUPR: 0.8047\n",
            "Epoch 8/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3988 - accuracy: 0.8196 - precision: 0.8277 - recall: 0.8881 - AUC: 0.8007 - AUPR: 0.7959\n",
            "Epoch 9/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3955 - accuracy: 0.8203 - precision: 0.8296 - recall: 0.8865 - AUC: 0.8069 - AUPR: 0.7990\n",
            "Epoch 10/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3969 - accuracy: 0.8189 - precision: 0.8250 - recall: 0.8913 - AUC: 0.8065 - AUPR: 0.7994\n",
            "Epoch 11/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.8206 - precision: 0.8289 - recall: 0.8883 - AUC: 0.8026 - AUPR: 0.7997\n",
            "Epoch 12/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8209 - precision: 0.8294 - recall: 0.8880 - AUC: 0.8057 - AUPR: 0.8012\n",
            "Epoch 13/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.8200 - precision: 0.8290 - recall: 0.8868 - AUC: 0.8034 - AUPR: 0.7978\n",
            "Epoch 14/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.8177 - precision: 0.8272 - recall: 0.8850 - AUC: 0.8042 - AUPR: 0.7972\n",
            "Epoch 15/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3984 - accuracy: 0.8181 - precision: 0.8273 - recall: 0.8858 - AUC: 0.8033 - AUPR: 0.8015\n",
            "Epoch 16/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3977 - accuracy: 0.8171 - precision: 0.8280 - recall: 0.8825 - AUC: 0.8030 - AUPR: 0.7976\n",
            "Epoch 17/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4007 - accuracy: 0.8167 - precision: 0.8272 - recall: 0.8830 - AUC: 0.7971 - AUPR: 0.7951\n",
            "Epoch 18/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3981 - accuracy: 0.8193 - precision: 0.8285 - recall: 0.8862 - AUC: 0.8037 - AUPR: 0.7989\n",
            "Epoch 19/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3961 - accuracy: 0.8197 - precision: 0.8287 - recall: 0.8868 - AUC: 0.8041 - AUPR: 0.7976\n",
            "Epoch 20/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3974 - accuracy: 0.8200 - precision: 0.8290 - recall: 0.8869 - AUC: 0.8043 - AUPR: 0.7968\n",
            "Epoch 21/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.8199 - precision: 0.8295 - recall: 0.8859 - AUC: 0.8066 - AUPR: 0.7994\n",
            "Epoch 22/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3939 - accuracy: 0.8213 - precision: 0.8296 - recall: 0.8886 - AUC: 0.8093 - AUPR: 0.8034\n",
            "Epoch 23/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3964 - accuracy: 0.8196 - precision: 0.8281 - recall: 0.8874 - AUC: 0.8056 - AUPR: 0.8039\n",
            "Epoch 24/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3989 - accuracy: 0.8183 - precision: 0.8255 - recall: 0.8891 - AUC: 0.8021 - AUPR: 0.7972\n",
            "Epoch 25/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8203 - precision: 0.8302 - recall: 0.8857 - AUC: 0.8070 - AUPR: 0.8012\n",
            "Epoch 26/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8198 - precision: 0.8286 - recall: 0.8871 - AUC: 0.8089 - AUPR: 0.8016\n",
            "Epoch 27/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.8217 - precision: 0.8306 - recall: 0.8877 - AUC: 0.8100 - AUPR: 0.8012\n",
            "Epoch 28/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3974 - accuracy: 0.8194 - precision: 0.8288 - recall: 0.8860 - AUC: 0.8041 - AUPR: 0.7984\n",
            "Epoch 29/400\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8212 - precision: 0.8318 - recall: 0.8848 - AUC: 0.8052 - AUPR: 0.8000\n",
            "Epoch 30/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3945 - accuracy: 0.8197 - precision: 0.8300 - recall: 0.8848 - AUC: 0.8076 - AUPR: 0.8009\n",
            "Epoch 31/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.8207 - precision: 0.8305 - recall: 0.8858 - AUC: 0.8046 - AUPR: 0.7956\n",
            "Epoch 32/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.8195 - precision: 0.8287 - recall: 0.8862 - AUC: 0.8076 - AUPR: 0.8014\n",
            "Epoch 33/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3979 - accuracy: 0.8195 - precision: 0.8281 - recall: 0.8874 - AUC: 0.8011 - AUPR: 0.7953\n",
            "Epoch 34/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8195 - precision: 0.8290 - recall: 0.8859 - AUC: 0.8076 - AUPR: 0.7990\n",
            "Epoch 35/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.8193 - precision: 0.8296 - recall: 0.8845 - AUC: 0.8058 - AUPR: 0.7980\n",
            "Epoch 36/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.8225 - precision: 0.8327 - recall: 0.8861 - AUC: 0.8075 - AUPR: 0.8004\n",
            "Epoch 37/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3975 - accuracy: 0.8199 - precision: 0.8305 - recall: 0.8842 - AUC: 0.8033 - AUPR: 0.7975\n",
            "Epoch 38/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3973 - accuracy: 0.8182 - precision: 0.8296 - recall: 0.8821 - AUC: 0.8034 - AUPR: 0.7973\n",
            "Epoch 39/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3939 - accuracy: 0.8209 - precision: 0.8303 - recall: 0.8865 - AUC: 0.8090 - AUPR: 0.8000\n",
            "Epoch 40/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.8237 - precision: 0.8338 - recall: 0.8868 - AUC: 0.8081 - AUPR: 0.8016\n",
            "Epoch 41/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8199 - precision: 0.8305 - recall: 0.8843 - AUC: 0.8050 - AUPR: 0.7985\n",
            "Epoch 42/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8199 - precision: 0.8289 - recall: 0.8868 - AUC: 0.8089 - AUPR: 0.7999\n",
            "Epoch 43/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.8214 - precision: 0.8316 - recall: 0.8856 - AUC: 0.8075 - AUPR: 0.7999\n",
            "Epoch 44/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3967 - accuracy: 0.8195 - precision: 0.8300 - recall: 0.8843 - AUC: 0.8042 - AUPR: 0.7990\n",
            "Epoch 45/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3934 - accuracy: 0.8208 - precision: 0.8300 - recall: 0.8870 - AUC: 0.8100 - AUPR: 0.8025\n",
            "Epoch 46/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8203 - precision: 0.8316 - recall: 0.8834 - AUC: 0.8072 - AUPR: 0.7995\n",
            "Epoch 47/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8186 - precision: 0.8301 - recall: 0.8822 - AUC: 0.8065 - AUPR: 0.8000\n",
            "Epoch 48/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8212 - precision: 0.8309 - recall: 0.8862 - AUC: 0.8061 - AUPR: 0.8017\n",
            "Epoch 49/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3938 - accuracy: 0.8213 - precision: 0.8326 - recall: 0.8839 - AUC: 0.8092 - AUPR: 0.8001\n",
            "Epoch 50/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3925 - accuracy: 0.8223 - precision: 0.8320 - recall: 0.8868 - AUC: 0.8114 - AUPR: 0.8023\n",
            "Epoch 51/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3966 - accuracy: 0.8198 - precision: 0.8304 - recall: 0.8843 - AUC: 0.8034 - AUPR: 0.7977\n",
            "Epoch 52/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3949 - accuracy: 0.8208 - precision: 0.8290 - recall: 0.8886 - AUC: 0.8060 - AUPR: 0.7993\n",
            "Epoch 53/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8213 - precision: 0.8313 - recall: 0.8859 - AUC: 0.8070 - AUPR: 0.8026\n",
            "Epoch 54/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.8198 - precision: 0.8304 - recall: 0.8843 - AUC: 0.8038 - AUPR: 0.7992\n",
            "Epoch 55/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 0.8194 - precision: 0.8294 - recall: 0.8849 - AUC: 0.8072 - AUPR: 0.7996\n",
            "Epoch 56/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8190 - precision: 0.8303 - recall: 0.8826 - AUC: 0.8062 - AUPR: 0.8034\n",
            "Epoch 57/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8205 - precision: 0.8322 - recall: 0.8829 - AUC: 0.8051 - AUPR: 0.8012\n",
            "Epoch 58/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3942 - accuracy: 0.8203 - precision: 0.8301 - recall: 0.8858 - AUC: 0.8063 - AUPR: 0.8019\n",
            "Epoch 59/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8203 - precision: 0.8317 - recall: 0.8831 - AUC: 0.8093 - AUPR: 0.8021\n",
            "Epoch 60/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3921 - accuracy: 0.8215 - precision: 0.8335 - recall: 0.8828 - AUC: 0.8093 - AUPR: 0.8046\n",
            "Epoch 61/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8211 - precision: 0.8314 - recall: 0.8854 - AUC: 0.8067 - AUPR: 0.7983\n",
            "Epoch 62/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.8215 - precision: 0.8323 - recall: 0.8847 - AUC: 0.8086 - AUPR: 0.7981\n",
            "Epoch 63/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8202 - precision: 0.8301 - recall: 0.8854 - AUC: 0.8054 - AUPR: 0.7978\n",
            "Epoch 64/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8219 - precision: 0.8329 - recall: 0.8846 - AUC: 0.8055 - AUPR: 0.8043\n",
            "Epoch 65/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.8208 - precision: 0.8299 - recall: 0.8871 - AUC: 0.8060 - AUPR: 0.8028\n",
            "Epoch 66/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3957 - accuracy: 0.8205 - precision: 0.8305 - recall: 0.8854 - AUC: 0.8085 - AUPR: 0.7971\n",
            "Epoch 67/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.8197 - precision: 0.8309 - recall: 0.8832 - AUC: 0.8081 - AUPR: 0.7990\n",
            "Epoch 68/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8197 - precision: 0.8299 - recall: 0.8848 - AUC: 0.8041 - AUPR: 0.8009\n",
            "Epoch 69/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3963 - accuracy: 0.8209 - precision: 0.8316 - recall: 0.8844 - AUC: 0.8059 - AUPR: 0.7992\n",
            "Epoch 70/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.8205 - precision: 0.8302 - recall: 0.8860 - AUC: 0.8078 - AUPR: 0.8002\n",
            "Epoch 71/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3958 - accuracy: 0.8196 - precision: 0.8301 - recall: 0.8844 - AUC: 0.8063 - AUPR: 0.8001\n",
            "Epoch 72/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3925 - accuracy: 0.8199 - precision: 0.8306 - recall: 0.8842 - AUC: 0.8105 - AUPR: 0.8015\n",
            "Epoch 73/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3949 - accuracy: 0.8199 - precision: 0.8304 - recall: 0.8845 - AUC: 0.8074 - AUPR: 0.7999\n",
            "Epoch 74/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8215 - precision: 0.8321 - recall: 0.8850 - AUC: 0.8089 - AUPR: 0.8034\n",
            "Epoch 75/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3938 - accuracy: 0.8215 - precision: 0.8318 - recall: 0.8855 - AUC: 0.8076 - AUPR: 0.8036\n",
            "Epoch 76/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3949 - accuracy: 0.8201 - precision: 0.8318 - recall: 0.8826 - AUC: 0.8073 - AUPR: 0.7991\n",
            "Epoch 77/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3939 - accuracy: 0.8198 - precision: 0.8296 - recall: 0.8855 - AUC: 0.8075 - AUPR: 0.8004\n",
            "Epoch 78/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3956 - accuracy: 0.8205 - precision: 0.8296 - recall: 0.8869 - AUC: 0.8073 - AUPR: 0.7994\n",
            "Epoch 79/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8221 - precision: 0.8343 - recall: 0.8827 - AUC: 0.8073 - AUPR: 0.8007\n",
            "Epoch 80/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3933 - accuracy: 0.8220 - precision: 0.8322 - recall: 0.8859 - AUC: 0.8089 - AUPR: 0.8026\n",
            "Epoch 81/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.8233 - precision: 0.8333 - recall: 0.8869 - AUC: 0.8123 - AUPR: 0.8060\n",
            "Epoch 82/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.8199 - precision: 0.8299 - recall: 0.8854 - AUC: 0.8076 - AUPR: 0.8055\n",
            "Epoch 83/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8211 - precision: 0.8316 - recall: 0.8851 - AUC: 0.8082 - AUPR: 0.8033\n",
            "Epoch 84/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3968 - accuracy: 0.8181 - precision: 0.8289 - recall: 0.8831 - AUC: 0.8053 - AUPR: 0.7994\n",
            "Epoch 85/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8208 - precision: 0.8305 - recall: 0.8860 - AUC: 0.8083 - AUPR: 0.8048\n",
            "Epoch 86/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3933 - accuracy: 0.8228 - precision: 0.8332 - recall: 0.8860 - AUC: 0.8083 - AUPR: 0.7999\n",
            "Epoch 87/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.8236 - precision: 0.8348 - recall: 0.8849 - AUC: 0.8123 - AUPR: 0.8034\n",
            "Epoch 88/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3922 - accuracy: 0.8213 - precision: 0.8324 - recall: 0.8842 - AUC: 0.8109 - AUPR: 0.8011\n",
            "Epoch 89/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.8199 - precision: 0.8298 - recall: 0.8854 - AUC: 0.8037 - AUPR: 0.7990\n",
            "Epoch 90/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8225 - precision: 0.8330 - recall: 0.8857 - AUC: 0.8106 - AUPR: 0.8018\n",
            "Epoch 91/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8214 - precision: 0.8316 - recall: 0.8855 - AUC: 0.8066 - AUPR: 0.7984\n",
            "Epoch 92/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3945 - accuracy: 0.8194 - precision: 0.8305 - recall: 0.8832 - AUC: 0.8081 - AUPR: 0.8019\n",
            "Epoch 93/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 0.8204 - precision: 0.8313 - recall: 0.8840 - AUC: 0.8068 - AUPR: 0.7995\n",
            "Epoch 94/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8230 - precision: 0.8320 - recall: 0.8883 - AUC: 0.8078 - AUPR: 0.8010\n",
            "Epoch 95/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.8208 - precision: 0.8323 - recall: 0.8832 - AUC: 0.8113 - AUPR: 0.8009\n",
            "Epoch 96/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3940 - accuracy: 0.8207 - precision: 0.8311 - recall: 0.8849 - AUC: 0.8077 - AUPR: 0.8028\n",
            "Epoch 97/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8211 - precision: 0.8320 - recall: 0.8842 - AUC: 0.8068 - AUPR: 0.8041\n",
            "Epoch 98/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.8228 - precision: 0.8321 - recall: 0.8877 - AUC: 0.8140 - AUPR: 0.8089\n",
            "Epoch 99/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8229 - precision: 0.8332 - recall: 0.8861 - AUC: 0.8128 - AUPR: 0.8050\n",
            "Epoch 100/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.8219 - precision: 0.8313 - recall: 0.8870 - AUC: 0.8080 - AUPR: 0.8035\n",
            "Epoch 101/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.8188 - precision: 0.8297 - recall: 0.8833 - AUC: 0.8035 - AUPR: 0.7978\n",
            "Epoch 102/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.8226 - precision: 0.8328 - recall: 0.8861 - AUC: 0.8112 - AUPR: 0.8026\n",
            "Epoch 103/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8208 - precision: 0.8312 - recall: 0.8850 - AUC: 0.8051 - AUPR: 0.7982\n",
            "Epoch 104/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.8222 - precision: 0.8339 - recall: 0.8836 - AUC: 0.8092 - AUPR: 0.8022\n",
            "Epoch 105/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3949 - accuracy: 0.8204 - precision: 0.8316 - recall: 0.8834 - AUC: 0.8069 - AUPR: 0.7999\n",
            "Epoch 106/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3934 - accuracy: 0.8214 - precision: 0.8320 - recall: 0.8851 - AUC: 0.8080 - AUPR: 0.7991\n",
            "Epoch 107/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8209 - precision: 0.8301 - recall: 0.8870 - AUC: 0.8126 - AUPR: 0.8030\n",
            "Epoch 108/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3940 - accuracy: 0.8215 - precision: 0.8318 - recall: 0.8855 - AUC: 0.8086 - AUPR: 0.8023\n",
            "Epoch 109/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8214 - precision: 0.8315 - recall: 0.8857 - AUC: 0.8096 - AUPR: 0.8046\n",
            "Epoch 110/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3948 - accuracy: 0.8199 - precision: 0.8308 - recall: 0.8839 - AUC: 0.8072 - AUPR: 0.8020\n",
            "Epoch 111/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8212 - precision: 0.8308 - recall: 0.8864 - AUC: 0.8072 - AUPR: 0.7993\n",
            "Epoch 112/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3923 - accuracy: 0.8214 - precision: 0.8320 - recall: 0.8850 - AUC: 0.8110 - AUPR: 0.8011\n",
            "Epoch 113/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3949 - accuracy: 0.8203 - precision: 0.8298 - recall: 0.8861 - AUC: 0.8083 - AUPR: 0.7990\n",
            "Epoch 114/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.8195 - precision: 0.8302 - recall: 0.8839 - AUC: 0.8045 - AUPR: 0.8009\n",
            "Epoch 115/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3968 - accuracy: 0.8185 - precision: 0.8294 - recall: 0.8831 - AUC: 0.8064 - AUPR: 0.7993\n",
            "Epoch 116/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.8212 - precision: 0.8307 - recall: 0.8868 - AUC: 0.8088 - AUPR: 0.7985\n",
            "Epoch 117/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3938 - accuracy: 0.8216 - precision: 0.8327 - recall: 0.8842 - AUC: 0.8090 - AUPR: 0.7990\n",
            "Epoch 118/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3950 - accuracy: 0.8220 - precision: 0.8306 - recall: 0.8886 - AUC: 0.8064 - AUPR: 0.8003\n",
            "Epoch 119/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.8217 - precision: 0.8313 - recall: 0.8867 - AUC: 0.8109 - AUPR: 0.8037\n",
            "Epoch 120/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3953 - accuracy: 0.8211 - precision: 0.8302 - recall: 0.8871 - AUC: 0.8069 - AUPR: 0.7978\n",
            "Epoch 121/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.8212 - precision: 0.8319 - recall: 0.8846 - AUC: 0.8128 - AUPR: 0.8031\n",
            "Epoch 122/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8207 - precision: 0.8302 - recall: 0.8865 - AUC: 0.8097 - AUPR: 0.8013\n",
            "Epoch 123/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8194 - precision: 0.8308 - recall: 0.8828 - AUC: 0.8054 - AUPR: 0.8018\n",
            "Epoch 124/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3940 - accuracy: 0.8211 - precision: 0.8312 - recall: 0.8856 - AUC: 0.8090 - AUPR: 0.8007\n",
            "Epoch 125/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3930 - accuracy: 0.8215 - precision: 0.8310 - recall: 0.8868 - AUC: 0.8100 - AUPR: 0.8045\n",
            "Epoch 126/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8198 - precision: 0.8318 - recall: 0.8821 - AUC: 0.8087 - AUPR: 0.8012\n",
            "Epoch 127/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8196 - precision: 0.8298 - recall: 0.8849 - AUC: 0.8078 - AUPR: 0.8019\n",
            "Epoch 128/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.8205 - precision: 0.8302 - recall: 0.8859 - AUC: 0.8100 - AUPR: 0.8037\n",
            "Epoch 129/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3921 - accuracy: 0.8231 - precision: 0.8324 - recall: 0.8878 - AUC: 0.8112 - AUPR: 0.8025\n",
            "Epoch 130/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3900 - accuracy: 0.8233 - precision: 0.8327 - recall: 0.8877 - AUC: 0.8164 - AUPR: 0.8082\n",
            "Epoch 131/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3923 - accuracy: 0.8209 - precision: 0.8302 - recall: 0.8869 - AUC: 0.8114 - AUPR: 0.8021\n",
            "Epoch 132/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.8226 - precision: 0.8328 - recall: 0.8861 - AUC: 0.8101 - AUPR: 0.8040\n",
            "Epoch 133/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3935 - accuracy: 0.8198 - precision: 0.8307 - recall: 0.8838 - AUC: 0.8100 - AUPR: 0.8044\n",
            "Epoch 134/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8216 - precision: 0.8313 - recall: 0.8866 - AUC: 0.8114 - AUPR: 0.8048\n",
            "Epoch 135/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3946 - accuracy: 0.8217 - precision: 0.8320 - recall: 0.8854 - AUC: 0.8074 - AUPR: 0.7994\n",
            "Epoch 136/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3924 - accuracy: 0.8202 - precision: 0.8315 - recall: 0.8834 - AUC: 0.8114 - AUPR: 0.8013\n",
            "Epoch 137/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.8206 - precision: 0.8317 - recall: 0.8838 - AUC: 0.8070 - AUPR: 0.8022\n",
            "Epoch 138/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3939 - accuracy: 0.8209 - precision: 0.8295 - recall: 0.8880 - AUC: 0.8098 - AUPR: 0.8018\n",
            "Epoch 139/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.8201 - precision: 0.8305 - recall: 0.8847 - AUC: 0.8093 - AUPR: 0.8041\n",
            "Epoch 140/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3941 - accuracy: 0.8208 - precision: 0.8297 - recall: 0.8874 - AUC: 0.8075 - AUPR: 0.8001\n",
            "Epoch 141/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.8197 - precision: 0.8298 - recall: 0.8851 - AUC: 0.8094 - AUPR: 0.8043\n",
            "Epoch 142/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3948 - accuracy: 0.8208 - precision: 0.8323 - recall: 0.8832 - AUC: 0.8065 - AUPR: 0.8024\n",
            "Epoch 143/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3940 - accuracy: 0.8227 - precision: 0.8326 - recall: 0.8868 - AUC: 0.8074 - AUPR: 0.8007\n",
            "Epoch 144/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3924 - accuracy: 0.8221 - precision: 0.8323 - recall: 0.8858 - AUC: 0.8112 - AUPR: 0.8048\n",
            "Epoch 145/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8233 - precision: 0.8342 - recall: 0.8854 - AUC: 0.8117 - AUPR: 0.8030\n",
            "Epoch 146/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3915 - accuracy: 0.8218 - precision: 0.8317 - recall: 0.8863 - AUC: 0.8114 - AUPR: 0.8048\n",
            "Epoch 147/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3918 - accuracy: 0.8228 - precision: 0.8329 - recall: 0.8863 - AUC: 0.8102 - AUPR: 0.8050\n",
            "Epoch 148/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3930 - accuracy: 0.8218 - precision: 0.8306 - recall: 0.8882 - AUC: 0.8099 - AUPR: 0.8004\n",
            "Epoch 149/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3945 - accuracy: 0.8208 - precision: 0.8291 - recall: 0.8884 - AUC: 0.8076 - AUPR: 0.8006\n",
            "Epoch 150/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.8210 - precision: 0.8337 - recall: 0.8815 - AUC: 0.8110 - AUPR: 0.8024\n",
            "Epoch 151/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8237 - precision: 0.8357 - recall: 0.8839 - AUC: 0.8141 - AUPR: 0.8083\n",
            "Epoch 152/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3936 - accuracy: 0.8210 - precision: 0.8314 - recall: 0.8851 - AUC: 0.8081 - AUPR: 0.8006\n",
            "Epoch 153/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3941 - accuracy: 0.8216 - precision: 0.8314 - recall: 0.8864 - AUC: 0.8087 - AUPR: 0.8043\n",
            "Epoch 154/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3923 - accuracy: 0.8227 - precision: 0.8325 - recall: 0.8868 - AUC: 0.8111 - AUPR: 0.8008\n",
            "Epoch 155/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.8216 - precision: 0.8325 - recall: 0.8845 - AUC: 0.8094 - AUPR: 0.8048\n",
            "Epoch 156/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3922 - accuracy: 0.8221 - precision: 0.8307 - recall: 0.8884 - AUC: 0.8107 - AUPR: 0.8066\n",
            "Epoch 157/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8228 - precision: 0.8316 - recall: 0.8884 - AUC: 0.8108 - AUPR: 0.8026\n",
            "Epoch 158/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3909 - accuracy: 0.8241 - precision: 0.8335 - recall: 0.8880 - AUC: 0.8107 - AUPR: 0.8037\n",
            "Epoch 159/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3942 - accuracy: 0.8204 - precision: 0.8315 - recall: 0.8838 - AUC: 0.8096 - AUPR: 0.8012\n",
            "Epoch 160/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.8238 - precision: 0.8346 - recall: 0.8859 - AUC: 0.8110 - AUPR: 0.8058\n",
            "Epoch 161/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3960 - accuracy: 0.8190 - precision: 0.8307 - recall: 0.8822 - AUC: 0.8076 - AUPR: 0.8017\n",
            "Epoch 162/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.8200 - precision: 0.8303 - recall: 0.8849 - AUC: 0.8058 - AUPR: 0.8031\n",
            "Epoch 163/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3926 - accuracy: 0.8207 - precision: 0.8296 - recall: 0.8874 - AUC: 0.8108 - AUPR: 0.8049\n",
            "Epoch 164/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.8217 - precision: 0.8311 - recall: 0.8871 - AUC: 0.8100 - AUPR: 0.8037\n",
            "Epoch 165/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8227 - precision: 0.8310 - recall: 0.8892 - AUC: 0.8115 - AUPR: 0.8047\n",
            "Epoch 166/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.8204 - precision: 0.8299 - recall: 0.8863 - AUC: 0.8086 - AUPR: 0.8052\n",
            "Epoch 167/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8216 - precision: 0.8315 - recall: 0.8860 - AUC: 0.8113 - AUPR: 0.8043\n",
            "Epoch 168/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8246 - precision: 0.8359 - recall: 0.8853 - AUC: 0.8148 - AUPR: 0.8085\n",
            "Epoch 169/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.8225 - precision: 0.8325 - recall: 0.8865 - AUC: 0.8117 - AUPR: 0.8052\n",
            "Epoch 170/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3939 - accuracy: 0.8207 - precision: 0.8307 - recall: 0.8856 - AUC: 0.8080 - AUPR: 0.8016\n",
            "Epoch 171/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8229 - precision: 0.8315 - recall: 0.8887 - AUC: 0.8121 - AUPR: 0.8048\n",
            "Epoch 172/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3935 - accuracy: 0.8205 - precision: 0.8301 - recall: 0.8861 - AUC: 0.8086 - AUPR: 0.8033\n",
            "Epoch 173/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3955 - accuracy: 0.8198 - precision: 0.8307 - recall: 0.8838 - AUC: 0.8067 - AUPR: 0.8000\n",
            "Epoch 174/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8223 - precision: 0.8320 - recall: 0.8868 - AUC: 0.8119 - AUPR: 0.8031\n",
            "Epoch 175/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8249 - precision: 0.8339 - recall: 0.8892 - AUC: 0.8131 - AUPR: 0.8044\n",
            "Epoch 176/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3930 - accuracy: 0.8226 - precision: 0.8322 - recall: 0.8870 - AUC: 0.8114 - AUPR: 0.8057\n",
            "Epoch 177/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.8215 - precision: 0.8323 - recall: 0.8847 - AUC: 0.8109 - AUPR: 0.8017\n",
            "Epoch 178/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.8196 - precision: 0.8295 - recall: 0.8853 - AUC: 0.8088 - AUPR: 0.8040\n",
            "Epoch 179/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 0.8226 - precision: 0.8320 - recall: 0.8874 - AUC: 0.8101 - AUPR: 0.8036\n",
            "Epoch 180/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3938 - accuracy: 0.8210 - precision: 0.8316 - recall: 0.8847 - AUC: 0.8089 - AUPR: 0.8020\n",
            "Epoch 181/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8222 - precision: 0.8319 - recall: 0.8867 - AUC: 0.8098 - AUPR: 0.8028\n",
            "Epoch 182/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3918 - accuracy: 0.8214 - precision: 0.8313 - recall: 0.8862 - AUC: 0.8104 - AUPR: 0.8037\n",
            "Epoch 183/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3927 - accuracy: 0.8221 - precision: 0.8321 - recall: 0.8863 - AUC: 0.8117 - AUPR: 0.8019\n",
            "Epoch 184/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3903 - accuracy: 0.8227 - precision: 0.8321 - recall: 0.8874 - AUC: 0.8143 - AUPR: 0.8051\n",
            "Epoch 185/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3904 - accuracy: 0.8225 - precision: 0.8316 - recall: 0.8879 - AUC: 0.8118 - AUPR: 0.8081\n",
            "Epoch 186/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8216 - precision: 0.8323 - recall: 0.8849 - AUC: 0.8125 - AUPR: 0.8048\n",
            "Epoch 187/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8224 - precision: 0.8313 - recall: 0.8881 - AUC: 0.8117 - AUPR: 0.8065\n",
            "Epoch 188/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8251 - precision: 0.8348 - recall: 0.8882 - AUC: 0.8136 - AUPR: 0.8049\n",
            "Epoch 189/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3939 - accuracy: 0.8198 - precision: 0.8273 - recall: 0.8894 - AUC: 0.8104 - AUPR: 0.8054\n",
            "Epoch 190/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3910 - accuracy: 0.8229 - precision: 0.8335 - recall: 0.8856 - AUC: 0.8130 - AUPR: 0.8022\n",
            "Epoch 191/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3885 - accuracy: 0.8236 - precision: 0.8340 - recall: 0.8864 - AUC: 0.8155 - AUPR: 0.8057\n",
            "Epoch 192/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8202 - precision: 0.8303 - recall: 0.8852 - AUC: 0.8063 - AUPR: 0.8008\n",
            "Epoch 193/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3909 - accuracy: 0.8219 - precision: 0.8308 - recall: 0.8880 - AUC: 0.8132 - AUPR: 0.8058\n",
            "Epoch 194/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3900 - accuracy: 0.8225 - precision: 0.8335 - recall: 0.8847 - AUC: 0.8130 - AUPR: 0.8074\n",
            "Epoch 195/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3869 - accuracy: 0.8250 - precision: 0.8346 - recall: 0.8881 - AUC: 0.8192 - AUPR: 0.8101\n",
            "Epoch 196/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8220 - precision: 0.8318 - recall: 0.8866 - AUC: 0.8130 - AUPR: 0.8065\n",
            "Epoch 197/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.8205 - precision: 0.8309 - recall: 0.8849 - AUC: 0.8082 - AUPR: 0.8014\n",
            "Epoch 198/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.8210 - precision: 0.8305 - recall: 0.8865 - AUC: 0.8071 - AUPR: 0.8001\n",
            "Epoch 199/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3914 - accuracy: 0.8235 - precision: 0.8347 - recall: 0.8850 - AUC: 0.8120 - AUPR: 0.8061\n",
            "Epoch 200/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8234 - precision: 0.8338 - recall: 0.8862 - AUC: 0.8106 - AUPR: 0.8043\n",
            "Epoch 201/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8230 - precision: 0.8331 - recall: 0.8865 - AUC: 0.8138 - AUPR: 0.8046\n",
            "Epoch 202/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8223 - precision: 0.8309 - recall: 0.8886 - AUC: 0.8094 - AUPR: 0.8078\n",
            "Epoch 203/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.8205 - precision: 0.8298 - recall: 0.8866 - AUC: 0.8071 - AUPR: 0.8016\n",
            "Epoch 204/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3930 - accuracy: 0.8213 - precision: 0.8317 - recall: 0.8853 - AUC: 0.8125 - AUPR: 0.8053\n",
            "Epoch 205/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3899 - accuracy: 0.8228 - precision: 0.8325 - recall: 0.8869 - AUC: 0.8144 - AUPR: 0.8106\n",
            "Epoch 206/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3918 - accuracy: 0.8218 - precision: 0.8323 - recall: 0.8852 - AUC: 0.8127 - AUPR: 0.8074\n",
            "Epoch 207/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8196 - precision: 0.8304 - recall: 0.8837 - AUC: 0.8072 - AUPR: 0.8012\n",
            "Epoch 208/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8229 - precision: 0.8343 - recall: 0.8844 - AUC: 0.8137 - AUPR: 0.8065\n",
            "Epoch 209/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8229 - precision: 0.8326 - recall: 0.8870 - AUC: 0.8113 - AUPR: 0.8051\n",
            "Epoch 210/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.8196 - precision: 0.8299 - recall: 0.8846 - AUC: 0.8073 - AUPR: 0.8011\n",
            "Epoch 211/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8217 - precision: 0.8307 - recall: 0.8877 - AUC: 0.8121 - AUPR: 0.8021\n",
            "Epoch 212/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3909 - accuracy: 0.8231 - precision: 0.8327 - recall: 0.8873 - AUC: 0.8119 - AUPR: 0.8048\n",
            "Epoch 213/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3888 - accuracy: 0.8240 - precision: 0.8332 - recall: 0.8884 - AUC: 0.8159 - AUPR: 0.8058\n",
            "Epoch 214/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8231 - precision: 0.8326 - recall: 0.8874 - AUC: 0.8148 - AUPR: 0.8080\n",
            "Epoch 215/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8222 - precision: 0.8314 - recall: 0.8874 - AUC: 0.8151 - AUPR: 0.8076\n",
            "Epoch 216/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8220 - precision: 0.8326 - recall: 0.8852 - AUC: 0.8119 - AUPR: 0.8042\n",
            "Epoch 217/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3928 - accuracy: 0.8214 - precision: 0.8318 - recall: 0.8853 - AUC: 0.8097 - AUPR: 0.8002\n",
            "Epoch 218/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3917 - accuracy: 0.8232 - precision: 0.8336 - recall: 0.8862 - AUC: 0.8122 - AUPR: 0.8050\n",
            "Epoch 219/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8233 - precision: 0.8315 - recall: 0.8896 - AUC: 0.8150 - AUPR: 0.8066\n",
            "Epoch 220/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8231 - precision: 0.8312 - recall: 0.8896 - AUC: 0.8128 - AUPR: 0.8095\n",
            "Epoch 221/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3934 - accuracy: 0.8216 - precision: 0.8306 - recall: 0.8877 - AUC: 0.8090 - AUPR: 0.8051\n",
            "Epoch 222/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3946 - accuracy: 0.8207 - precision: 0.8306 - recall: 0.8857 - AUC: 0.8076 - AUPR: 0.8023\n",
            "Epoch 223/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3877 - accuracy: 0.8259 - precision: 0.8342 - recall: 0.8906 - AUC: 0.8167 - AUPR: 0.8089\n",
            "Epoch 224/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8237 - precision: 0.8335 - recall: 0.8873 - AUC: 0.8138 - AUPR: 0.8028\n",
            "Epoch 225/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3898 - accuracy: 0.8229 - precision: 0.8342 - recall: 0.8844 - AUC: 0.8131 - AUPR: 0.8062\n",
            "Epoch 226/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.8218 - precision: 0.8324 - recall: 0.8850 - AUC: 0.8132 - AUPR: 0.8059\n",
            "Epoch 227/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3896 - accuracy: 0.8235 - precision: 0.8318 - recall: 0.8895 - AUC: 0.8140 - AUPR: 0.8057\n",
            "Epoch 228/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3937 - accuracy: 0.8192 - precision: 0.8280 - recall: 0.8868 - AUC: 0.8100 - AUPR: 0.8041\n",
            "Epoch 229/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3923 - accuracy: 0.8231 - precision: 0.8341 - recall: 0.8851 - AUC: 0.8094 - AUPR: 0.8008\n",
            "Epoch 230/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3931 - accuracy: 0.8219 - precision: 0.8324 - recall: 0.8854 - AUC: 0.8086 - AUPR: 0.8029\n",
            "Epoch 231/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8225 - precision: 0.8333 - recall: 0.8852 - AUC: 0.8111 - AUPR: 0.8042\n",
            "Epoch 232/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8249 - precision: 0.8339 - recall: 0.8892 - AUC: 0.8144 - AUPR: 0.8067\n",
            "Epoch 233/400\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8245 - precision: 0.8330 - recall: 0.8896 - AUC: 0.8148 - AUPR: 0.8030\n",
            "Epoch 234/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8247 - precision: 0.8335 - recall: 0.8892 - AUC: 0.8135 - AUPR: 0.8073\n",
            "Epoch 235/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3930 - accuracy: 0.8209 - precision: 0.8307 - recall: 0.8859 - AUC: 0.8094 - AUPR: 0.8033\n",
            "Epoch 236/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3926 - accuracy: 0.8210 - precision: 0.8303 - recall: 0.8869 - AUC: 0.8117 - AUPR: 0.8052\n",
            "Epoch 237/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3962 - accuracy: 0.8190 - precision: 0.8282 - recall: 0.8861 - AUC: 0.8044 - AUPR: 0.8001\n",
            "Epoch 238/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3908 - accuracy: 0.8227 - precision: 0.8331 - recall: 0.8859 - AUC: 0.8136 - AUPR: 0.8033\n",
            "Epoch 239/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3887 - accuracy: 0.8240 - precision: 0.8338 - recall: 0.8874 - AUC: 0.8180 - AUPR: 0.8059\n",
            "Epoch 240/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3880 - accuracy: 0.8237 - precision: 0.8336 - recall: 0.8871 - AUC: 0.8155 - AUPR: 0.8090\n",
            "Epoch 241/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3910 - accuracy: 0.8209 - precision: 0.8313 - recall: 0.8849 - AUC: 0.8133 - AUPR: 0.8041\n",
            "Epoch 242/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3904 - accuracy: 0.8221 - precision: 0.8332 - recall: 0.8846 - AUC: 0.8135 - AUPR: 0.8038\n",
            "Epoch 243/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3878 - accuracy: 0.8243 - precision: 0.8333 - recall: 0.8888 - AUC: 0.8168 - AUPR: 0.8062\n",
            "Epoch 244/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8217 - precision: 0.8319 - recall: 0.8858 - AUC: 0.8105 - AUPR: 0.8028\n",
            "Epoch 245/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3920 - accuracy: 0.8228 - precision: 0.8332 - recall: 0.8861 - AUC: 0.8110 - AUPR: 0.8023\n",
            "Epoch 246/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.8229 - precision: 0.8321 - recall: 0.8879 - AUC: 0.8158 - AUPR: 0.8056\n",
            "Epoch 247/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8236 - precision: 0.8328 - recall: 0.8883 - AUC: 0.8173 - AUPR: 0.8090\n",
            "Epoch 248/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.8231 - precision: 0.8320 - recall: 0.8885 - AUC: 0.8097 - AUPR: 0.8047\n",
            "Epoch 249/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3906 - accuracy: 0.8223 - precision: 0.8325 - recall: 0.8862 - AUC: 0.8128 - AUPR: 0.8069\n",
            "Epoch 250/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3923 - accuracy: 0.8220 - precision: 0.8328 - recall: 0.8850 - AUC: 0.8114 - AUPR: 0.8034\n",
            "Epoch 251/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3932 - accuracy: 0.8214 - precision: 0.8297 - recall: 0.8887 - AUC: 0.8095 - AUPR: 0.8017\n",
            "Epoch 252/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3908 - accuracy: 0.8220 - precision: 0.8321 - recall: 0.8861 - AUC: 0.8140 - AUPR: 0.8068\n",
            "Epoch 253/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3933 - accuracy: 0.8215 - precision: 0.8309 - recall: 0.8868 - AUC: 0.8104 - AUPR: 0.8027\n",
            "Epoch 254/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3896 - accuracy: 0.8234 - precision: 0.8338 - recall: 0.8861 - AUC: 0.8140 - AUPR: 0.8073\n",
            "Epoch 255/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8215 - precision: 0.8314 - recall: 0.8861 - AUC: 0.8129 - AUPR: 0.8058\n",
            "Epoch 256/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3909 - accuracy: 0.8220 - precision: 0.8318 - recall: 0.8865 - AUC: 0.8128 - AUPR: 0.8045\n",
            "Epoch 257/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.8245 - precision: 0.8336 - recall: 0.8889 - AUC: 0.8170 - AUPR: 0.8093\n",
            "Epoch 258/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8242 - precision: 0.8360 - recall: 0.8843 - AUC: 0.8149 - AUPR: 0.8073\n",
            "Epoch 259/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.8232 - precision: 0.8319 - recall: 0.8889 - AUC: 0.8110 - AUPR: 0.8078\n",
            "Epoch 260/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.8233 - precision: 0.8345 - recall: 0.8849 - AUC: 0.8172 - AUPR: 0.8082\n",
            "Epoch 261/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.8213 - precision: 0.8326 - recall: 0.8837 - AUC: 0.8096 - AUPR: 0.8072\n",
            "Epoch 262/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3900 - accuracy: 0.8237 - precision: 0.8321 - recall: 0.8896 - AUC: 0.8153 - AUPR: 0.8042\n",
            "Epoch 263/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8237 - precision: 0.8349 - recall: 0.8851 - AUC: 0.8129 - AUPR: 0.8072\n",
            "Epoch 264/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8224 - precision: 0.8323 - recall: 0.8865 - AUC: 0.8151 - AUPR: 0.8086\n",
            "Epoch 265/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8211 - precision: 0.8315 - recall: 0.8852 - AUC: 0.8139 - AUPR: 0.8074\n",
            "Epoch 266/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8211 - precision: 0.8298 - recall: 0.8879 - AUC: 0.8154 - AUPR: 0.8068\n",
            "Epoch 267/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3890 - accuracy: 0.8250 - precision: 0.8362 - recall: 0.8856 - AUC: 0.8160 - AUPR: 0.8069\n",
            "Epoch 268/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3877 - accuracy: 0.8245 - precision: 0.8330 - recall: 0.8898 - AUC: 0.8180 - AUPR: 0.8052\n",
            "Epoch 269/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3917 - accuracy: 0.8224 - precision: 0.8310 - recall: 0.8885 - AUC: 0.8122 - AUPR: 0.8033\n",
            "Epoch 270/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3933 - accuracy: 0.8205 - precision: 0.8304 - recall: 0.8857 - AUC: 0.8105 - AUPR: 0.8030\n",
            "Epoch 271/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3883 - accuracy: 0.8250 - precision: 0.8345 - recall: 0.8882 - AUC: 0.8156 - AUPR: 0.8056\n",
            "Epoch 272/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3902 - accuracy: 0.8228 - precision: 0.8327 - recall: 0.8866 - AUC: 0.8141 - AUPR: 0.8052\n",
            "Epoch 273/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8224 - precision: 0.8313 - recall: 0.8882 - AUC: 0.8130 - AUPR: 0.8064\n",
            "Epoch 274/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3935 - accuracy: 0.8216 - precision: 0.8303 - recall: 0.8882 - AUC: 0.8098 - AUPR: 0.8028\n",
            "Epoch 275/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8223 - precision: 0.8321 - recall: 0.8866 - AUC: 0.8143 - AUPR: 0.8081\n",
            "Epoch 276/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8246 - precision: 0.8346 - recall: 0.8874 - AUC: 0.8107 - AUPR: 0.8046\n",
            "Epoch 277/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8236 - precision: 0.8336 - recall: 0.8869 - AUC: 0.8126 - AUPR: 0.8087\n",
            "Epoch 278/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3891 - accuracy: 0.8243 - precision: 0.8335 - recall: 0.8884 - AUC: 0.8143 - AUPR: 0.8066\n",
            "Epoch 279/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3913 - accuracy: 0.8231 - precision: 0.8329 - recall: 0.8871 - AUC: 0.8105 - AUPR: 0.8027\n",
            "Epoch 280/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.8239 - precision: 0.8329 - recall: 0.8887 - AUC: 0.8198 - AUPR: 0.8061\n",
            "Epoch 281/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.8236 - precision: 0.8345 - recall: 0.8855 - AUC: 0.8186 - AUPR: 0.8068\n",
            "Epoch 282/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8224 - precision: 0.8324 - recall: 0.8862 - AUC: 0.8116 - AUPR: 0.8068\n",
            "Epoch 283/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3912 - accuracy: 0.8237 - precision: 0.8332 - recall: 0.8879 - AUC: 0.8122 - AUPR: 0.8047\n",
            "Epoch 284/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8242 - precision: 0.8318 - recall: 0.8909 - AUC: 0.8184 - AUPR: 0.8074\n",
            "Epoch 285/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8228 - precision: 0.8334 - recall: 0.8856 - AUC: 0.8143 - AUPR: 0.8048\n",
            "Epoch 286/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8228 - precision: 0.8325 - recall: 0.8870 - AUC: 0.8137 - AUPR: 0.8036\n",
            "Epoch 287/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8241 - precision: 0.8332 - recall: 0.8886 - AUC: 0.8162 - AUPR: 0.8070\n",
            "Epoch 288/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3910 - accuracy: 0.8225 - precision: 0.8309 - recall: 0.8890 - AUC: 0.8135 - AUPR: 0.8060\n",
            "Epoch 289/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8233 - precision: 0.8340 - recall: 0.8857 - AUC: 0.8137 - AUPR: 0.8067\n",
            "Epoch 290/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3909 - accuracy: 0.8238 - precision: 0.8332 - recall: 0.8880 - AUC: 0.8116 - AUPR: 0.8044\n",
            "Epoch 291/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3875 - accuracy: 0.8252 - precision: 0.8348 - recall: 0.8882 - AUC: 0.8178 - AUPR: 0.8104\n",
            "Epoch 292/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3892 - accuracy: 0.8258 - precision: 0.8359 - recall: 0.8878 - AUC: 0.8160 - AUPR: 0.8103\n",
            "Epoch 293/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.8246 - precision: 0.8335 - recall: 0.8893 - AUC: 0.8149 - AUPR: 0.8059\n",
            "Epoch 294/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.8224 - precision: 0.8328 - recall: 0.8857 - AUC: 0.8149 - AUPR: 0.8065\n",
            "Epoch 295/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8220 - precision: 0.8308 - recall: 0.8883 - AUC: 0.8115 - AUPR: 0.8077\n",
            "Epoch 296/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3908 - accuracy: 0.8235 - precision: 0.8350 - recall: 0.8843 - AUC: 0.8128 - AUPR: 0.8085\n",
            "Epoch 297/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.8233 - precision: 0.8340 - recall: 0.8857 - AUC: 0.8126 - AUPR: 0.8016\n",
            "Epoch 298/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8248 - precision: 0.8350 - recall: 0.8873 - AUC: 0.8147 - AUPR: 0.8047\n",
            "Epoch 299/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3883 - accuracy: 0.8223 - precision: 0.8325 - recall: 0.8861 - AUC: 0.8159 - AUPR: 0.8085\n",
            "Epoch 300/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8232 - precision: 0.8311 - recall: 0.8902 - AUC: 0.8138 - AUPR: 0.8063\n",
            "Epoch 301/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8216 - precision: 0.8307 - recall: 0.8875 - AUC: 0.8159 - AUPR: 0.8094\n",
            "Epoch 302/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8228 - precision: 0.8330 - recall: 0.8862 - AUC: 0.8157 - AUPR: 0.8083\n",
            "Epoch 303/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3907 - accuracy: 0.8230 - precision: 0.8318 - recall: 0.8887 - AUC: 0.8121 - AUPR: 0.8020\n",
            "Epoch 304/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8213 - precision: 0.8327 - recall: 0.8837 - AUC: 0.8137 - AUPR: 0.8068\n",
            "Epoch 305/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8225 - precision: 0.8318 - recall: 0.8877 - AUC: 0.8157 - AUPR: 0.8045\n",
            "Epoch 306/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3896 - accuracy: 0.8237 - precision: 0.8330 - recall: 0.8881 - AUC: 0.8139 - AUPR: 0.8059\n",
            "Epoch 307/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8235 - precision: 0.8329 - recall: 0.8879 - AUC: 0.8149 - AUPR: 0.8070\n",
            "Epoch 308/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8240 - precision: 0.8338 - recall: 0.8875 - AUC: 0.8202 - AUPR: 0.8072\n",
            "Epoch 309/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3909 - accuracy: 0.8223 - precision: 0.8333 - recall: 0.8847 - AUC: 0.8139 - AUPR: 0.8052\n",
            "Epoch 310/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3870 - accuracy: 0.8244 - precision: 0.8335 - recall: 0.8886 - AUC: 0.8177 - AUPR: 0.8072\n",
            "Epoch 311/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.8257 - precision: 0.8362 - recall: 0.8871 - AUC: 0.8180 - AUPR: 0.8084\n",
            "Epoch 312/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3921 - accuracy: 0.8217 - precision: 0.8318 - recall: 0.8859 - AUC: 0.8098 - AUPR: 0.8034\n",
            "Epoch 313/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.8235 - precision: 0.8342 - recall: 0.8859 - AUC: 0.8127 - AUPR: 0.8035\n",
            "Epoch 314/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8226 - precision: 0.8330 - recall: 0.8858 - AUC: 0.8129 - AUPR: 0.8033\n",
            "Epoch 315/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3899 - accuracy: 0.8247 - precision: 0.8349 - recall: 0.8871 - AUC: 0.8117 - AUPR: 0.8067\n",
            "Epoch 316/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.8226 - precision: 0.8329 - recall: 0.8859 - AUC: 0.8175 - AUPR: 0.8083\n",
            "Epoch 317/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3903 - accuracy: 0.8226 - precision: 0.8321 - recall: 0.8872 - AUC: 0.8134 - AUPR: 0.8081\n",
            "Epoch 318/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.8240 - precision: 0.8339 - recall: 0.8873 - AUC: 0.8172 - AUPR: 0.8084\n",
            "Epoch 319/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8229 - precision: 0.8339 - recall: 0.8849 - AUC: 0.8187 - AUPR: 0.8087\n",
            "Epoch 320/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3907 - accuracy: 0.8235 - precision: 0.8333 - recall: 0.8872 - AUC: 0.8119 - AUPR: 0.8042\n",
            "Epoch 321/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8231 - precision: 0.8339 - recall: 0.8855 - AUC: 0.8159 - AUPR: 0.8078\n",
            "Epoch 322/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3900 - accuracy: 0.8219 - precision: 0.8308 - recall: 0.8880 - AUC: 0.8136 - AUPR: 0.8086\n",
            "Epoch 323/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3895 - accuracy: 0.8235 - precision: 0.8343 - recall: 0.8855 - AUC: 0.8147 - AUPR: 0.8064\n",
            "Epoch 324/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.8232 - precision: 0.8338 - recall: 0.8859 - AUC: 0.8123 - AUPR: 0.8055\n",
            "Epoch 325/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3894 - accuracy: 0.8217 - precision: 0.8319 - recall: 0.8857 - AUC: 0.8151 - AUPR: 0.8096\n",
            "Epoch 326/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3889 - accuracy: 0.8235 - precision: 0.8312 - recall: 0.8905 - AUC: 0.8158 - AUPR: 0.8052\n",
            "Epoch 327/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.8226 - precision: 0.8315 - recall: 0.8881 - AUC: 0.8139 - AUPR: 0.8047\n",
            "Epoch 328/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3889 - accuracy: 0.8243 - precision: 0.8337 - recall: 0.8883 - AUC: 0.8157 - AUPR: 0.8064\n",
            "Epoch 329/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.8239 - precision: 0.8327 - recall: 0.8890 - AUC: 0.8172 - AUPR: 0.8127\n",
            "Epoch 330/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3888 - accuracy: 0.8245 - precision: 0.8349 - recall: 0.8866 - AUC: 0.8176 - AUPR: 0.8078\n",
            "Epoch 331/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8208 - precision: 0.8307 - recall: 0.8858 - AUC: 0.8143 - AUPR: 0.8053\n",
            "Epoch 332/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8235 - precision: 0.8335 - recall: 0.8870 - AUC: 0.8152 - AUPR: 0.8039\n",
            "Epoch 333/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8226 - precision: 0.8337 - recall: 0.8847 - AUC: 0.8169 - AUPR: 0.8113\n",
            "Epoch 334/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8225 - precision: 0.8333 - recall: 0.8850 - AUC: 0.8149 - AUPR: 0.8081\n",
            "Epoch 335/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3852 - accuracy: 0.8242 - precision: 0.8332 - recall: 0.8889 - AUC: 0.8226 - AUPR: 0.8099\n",
            "Epoch 336/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3861 - accuracy: 0.8268 - precision: 0.8358 - recall: 0.8900 - AUC: 0.8202 - AUPR: 0.8093\n",
            "Epoch 337/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.8247 - precision: 0.8345 - recall: 0.8878 - AUC: 0.8134 - AUPR: 0.8052\n",
            "Epoch 338/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3878 - accuracy: 0.8223 - precision: 0.8323 - recall: 0.8863 - AUC: 0.8173 - AUPR: 0.8076\n",
            "Epoch 339/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.8236 - precision: 0.8328 - recall: 0.8881 - AUC: 0.8165 - AUPR: 0.8079\n",
            "Epoch 340/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.8232 - precision: 0.8331 - recall: 0.8868 - AUC: 0.8162 - AUPR: 0.8075\n",
            "Epoch 341/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3896 - accuracy: 0.8226 - precision: 0.8318 - recall: 0.8877 - AUC: 0.8139 - AUPR: 0.8095\n",
            "Epoch 342/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8249 - precision: 0.8360 - recall: 0.8859 - AUC: 0.8176 - AUPR: 0.8067\n",
            "Epoch 343/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3922 - accuracy: 0.8225 - precision: 0.8318 - recall: 0.8875 - AUC: 0.8107 - AUPR: 0.8042\n",
            "Epoch 344/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8249 - precision: 0.8355 - recall: 0.8866 - AUC: 0.8184 - AUPR: 0.8093\n",
            "Epoch 345/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3911 - accuracy: 0.8215 - precision: 0.8304 - recall: 0.8878 - AUC: 0.8130 - AUPR: 0.8027\n",
            "Epoch 346/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3915 - accuracy: 0.8215 - precision: 0.8323 - recall: 0.8847 - AUC: 0.8137 - AUPR: 0.8094\n",
            "Epoch 347/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3923 - accuracy: 0.8227 - precision: 0.8322 - recall: 0.8873 - AUC: 0.8089 - AUPR: 0.8020\n",
            "Epoch 348/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3892 - accuracy: 0.8237 - precision: 0.8342 - recall: 0.8862 - AUC: 0.8149 - AUPR: 0.8081\n",
            "Epoch 349/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3895 - accuracy: 0.8234 - precision: 0.8348 - recall: 0.8846 - AUC: 0.8152 - AUPR: 0.8055\n",
            "Epoch 350/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3875 - accuracy: 0.8229 - precision: 0.8324 - recall: 0.8874 - AUC: 0.8180 - AUPR: 0.8108\n",
            "Epoch 351/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3881 - accuracy: 0.8236 - precision: 0.8329 - recall: 0.8880 - AUC: 0.8161 - AUPR: 0.8073\n",
            "Epoch 352/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3887 - accuracy: 0.8244 - precision: 0.8347 - recall: 0.8868 - AUC: 0.8164 - AUPR: 0.8034\n",
            "Epoch 353/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3880 - accuracy: 0.8245 - precision: 0.8341 - recall: 0.8881 - AUC: 0.8170 - AUPR: 0.8100\n",
            "Epoch 354/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3890 - accuracy: 0.8237 - precision: 0.8341 - recall: 0.8862 - AUC: 0.8171 - AUPR: 0.8069\n",
            "Epoch 355/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.8231 - precision: 0.8323 - recall: 0.8880 - AUC: 0.8148 - AUPR: 0.8070\n",
            "Epoch 356/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3885 - accuracy: 0.8240 - precision: 0.8333 - recall: 0.8882 - AUC: 0.8171 - AUPR: 0.8088\n",
            "Epoch 357/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3840 - accuracy: 0.8253 - precision: 0.8340 - recall: 0.8897 - AUC: 0.8233 - AUPR: 0.8106\n",
            "Epoch 358/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8241 - precision: 0.8337 - recall: 0.8878 - AUC: 0.8164 - AUPR: 0.8058\n",
            "Epoch 359/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8228 - precision: 0.8322 - recall: 0.8875 - AUC: 0.8117 - AUPR: 0.8061\n",
            "Epoch 360/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3892 - accuracy: 0.8234 - precision: 0.8324 - recall: 0.8885 - AUC: 0.8169 - AUPR: 0.8094\n",
            "Epoch 361/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3883 - accuracy: 0.8244 - precision: 0.8344 - recall: 0.8874 - AUC: 0.8185 - AUPR: 0.8109\n",
            "Epoch 362/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3881 - accuracy: 0.8238 - precision: 0.8335 - recall: 0.8875 - AUC: 0.8185 - AUPR: 0.8093\n",
            "Epoch 363/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3896 - accuracy: 0.8232 - precision: 0.8341 - recall: 0.8852 - AUC: 0.8186 - AUPR: 0.8082\n",
            "Epoch 364/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3888 - accuracy: 0.8234 - precision: 0.8322 - recall: 0.8886 - AUC: 0.8158 - AUPR: 0.8095\n",
            "Epoch 365/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8246 - precision: 0.8342 - recall: 0.8880 - AUC: 0.8158 - AUPR: 0.8092\n",
            "Epoch 366/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3880 - accuracy: 0.8247 - precision: 0.8348 - recall: 0.8874 - AUC: 0.8172 - AUPR: 0.8101\n",
            "Epoch 367/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3880 - accuracy: 0.8245 - precision: 0.8343 - recall: 0.8876 - AUC: 0.8173 - AUPR: 0.8045\n",
            "Epoch 368/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3894 - accuracy: 0.8246 - precision: 0.8346 - recall: 0.8872 - AUC: 0.8143 - AUPR: 0.8057\n",
            "Epoch 369/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.8229 - precision: 0.8345 - recall: 0.8840 - AUC: 0.8147 - AUPR: 0.8074\n",
            "Epoch 370/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3904 - accuracy: 0.8233 - precision: 0.8341 - recall: 0.8856 - AUC: 0.8142 - AUPR: 0.8037\n",
            "Epoch 371/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3883 - accuracy: 0.8232 - precision: 0.8328 - recall: 0.8873 - AUC: 0.8183 - AUPR: 0.8100\n",
            "Epoch 372/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.8220 - precision: 0.8312 - recall: 0.8875 - AUC: 0.8107 - AUPR: 0.8047\n",
            "Epoch 373/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.8208 - precision: 0.8314 - recall: 0.8847 - AUC: 0.8161 - AUPR: 0.8073\n",
            "Epoch 374/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3898 - accuracy: 0.8217 - precision: 0.8315 - recall: 0.8864 - AUC: 0.8154 - AUPR: 0.8074\n",
            "Epoch 375/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.8213 - precision: 0.8318 - recall: 0.8852 - AUC: 0.8131 - AUPR: 0.8054\n",
            "Epoch 376/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8237 - precision: 0.8323 - recall: 0.8892 - AUC: 0.8174 - AUPR: 0.8071\n",
            "Epoch 377/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3880 - accuracy: 0.8234 - precision: 0.8331 - recall: 0.8874 - AUC: 0.8169 - AUPR: 0.8072\n",
            "Epoch 378/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3891 - accuracy: 0.8240 - precision: 0.8333 - recall: 0.8883 - AUC: 0.8154 - AUPR: 0.8079\n",
            "Epoch 379/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.8243 - precision: 0.8341 - recall: 0.8876 - AUC: 0.8172 - AUPR: 0.8044\n",
            "Epoch 380/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3908 - accuracy: 0.8228 - precision: 0.8330 - recall: 0.8862 - AUC: 0.8128 - AUPR: 0.8040\n",
            "Epoch 381/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.8225 - precision: 0.8325 - recall: 0.8865 - AUC: 0.8159 - AUPR: 0.8082\n",
            "Epoch 382/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3866 - accuracy: 0.8257 - precision: 0.8345 - recall: 0.8898 - AUC: 0.8182 - AUPR: 0.8129\n",
            "Epoch 383/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3883 - accuracy: 0.8240 - precision: 0.8334 - recall: 0.8880 - AUC: 0.8171 - AUPR: 0.8036\n",
            "Epoch 384/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3878 - accuracy: 0.8242 - precision: 0.8343 - recall: 0.8871 - AUC: 0.8154 - AUPR: 0.8084\n",
            "Epoch 385/400\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.3889 - accuracy: 0.8239 - precision: 0.8336 - recall: 0.8876 - AUC: 0.8164 - AUPR: 0.8073\n",
            "Epoch 386/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3893 - accuracy: 0.8242 - precision: 0.8336 - recall: 0.8881 - AUC: 0.8156 - AUPR: 0.8046\n",
            "Epoch 387/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3885 - accuracy: 0.8246 - precision: 0.8347 - recall: 0.8872 - AUC: 0.8172 - AUPR: 0.8098\n",
            "Epoch 388/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8237 - precision: 0.8329 - recall: 0.8883 - AUC: 0.8173 - AUPR: 0.8074\n",
            "Epoch 389/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8225 - precision: 0.8317 - recall: 0.8876 - AUC: 0.8146 - AUPR: 0.8083\n",
            "Epoch 390/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8244 - precision: 0.8339 - recall: 0.8881 - AUC: 0.8185 - AUPR: 0.8073\n",
            "Epoch 391/400\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.8247 - precision: 0.8335 - recall: 0.8893 - AUC: 0.8194 - AUPR: 0.8112\n",
            "Epoch 392/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.8258 - precision: 0.8349 - recall: 0.8894 - AUC: 0.8195 - AUPR: 0.8120\n",
            "Epoch 393/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3872 - accuracy: 0.8242 - precision: 0.8341 - recall: 0.8874 - AUC: 0.8184 - AUPR: 0.8097\n",
            "Epoch 394/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3884 - accuracy: 0.8234 - precision: 0.8334 - recall: 0.8869 - AUC: 0.8169 - AUPR: 0.8073\n",
            "Epoch 395/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8240 - precision: 0.8347 - recall: 0.8859 - AUC: 0.8184 - AUPR: 0.8087\n",
            "Epoch 396/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3882 - accuracy: 0.8246 - precision: 0.8335 - recall: 0.8893 - AUC: 0.8190 - AUPR: 0.8083\n",
            "Epoch 397/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.8244 - precision: 0.8336 - recall: 0.8886 - AUC: 0.8184 - AUPR: 0.8056\n",
            "Epoch 398/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8229 - precision: 0.8329 - recall: 0.8867 - AUC: 0.8180 - AUPR: 0.8094\n",
            "Epoch 399/400\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3890 - accuracy: 0.8234 - precision: 0.8331 - recall: 0.8874 - AUC: 0.8158 - AUPR: 0.8089\n",
            "Epoch 400/400\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3905 - accuracy: 0.8225 - precision: 0.8333 - recall: 0.8852 - AUC: 0.8124 - AUPR: 0.8038\n",
            "8/8 [==============================] - 1s 5ms/step - loss: 0.4257 - accuracy: 0.8079 - precision: 0.8389 - recall: 0.8655 - AUC: 0.7247 - AUPR: 0.7712\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AUC': 0.7246651649475098,\n",
              " 'AUPR': 0.7711918950080872,\n",
              " 'accuracy': 0.8079012632369995,\n",
              " 'loss': 0.42572110891342163,\n",
              " 'precision': 0.8389111161231995,\n",
              " 'recall': 0.8654986023902893}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD63RHtOUYTc"
      },
      "source": [
        "y_pre5 = model5.predict(x4_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpZEALiZWSQf"
      },
      "source": [
        "nlabel = np.array(y_test)\n",
        "plabel = np.where(y_pre5 > 0.5,1,0)\n",
        "\n",
        "aiming, coverage, accuracy, absolute_true, absolute_false = validation(plabel, nlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1XVGISAxtIC",
        "outputId": "f550f4e0-14b0-4e54-f4ec-51badbf54259"
      },
      "source": [
        "aiming, coverage, accuracy, absolute_true, absolute_false"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8301208476641239,\n",
              " 0.8668982425136816,\n",
              " 0.7244053497074668,\n",
              " 0.04888888888888889,\n",
              " 0.19209876543209886)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4QXM7Mh3Z7x"
      },
      "source": [
        "m1 = keras.metrics.BinaryAccuracy(name='accuracy',threshold=0.5)\n",
        "m2 = keras.metrics.Precision(name='precision')\n",
        "m3 = keras.metrics.Recall(name='recall')\n",
        "m4 = keras.metrics.AUC(name='AUC',multi_label=True,num_labels=27,num_thresholds=498)\n",
        "m5 = keras.metrics.AUC(name='AUPR',curve='PR',multi_label=True,num_labels=27,num_thresholds=498)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s390Heek4aah"
      },
      "source": [
        "m1.update_state(y_test,y_pre12345)\n",
        "m2.update_state(y_test,y_pre12345)\n",
        "m3.update_state(y_test,y_pre12345)\n",
        "m4.update_state(y_test,y_pre12345)\n",
        "m5.update_state(y_test,y_pre12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7uLNBMHFO7f",
        "outputId": "dad39332-e9b1-4580-de13-100a1422d47d"
      },
      "source": [
        "print(f\"-Accuracy score_mean:{m1.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Precision score_mean:{m2.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Recall score_mean:{m3.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUC score_mean:{m4.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUPR score_mean:{m5.result().numpy()}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Accuracy score_mean:0.807953953742981\n",
            "-Precision score_mean:0.8502597212791443\n",
            "-Recall score_mean:0.8626877069473267\n",
            "-AUC score_mean:0.7449020743370056\n",
            "-AUPR score_mean:0.7810348272323608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x5Ma_k-49Y3",
        "outputId": "5d738c51-20d4-4d4d-9025-9fc2e89fcfad"
      },
      "source": [
        "m[0].result().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlRBDgOp3aBk"
      },
      "source": [
        "y_pre24 = (y_pre2+y_pre4)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQJjnOTpWSV4"
      },
      "source": [
        "y_pre12 = (y_pre1+y_pre2)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssMEOh4lHzxM"
      },
      "source": [
        "y_pre13 = (y_pre1+y_pre3)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw7qMwScHz0Q"
      },
      "source": [
        "y_pre14 = (y_pre1+y_pre4)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53M1ujBK6WCi"
      },
      "source": [
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQLHp8I6f26"
      },
      "source": [
        "y_pre15 = (y_pre1+y_pre5)/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBxCLy9WIhdY"
      },
      "source": [
        "y_pre135 = (y_pre1+y_pre3+y_pre5)/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiYHqTzZLo6Y"
      },
      "source": [
        "y_pre345 = (y_pre4+y_pre3+y_pre5)/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-kXTUdpMB71"
      },
      "source": [
        "y_pre1345 = (y_pre1+y_pre4+y_pre3+y_pre5)/4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OloqX52INOVW"
      },
      "source": [
        "y_pre12345 = (y_pre1+y_pre4+y_pre3+y_pre5)/5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgVLJO7uQ146"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQYXBUXBdG3"
      },
      "source": [
        "# 子模型融合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgHs2huUF2FO"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/iADR')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "y = pd.read_csv('./data/labels(2248).csv')\n",
        "data6 = np.load('./data/gin_supervised_masking.npy')\n",
        "c_X_train,k_x_test,c_Y_train,k_y_test= train_test_split(data6,y,test_size=0.1,random_state=2021)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llx7R7KPBida"
      },
      "source": [
        "m1 = keras.metrics.BinaryAccuracy(name='accuracy',threshold=0.5)\n",
        "m2 = keras.metrics.Precision(name='precision')\n",
        "m3 = keras.metrics.Recall(name='recall')\n",
        "m4 = keras.metrics.AUC(name='AUC',multi_label=True,num_labels=27,num_thresholds=498)\n",
        "m5 = keras.metrics.AUC(name='AUPR',curve='PR',multi_label=True,num_labels=27,num_thresholds=498)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk1bneaoCGNe",
        "outputId": "3b6a11da-e900-4bf5-fbfe-0d5b0ed165d6"
      },
      "source": [
        "#IADRDDI\n",
        "# y_pre1 = np.load('./model/masking/masking_pre.npy')\n",
        "# y_pre2 = np.load('./model/edeg/edeg_pre.npy')\n",
        "# y_pre3 = np.load('./model/info/info_pre.npy')\n",
        "# y_pre4 = np.load('./model/context/context_pre.npy')\n",
        "\n",
        "\n",
        "# y_pre5 = np.load('./model/fp/fp_pre.npy')\n",
        "# y_pre6 = np.load('./model/attfp/attfp_pre.npy')\n",
        "# y_pre = (y_pre1+y_pre2+y_pre4+y_pre5+y_pre6)/5\n",
        "\n",
        "\n",
        "#RF\n",
        "y_pre1 = np.load('./model/masking/masking_RF_pre.npy')\n",
        "y_pre2 = np.load('./model/edeg/edeg_RF_pre.npy')\n",
        "\n",
        "y_pre3 = np.load('./model/context/context_RF_pre.npy')\n",
        "y_pre4 = np.load('./model/attfp/attfp_RF_pre.npy')\n",
        "\n",
        "y_pre5 = np.load('./model/fp/fp_RF_pre.npy')\n",
        "\n",
        "\n",
        "#svm\n",
        "# y_pre1 = np.load('./model/masking/masking_svm_pre.npy')\n",
        "# y_pre2 = np.load('./model/edeg/edeg_svm_pre.npy')\n",
        "\n",
        "# y_pre3 = np.load('./model/context/context_svm_pre.npy')\n",
        "# y_pre4 = np.load('./model/attfp/attfp_svm_pre.npy')\n",
        "\n",
        "# y_pre5 = np.load('./model/fp/fp_svm_pre.npy')\n",
        "\n",
        "\n",
        "\n",
        "y_pre = (y_pre1+y_pre2+y_pre3+y_pre5+y_pre4)/5\n",
        "\n",
        "m1.update_state(k_y_test,y_pre)\n",
        "m2.update_state(k_y_test,y_pre)\n",
        "m3.update_state(k_y_test,y_pre)\n",
        "m4.update_state(k_y_test,y_pre)\n",
        "m5.update_state(k_y_test,y_pre)\n",
        "\n",
        "print(f\"-Accuracy score_mean:{m1.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Precision score_mean:{m2.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Recall score_mean:{m3.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUC score_mean:{m4.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUPR score_mean:{m5.result().numpy()}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Accuracy score_mean:0.8169546723365784\n",
            "-Precision score_mean:0.8412620425224304\n",
            "-Recall score_mean:0.8794125318527222\n",
            "-AUC score_mean:0.7435588836669922\n",
            "-AUPR score_mean:0.7838318347930908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK5mwKiODKdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I8R-bq-fsHP"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hxMwQhUfvIb",
        "outputId": "7e1ab082-4f87-466c-9b7a-56763713a2cd"
      },
      "source": [
        "y_pre1 = np.load('./model/masking/masking_svm_pre.npy')\n",
        "y_pre2 = np.load('./model/edeg/edeg_svm_pre.npy')\n",
        "\n",
        "y_pre3 = np.load('./model/context/context_svm_pre.npy')\n",
        "y_pre4 = np.load('./model/attfp/attfp_svm_pre.npy')\n",
        "\n",
        "y_pre5 = np.load('./model/fp/fp_svm_pre.npy')\n",
        "\n",
        "\n",
        "\n",
        "y_pre = (y_pre1+y_pre2+y_pre3+y_pre5+y_pre4)/5\n",
        "\n",
        "m1.update_state(k_y_test,y_pre)\n",
        "m2.update_state(k_y_test,y_pre)\n",
        "m3.update_state(k_y_test,y_pre)\n",
        "m4.update_state(k_y_test,y_pre)\n",
        "m5.update_state(k_y_test,y_pre)\n",
        "\n",
        "print(f\"-Accuracy score_mean:{m1.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Precision score_mean:{m2.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Recall score_mean:{m3.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUC score_mean:{m4.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUPR score_mean:{m5.result().numpy()}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Accuracy score_mean:0.8136625289916992\n",
            "-Precision score_mean:0.827495813369751\n",
            "-Recall score_mean:0.8948724269866943\n",
            "-AUC score_mean:0.728751003742218\n",
            "-AUPR score_mean:0.7855202555656433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFUmXfMRp3M_"
      },
      "source": [
        "# DeepDDI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiQqytn0p73b",
        "outputId": "28590f44-3eb0-4adb-df44-3a2195b1da23"
      },
      "source": [
        "y_pre1 = np.load('./model/masking/masking_DDI_pre.npy')\n",
        "y_pre2 = np.load('./model/edeg/fp_edeg_pre.npy')\n",
        "\n",
        "y_pre3 = np.load('./model/context/context_DDI_pre.npy')\n",
        "y_pre4 = np.load('./model/attfp/attfp_DDI_pre.npy')\n",
        "\n",
        "y_pre5 = np.load('./model/fp/fp_DDI_pre.npy')\n",
        "\n",
        "\n",
        "\n",
        "y_pre = (y_pre1+y_pre2+y_pre3+y_pre5+y_pre4)/5\n",
        "\n",
        "m1.update_state(k_y_test,y_pre)\n",
        "m2.update_state(k_y_test,y_pre)\n",
        "m3.update_state(k_y_test,y_pre)\n",
        "m4.update_state(k_y_test,y_pre)\n",
        "m5.update_state(k_y_test,y_pre)\n",
        "\n",
        "print(f\"-Accuracy score_mean:{m1.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Precision score_mean:{m2.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-Recall score_mean:{m3.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUC score_mean:{m4.result().numpy()}\")\n",
        "\n",
        "\n",
        "print(f\"-AUPR score_mean:{m5.result().numpy()}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Accuracy score_mean:0.8031275868415833\n",
            "-Precision score_mean:0.8195667862892151\n",
            "-Recall score_mean:0.8871424794197083\n",
            "-AUC score_mean:0.7314255833625793\n",
            "-AUPR score_mean:0.7429443597793579\n"
          ]
        }
      ]
    }
  ]
}